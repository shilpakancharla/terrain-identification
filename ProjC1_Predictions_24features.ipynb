{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "natural-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import imblearn\n",
    "#!{sys.executable} -m pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-feeding",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beginning-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Based on the training data given, we are able to extract 7 attributes:\n",
    "    1. x accelerometer measurement\n",
    "    2. y accelerometer measurement\n",
    "    3. z accelerometer measurement\n",
    "    4. x gyroscope measurement\n",
    "    5. y gyroscope measurement\n",
    "    6. z gyroscope measurement\n",
    "    7. time stamp for accelerometer and gyroscope measures\n",
    "    \n",
    "    We start by creating a dataframe using the csv files provided for readability.\n",
    "    \n",
    "    @param x_file: contains the xyz accelerometers and xyz gyroscope measures from the lower limb\n",
    "    @param x_time_file: contain the time stamps for the accelerometer and gyroscope measures\n",
    "    @return dataframe of 7 attributes mentioned\n",
    "\"\"\"\n",
    "def create_dataframe_X(x_file, x_time_file):\n",
    "    df1 = pd.read_csv(x_file, sep = ',', names = ['X_acc', 'Y_acc', 'Z_acc', 'X_gyr', 'Y_gyr', 'Z_gyr'])\n",
    "    df2 = pd.read_csv(x_time_file, names = ['Time stamp'])\n",
    "    frames = [df1, df2]\n",
    "    result = pd.concat(frames, axis = 1)\n",
    "    return result\n",
    "    \n",
    "\"\"\"\n",
    "    We have both the labels and the time stamps for the labels. We create a dataframe from these for\n",
    "    readability.\n",
    "    \n",
    "    @param y_file: contain the labels: \n",
    "        (0) indicates standing or walking in solid ground, \n",
    "        (1) indicates going down the stairs, \n",
    "        (2) indicates going up the stairs, and \n",
    "        (3) indicates walking on grass\n",
    "    @param y_time_file: contain the time stamps for the labels\n",
    "    @return dataframe of labels and time stamps\n",
    "\"\"\" \n",
    "def create_dataframe_Y(y_file, y_time_file):\n",
    "    df1 = pd.read_csv(y_file, names = ['Label'])\n",
    "    df2 = pd.read_csv(y_time_file, names = ['Time stamp'])\n",
    "    frames = [df1, df2]\n",
    "    result = pd.concat(frames, axis = 1)\n",
    "    return result\n",
    "    \n",
    "\"\"\"\n",
    "    We take the outputs of create_dataframe_X and create_dataframe_Y. In order to combine both of these\n",
    "    dataframes, we need look at the time intervals present for when the labels were assigned. The goal is\n",
    "    to return a dataframe that now has an eighth column in addition to the seven columns from the dataframe\n",
    "    from create_dataframe_X. Additionally, we know that x_frame contains more values than y_frame. We want to\n",
    "    map these labels accordingly. In the end, we drop data points that have missing values.\n",
    "    \n",
    "    @param x_frame: dataframe from create_dataframe_X\n",
    "    @param y_frame: dataframe from create_dataframe_Y\n",
    "    @return dataframe with 8 columns (7 attributes and label)\n",
    "\"\"\"\n",
    "def combine_frames(x_frame, y_frame):\n",
    "    # Change each dataframe column to a list for iterations\n",
    "    labels = y_frame['Label'].tolist()\n",
    "    time_stamp_y = y_frame['Time stamp'].tolist()\n",
    "    time_stamp_x = x_frame['Time stamp'].tolist()\n",
    "    \n",
    "    labels_for_x = [] # Create empty list to gather corresponding labels for x_frame\n",
    "    count = 0\n",
    "    for i in range(0, len(time_stamp_y)):\n",
    "        while (time_stamp_x[count] <= time_stamp_y[i]) and (count <= len(time_stamp_x)):\n",
    "            labels_for_x.append(labels[i])\n",
    "            count += 1\n",
    "        continue\n",
    "    \n",
    "    # Concatenate the dataframes\n",
    "    label_df = pd.DataFrame(labels_for_x, columns = ['Label']) # Convert list back to data frame\n",
    "    combined_frame = pd.concat([x_frame, label_df], axis = 1)\n",
    "    \n",
    "    # Drop missing values at the end\n",
    "    combined_frame = combined_frame.dropna()\n",
    "    \n",
    "    # Drop 'Time stamp' column\n",
    "    combined_frame = combined_frame.drop(columns = ['Time stamp'])\n",
    "    return combined_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "documented-eight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X_acc     Y_acc     Z_acc     X_gyr     Y_gyr     Z_gyr  Label\n",
      "0      1.726654  9.619981  1.723327 -0.001997  0.067502  0.126057    0.0\n",
      "1      2.225759  9.493385  1.782374  0.008557  0.029333  0.073573    0.0\n",
      "2      2.010621  9.481603  1.770000 -0.004651  0.001009  0.062978    0.0\n",
      "3      1.614272  9.516440  1.798932  0.009519  0.024405  0.032554    0.0\n",
      "4      1.862582  9.353709  1.722649  0.007902  0.022794  0.020837    0.0\n",
      "...         ...       ...       ...       ...       ...       ...    ...\n",
      "70164  3.704972  8.586173  3.088743 -0.010505  0.009598 -0.004949    0.0\n",
      "70165  3.690854  8.759488  3.099146 -0.002501  0.001989  0.001526    0.0\n",
      "70166  3.939186  8.407883  3.049837  0.015672  0.011588  0.014313    0.0\n",
      "70167  3.762566  8.168921  3.062974  0.015675  0.007165  0.019624    0.0\n",
      "70168  3.729076  8.256303  3.034621 -0.005977  0.006976  0.006051    0.0\n",
      "\n",
      "[70169 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "x = create_dataframe_X('TrainingData/subject_001_02__x.csv', 'TrainingData/subject_001_02__x_time.csv')\n",
    "y = create_dataframe_Y('TrainingData/subject_001_02__y.csv', 'TrainingData/subject_001_02__y_time.csv')\n",
    "combined = combine_frames(x, y)\n",
    "print(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fifteen-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Generating data frames from training data.\n",
    "\"\"\"\n",
    "# Subject_001_01\n",
    "df_x_1_1 = create_dataframe_X('TrainingData/subject_001_01__x.csv', 'TrainingData/subject_001_01__x_time.csv')\n",
    "df_y_1_1 = create_dataframe_Y('TrainingData/subject_001_01__y.csv', 'TrainingData/subject_001_01__y_time.csv')\n",
    "frame_1_1 = combine_frames(df_x_1_1, df_y_1_1)\n",
    "\n",
    "# Subject_001_02\n",
    "df_x_1_2 = create_dataframe_X('TrainingData/subject_001_02__x.csv', 'TrainingData/subject_001_02__x_time.csv')\n",
    "df_y_1_2 = create_dataframe_Y('TrainingData/subject_001_02__y.csv', 'TrainingData/subject_001_02__y_time.csv')\n",
    "frame_1_2 = combine_frames(df_x_1_2, df_y_1_2)\n",
    "\n",
    "# Subject_001_03\n",
    "df_x_1_3 = create_dataframe_X('TrainingData/subject_001_03__x.csv', 'TrainingData/subject_001_03__x_time.csv')\n",
    "df_y_1_3 = create_dataframe_Y('TrainingData/subject_001_03__y.csv', 'TrainingData/subject_001_03__y_time.csv')\n",
    "frame_1_3 = combine_frames(df_x_1_3, df_y_1_3)\n",
    "\n",
    "# Subject_001_04\n",
    "df_x_1_4 = create_dataframe_X('TrainingData/subject_001_04__x.csv', 'TrainingData/subject_001_04__x_time.csv')\n",
    "df_y_1_4 = create_dataframe_Y('TrainingData/subject_001_04__y.csv', 'TrainingData/subject_001_04__y_time.csv')\n",
    "frame_1_4 = combine_frames(df_x_1_4, df_y_1_4)\n",
    "\n",
    "# Subject_001_05\n",
    "df_x_1_5 = create_dataframe_X('TrainingData/subject_001_05__x.csv', 'TrainingData/subject_001_05__x_time.csv')\n",
    "df_y_1_5 = create_dataframe_Y('TrainingData/subject_001_05__y.csv', 'TrainingData/subject_001_05__y_time.csv')\n",
    "frame_1_5 = combine_frames(df_x_1_5, df_y_1_5)\n",
    "\n",
    "# Subject_001_06\n",
    "df_x_1_6 = create_dataframe_X('TrainingData/subject_001_06__x.csv', 'TrainingData/subject_001_06__x_time.csv')\n",
    "df_y_1_6 = create_dataframe_Y('TrainingData/subject_001_06__y.csv', 'TrainingData/subject_001_06__y_time.csv')\n",
    "frame_1_6 = combine_frames(df_x_1_6, df_y_1_6)\n",
    "\n",
    "# Subject_001_07\n",
    "df_x_1_7 = create_dataframe_X('TrainingData/subject_001_07__x.csv', 'TrainingData/subject_001_07__x_time.csv')\n",
    "df_y_1_7 = create_dataframe_Y('TrainingData/subject_001_07__y.csv', 'TrainingData/subject_001_07__y_time.csv')\n",
    "frame_1_7 = combine_frames(df_x_1_7, df_y_1_7)\n",
    "\n",
    "# Subject_001_08\n",
    "df_x_1_8 = create_dataframe_X('TrainingData/subject_001_08__x.csv', 'TrainingData/subject_001_08__x_time.csv')\n",
    "df_y_1_8 = create_dataframe_Y('TrainingData/subject_001_08__y.csv', 'TrainingData/subject_001_08__y_time.csv')\n",
    "frame_1_8 = combine_frames(df_x_1_8, df_y_1_8)\n",
    "\n",
    "# Subject_002_01\n",
    "df_x_2_1 = create_dataframe_X('TrainingData/subject_002_01__x.csv', 'TrainingData/subject_002_01__x_time.csv')\n",
    "df_y_2_1 = create_dataframe_Y('TrainingData/subject_002_01__y.csv', 'TrainingData/subject_002_01__y_time.csv')\n",
    "frame_2_1 = combine_frames(df_x_2_1, df_y_2_1)\n",
    "\n",
    "# Subject_002_02\n",
    "df_x_2_2 = create_dataframe_X('TrainingData/subject_002_02__x.csv', 'TrainingData/subject_002_02__x_time.csv')\n",
    "df_y_2_2 = create_dataframe_Y('TrainingData/subject_002_02__y.csv', 'TrainingData/subject_002_02__y_time.csv')\n",
    "frame_2_2 = combine_frames(df_x_2_2, df_y_2_2)\n",
    "\n",
    "# Subject_002_03\n",
    "df_x_2_3 = create_dataframe_X('TrainingData/subject_002_03__x.csv', 'TrainingData/subject_002_03__x_time.csv')\n",
    "df_y_2_3 = create_dataframe_Y('TrainingData/subject_002_03__y.csv', 'TrainingData/subject_002_03__y_time.csv')\n",
    "frame_2_3 = combine_frames(df_x_2_3, df_y_2_3)\n",
    "\n",
    "# Subject_002_04\n",
    "df_x_2_4 = create_dataframe_X('TrainingData/subject_001_04__x.csv', 'TrainingData/subject_001_04__x_time.csv')\n",
    "df_y_2_4 = create_dataframe_Y('TrainingData/subject_001_04__y.csv', 'TrainingData/subject_001_04__y_time.csv')\n",
    "frame_2_4 = combine_frames(df_x_2_4, df_y_2_4)\n",
    "\n",
    "# Subject_002_05\n",
    "df_x_2_5 = create_dataframe_X('TrainingData/subject_002_05__x.csv', 'TrainingData/subject_002_05__x_time.csv')\n",
    "df_y_2_5 = create_dataframe_Y('TrainingData/subject_002_05__y.csv', 'TrainingData/subject_002_05__y_time.csv')\n",
    "frame_2_5 = combine_frames(df_x_2_5, df_y_2_5)\n",
    "\n",
    "# Subject_003_01\n",
    "df_x_3_1 = create_dataframe_X('TrainingData/subject_003_01__x.csv', 'TrainingData/subject_003_01__x_time.csv')\n",
    "df_y_3_1 = create_dataframe_Y('TrainingData/subject_003_01__y.csv', 'TrainingData/subject_003_01__y_time.csv')\n",
    "frame_3_1 = combine_frames(df_x_3_1, df_y_3_1)\n",
    "\n",
    "# Subject_003_02\n",
    "df_x_3_2 = create_dataframe_X('TrainingData/subject_003_02__x.csv', 'TrainingData/subject_003_02__x_time.csv')\n",
    "df_y_3_2 = create_dataframe_Y('TrainingData/subject_003_02__y.csv', 'TrainingData/subject_003_02__y_time.csv')\n",
    "frame_3_2 = combine_frames(df_x_3_2, df_y_3_2)\n",
    "\n",
    "# Subject_003_03\n",
    "df_x_3_3 = create_dataframe_X('TrainingData/subject_003_03__x.csv', 'TrainingData/subject_003_03__x_time.csv')\n",
    "df_y_3_3 = create_dataframe_Y('TrainingData/subject_003_03__y.csv', 'TrainingData/subject_003_03__y_time.csv')\n",
    "frame_3_3 = combine_frames(df_x_3_3, df_y_3_3)\n",
    "\n",
    "# Subject_004_01\n",
    "df_x_4_1 = create_dataframe_X('TrainingData/subject_004_01__x.csv', 'TrainingData/subject_004_01__x_time.csv')\n",
    "df_y_4_1 = create_dataframe_Y('TrainingData/subject_004_01__y.csv', 'TrainingData/subject_004_01__y_time.csv')\n",
    "frame_4_1 = combine_frames(df_x_4_1, df_y_4_1)\n",
    "\n",
    "# Subject_004_02\n",
    "df_x_4_2 = create_dataframe_X('TrainingData/subject_004_02__x.csv', 'TrainingData/subject_004_02__x_time.csv')\n",
    "df_y_4_2 = create_dataframe_Y('TrainingData/subject_004_02__y.csv', 'TrainingData/subject_004_02__y_time.csv')\n",
    "frame_4_2 = combine_frames(df_x_4_2, df_y_4_2)\n",
    "\n",
    "# Subject_005_01\n",
    "df_x_5_1 = create_dataframe_X('TrainingData/subject_005_01__x.csv', 'TrainingData/subject_005_01__x_time.csv')\n",
    "df_y_5_1 = create_dataframe_Y('TrainingData/subject_005_01__y.csv', 'TrainingData/subject_005_01__y_time.csv')\n",
    "frame_5_1 = combine_frames(df_x_5_1, df_y_5_1)\n",
    "\n",
    "# Subject_005_02\n",
    "df_x_5_2 = create_dataframe_X('TrainingData/subject_005_02__x.csv', 'TrainingData/subject_005_02__x_time.csv')\n",
    "df_y_5_2 = create_dataframe_Y('TrainingData/subject_005_02__y.csv', 'TrainingData/subject_005_02__y_time.csv')\n",
    "frame_5_2 = combine_frames(df_x_5_2, df_y_5_2)\n",
    "\n",
    "# Subject_005_03\n",
    "df_x_5_3 = create_dataframe_X('TrainingData/subject_005_03__x.csv', 'TrainingData/subject_005_03__x_time.csv')\n",
    "df_y_5_3 = create_dataframe_Y('TrainingData/subject_005_03__y.csv', 'TrainingData/subject_005_03__y_time.csv')\n",
    "frame_5_3 = combine_frames(df_x_5_3, df_y_5_3)\n",
    "\n",
    "# Subject_006_01\n",
    "df_x_6_1 = create_dataframe_X('TrainingData/subject_006_01__x.csv', 'TrainingData/subject_006_01__x_time.csv')\n",
    "df_y_6_1 = create_dataframe_Y('TrainingData/subject_006_01__y.csv', 'TrainingData/subject_006_01__y_time.csv')\n",
    "frame_6_1 = combine_frames(df_x_6_1, df_y_6_1)\n",
    "\n",
    "# Subject_006_02\n",
    "df_x_6_2 = create_dataframe_X('TrainingData/subject_006_02__x.csv', 'TrainingData/subject_006_02__x_time.csv')\n",
    "df_y_6_2 = create_dataframe_Y('TrainingData/subject_006_02__y.csv', 'TrainingData/subject_006_02__y_time.csv')\n",
    "frame_6_2 = combine_frames(df_x_6_2, df_y_6_2)\n",
    "\n",
    "# Subject_006_03\n",
    "df_x_6_3 = create_dataframe_X('TrainingData/subject_006_03__x.csv', 'TrainingData/subject_006_03__x_time.csv')\n",
    "df_y_6_3 = create_dataframe_Y('TrainingData/subject_006_03__y.csv', 'TrainingData/subject_006_03__y_time.csv')\n",
    "frame_6_3 = combine_frames(df_x_6_3, df_y_6_3)\n",
    "\n",
    "# Subject_007_01\n",
    "df_x_7_1 = create_dataframe_X('TrainingData/subject_007_01__x.csv', 'TrainingData/subject_007_01__x_time.csv')\n",
    "df_y_7_1 = create_dataframe_Y('TrainingData/subject_007_01__y.csv', 'TrainingData/subject_007_01__y_time.csv')\n",
    "frame_7_1 = combine_frames(df_x_7_1, df_y_7_1)\n",
    "\n",
    "# Subject_007_02\n",
    "df_x_7_2 = create_dataframe_X('TrainingData/subject_007_02__x.csv', 'TrainingData/subject_007_02__x_time.csv')\n",
    "df_y_7_2 = create_dataframe_Y('TrainingData/subject_007_02__y.csv', 'TrainingData/subject_007_02__y_time.csv')\n",
    "frame_7_2 = combine_frames(df_x_7_2, df_y_7_2)\n",
    "\n",
    "# Subject_007_03\n",
    "df_x_7_3 = create_dataframe_X('TrainingData/subject_007_03__x.csv', 'TrainingData/subject_007_03__x_time.csv')\n",
    "df_y_7_3 = create_dataframe_Y('TrainingData/subject_007_03__y.csv', 'TrainingData/subject_007_03__y_time.csv')\n",
    "frame_7_3 = combine_frames(df_x_7_3, df_y_7_3)\n",
    "\n",
    "# Subject_007_04\n",
    "df_x_7_4 = create_dataframe_X('TrainingData/subject_007_04__x.csv', 'TrainingData/subject_007_04__x_time.csv')\n",
    "df_y_7_4 = create_dataframe_Y('TrainingData/subject_007_04__y.csv', 'TrainingData/subject_007_04__y_time.csv')\n",
    "frame_7_4 = combine_frames(df_x_7_4, df_y_7_4)\n",
    "\n",
    "# Subject_008_01\n",
    "df_x_8_1 = create_dataframe_X('TrainingData/subject_008_01__x.csv', 'TrainingData/subject_008_01__x_time.csv')\n",
    "df_y_8_1 = create_dataframe_Y('TrainingData/subject_008_01__y.csv', 'TrainingData/subject_008_01__y_time.csv')\n",
    "frame_8_1 = combine_frames(df_x_8_1, df_y_8_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "electoral-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Combining all data frames.\n",
    "\"\"\"\n",
    "frame_list = [frame_1_1, frame_1_2, frame_1_3, frame_1_4, frame_1_5, frame_1_6, frame_1_7, frame_1_8,\n",
    "             frame_2_1, frame_2_2, frame_2_3, frame_2_4, frame_2_5,\n",
    "             frame_3_1, frame_3_2, frame_3_3,\n",
    "             frame_4_1, frame_4_2,\n",
    "             frame_5_1, frame_5_2, frame_5_3,\n",
    "             frame_6_1, frame_6_2, frame_6_3,\n",
    "             frame_7_1, frame_7_2, frame_7_3, frame_7_4,\n",
    "             frame_8_1]\n",
    "data = pd.concat(frame_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cellular-stewart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X_acc     Y_acc     Z_acc     X_gyr     Y_gyr     Z_gyr  Label\n",
      "0      4.435275  8.196063  2.974488  0.014215 -0.039157 -0.016744    0.0\n",
      "1      4.186920  8.344455  2.908057  0.005771 -0.004480 -0.003345    0.0\n",
      "2      4.544637  8.408659  2.890000  0.007967  0.022412  0.001159    0.0\n",
      "3      4.849308  8.411614  2.900692  0.027778 -0.010670 -0.014223    0.0\n",
      "4      4.509190  8.118649  2.847298  0.021577 -0.045498 -0.021111    0.0\n",
      "...         ...       ...       ...       ...       ...       ...    ...\n",
      "48132  2.098301  8.893398 -3.510000  0.001195  0.000335  0.001027    0.0\n",
      "48133  2.072244  8.908878 -3.500000  0.001351  0.001191  0.001031    0.0\n",
      "48134  2.085123  8.915123 -3.520000  0.001918 -0.001147  0.000000    0.0\n",
      "48135  2.083774  8.910000 -3.538981 -0.002015 -0.004099  0.001042    0.0\n",
      "48136  2.111447  8.908553 -3.535724  0.000183 -0.001673  0.001856    0.0\n",
      "\n",
      "[1345061 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "neural-appointment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Create X and y\n",
    "X = data[['X_acc', 'Y_acc', 'Z_acc', 'X_gyr', 'Y_gyr', 'Z_gyr']]\n",
    "y = data['Label']\n",
    "#oversample = SMOTE()\n",
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "offshore-jungle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              1         2         3         4         5         6         8   \\\n",
      "0       4.435275  8.196063  2.974488  0.014215 -0.039157 -0.016744  4.186920   \n",
      "1       4.509190  8.118649  2.847298  0.021577 -0.045498 -0.021111  4.226515   \n",
      "2       4.160676  8.260676  2.827568  0.011222 -0.016748 -0.006027  4.432763   \n",
      "3       3.931769  8.203628  2.958186 -0.015232 -0.006177  0.016877  4.524325   \n",
      "4       4.633221  8.197211  2.872404 -0.006495  0.039828  0.040343  4.788242   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "336260  2.065920  8.890000 -3.531840  0.003673 -0.003765 -0.001882  2.040000   \n",
      "336261  2.080000  8.904528 -3.519057  0.001111 -0.002931  0.001819  2.089250   \n",
      "336262  2.098552  8.898552 -3.515724  0.000000 -0.003569 -0.002222  2.060000   \n",
      "336263  2.085576  8.891152 -3.518848 -0.005395 -0.003226 -0.001057  2.051408   \n",
      "336264  2.098301  8.893398 -3.510000  0.001195  0.000335  0.001027  2.072244   \n",
      "\n",
      "              9         10        11  ...        17        18        19  \\\n",
      "0       8.344455  2.908057  0.005771  ...  2.890000  0.007967  0.022412   \n",
      "1       8.273807  2.851742  0.012534  ...  2.856682  0.014484  0.028769   \n",
      "2       8.272613  2.790050 -0.002715  ...  2.820538 -0.002248  0.001547   \n",
      "3       8.446963  2.874356 -0.003438  ...  2.782674 -0.002790  0.012677   \n",
      "4       8.201208  2.805275 -0.009608  ...  2.847035 -0.012330  0.018727   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "336260  8.910442 -3.528234 -0.003269  ... -3.512156 -0.003239 -0.005415   \n",
      "336261  8.900750 -3.539250  0.002040  ... -3.539476 -0.001942 -0.001111   \n",
      "336262  8.920930 -3.540930 -0.001169  ... -3.510000 -0.000049 -0.001136   \n",
      "336263  8.911408 -3.500704 -0.001219  ... -3.534900 -0.000794  0.001693   \n",
      "336264  8.908878 -3.500000  0.001351  ... -3.520000  0.001918 -0.001147   \n",
      "\n",
      "              20        22        23        24        25        26        27  \n",
      "0       0.001159  4.849308  8.411614  2.900692  0.027778 -0.010670 -0.014223  \n",
      "1      -0.011091  4.433669  8.294719  2.823521  0.016340 -0.029434 -0.008998  \n",
      "2       0.011137  4.098018  8.154184  2.901101 -0.010418 -0.042853  0.005031  \n",
      "3       0.054444  4.392814  8.239121  2.830176  0.001527  0.015576  0.052817  \n",
      "4       0.017562  4.612801  8.290000  2.845603 -0.004444  0.005675  0.003214  \n",
      "...          ...       ...       ...       ...       ...       ...       ...  \n",
      "336260 -0.001064  2.056069  8.903931 -3.516412  0.000787 -0.002222  0.000949  \n",
      "336261 -0.000280  2.104060  8.905940 -3.512179 -0.002083  0.000834 -0.001805  \n",
      "336262 -0.001111  2.095364  8.894636 -3.486954  0.000343  0.004787 -0.000768  \n",
      "336263  0.000582  2.103047  8.900000 -3.504349  0.000393  0.003299  0.001863  \n",
      "336264  0.000000  2.083774  8.910000 -3.538981 -0.002015 -0.004099  0.001042  \n",
      "\n",
      "[336265 rows x 24 columns]\n",
      "        Label\n",
      "0         0.0\n",
      "1         0.0\n",
      "2         0.0\n",
      "3         0.0\n",
      "4         0.0\n",
      "...       ...\n",
      "336260    0.0\n",
      "336261    0.0\n",
      "336262    0.0\n",
      "336263    0.0\n",
      "336264    0.0\n",
      "\n",
      "[336265 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "item0 = X.iloc[0::4,].reset_index()\n",
    "item1 = X.iloc[1::4,].reset_index()\n",
    "item2 = X.iloc[2::4,].reset_index()\n",
    "item3 = X.iloc[3::4,].reset_index()\n",
    "new_X = pd.concat([item0, item1, item2, item3], axis = 1, ignore_index = True)\n",
    "new_y = y.iloc[::4].reset_index()\n",
    "#print(new_X)\n",
    "#print(new_y)\n",
    "#print(new_X.iloc[0:2, 0:14])\n",
    "#print(new_X.iloc[0:2, 14:28])\n",
    "#print(new_X.iloc[0:2, ::7])\n",
    "\n",
    "new_X = new_X.dropna()\n",
    "new_X = new_X.drop(columns = [0, 7, 14, 21])\n",
    "new_y = new_y.iloc[0:336265]\n",
    "new_y = new_y.drop(columns = [\"index\"])\n",
    "print(new_X)\n",
    "print(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "settled-france",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              1          2          3         4         5         6   \\\n",
      "0      -0.931978   1.150824  10.538850  4.443518  1.449658  0.937431   \n",
      "1       8.897181  -6.869992  -5.657345  3.617849  0.795477 -0.780897   \n",
      "2       9.330196  22.915230  -5.000229 -4.248560 -1.828423  0.324595   \n",
      "3      -4.193694   2.395663   8.624337  3.398952  0.073381 -0.732928   \n",
      "4       3.292324   9.915436   3.280830  5.784408  0.067339 -0.679083   \n",
      "...          ...        ...        ...       ...       ...       ...   \n",
      "58447   3.128545  -0.519814  11.584370  4.415041 -0.833713 -1.222693   \n",
      "58448 -12.750750  -7.068924  10.037950 -2.796976 -0.114285  0.778639   \n",
      "58449   2.476282   4.070074   8.641264  3.500828  1.436515 -1.176871   \n",
      "58450   4.990125   8.258702   1.902598 -0.854384 -0.068192 -0.021236   \n",
      "58451  -1.140044   9.454595   5.129984 -0.568959  0.852395  0.280907   \n",
      "\n",
      "              8          9          10        11  ...         17        18  \\\n",
      "0       0.342040   0.640000  10.404010  5.175676  ...  10.815580  5.620439   \n",
      "1      -8.809071  -3.481797   2.094920 -1.578053  ...  11.774270 -3.728639   \n",
      "2       1.214110  19.849260   9.348403 -4.346760  ...  14.656580 -3.469470   \n",
      "3      -2.503096   2.096946  10.126280  4.376418  ...  10.682490  4.914395   \n",
      "4       4.405783  10.593320   2.382686  6.280255  ...   2.239501  6.411526   \n",
      "...          ...        ...        ...       ...  ...        ...       ...   \n",
      "58447   0.745382  -0.543266  11.489610  4.809857  ...  10.733510  4.877403   \n",
      "58448 -11.385060  10.496570  14.993050 -2.067175  ...  11.307180 -1.594757   \n",
      "58449   2.489052   4.070299   9.331122  4.660241  ...   9.570243  5.549547   \n",
      "58450   0.100576   8.566462   4.133553 -0.932789  ...   5.792225 -0.925692   \n",
      "58451  -1.893223   8.513388   4.253884 -0.576500  ...   2.244594 -0.664271   \n",
      "\n",
      "             19        20        22         23         24        25        26  \\\n",
      "0      1.021552  1.279464 -0.036050  -1.471864   9.152086  5.805314  0.550576   \n",
      "1     -1.412274 -0.625922 -8.380100  28.535880  -4.083969 -0.656770  3.306867   \n",
      "2     -3.222960 -0.249272 -5.485085  10.735840  16.148350 -2.144037 -1.373014   \n",
      "3      2.487463 -0.172177  1.434496   1.462806  11.624630  5.941699  3.205086   \n",
      "4     -0.094429 -1.104388 -0.483425   8.970580   2.288946  5.711234 -0.416255   \n",
      "...         ...       ...       ...        ...        ...       ...       ...   \n",
      "58447 -1.783661 -1.736846 -2.066530  -0.016650  10.737030  4.927195 -1.851372   \n",
      "58448  2.103529  1.193513  0.137377   7.185249   9.931312 -1.402347  1.236648   \n",
      "58449  2.213091 -1.029874  7.386633   1.827574   9.671781  6.626860  1.909471   \n",
      "58450 -0.543098 -0.176426 -0.816739   8.776761   6.573435 -0.810178 -0.177498   \n",
      "58451  1.034618  0.342696  3.258174   9.095700   2.012454 -0.747876  0.891328   \n",
      "\n",
      "             27  \n",
      "0      1.484114  \n",
      "1      0.357802  \n",
      "2      0.325597  \n",
      "3      0.317472  \n",
      "4     -1.286935  \n",
      "...         ...  \n",
      "58447 -1.648768  \n",
      "58448  0.541063  \n",
      "58449 -0.847999  \n",
      "58450 -0.080125  \n",
      "58451  0.290699  \n",
      "\n",
      "[58452 rows x 24 columns]\n",
      "       Label\n",
      "0        0.0\n",
      "1        0.0\n",
      "2        0.0\n",
      "3        0.0\n",
      "4        0.0\n",
      "...      ...\n",
      "58447    3.0\n",
      "58448    3.0\n",
      "58449    3.0\n",
      "58450    3.0\n",
      "58451    3.0\n",
      "\n",
      "[58452 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(new_X, new_y)\n",
    "print(X_resampled)\n",
    "print(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "spectacular-defense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               1          2          3         4         5         6  \\\n",
      "0      -0.931978   1.150824  10.538850  4.443518  1.449658  0.937431   \n",
      "1       8.897181  -6.869992  -5.657345  3.617849  0.795477 -0.780897   \n",
      "2       9.330196  22.915230  -5.000229 -4.248560 -1.828423  0.324595   \n",
      "3      -4.193694   2.395663   8.624337  3.398952  0.073381 -0.732928   \n",
      "4       3.292324   9.915436   3.280830  5.784408  0.067339 -0.679083   \n",
      "...          ...        ...        ...       ...       ...       ...   \n",
      "58447   3.128545  -0.519814  11.584370  4.415041 -0.833713 -1.222693   \n",
      "58448 -12.750750  -7.068924  10.037950 -2.796976 -0.114285  0.778639   \n",
      "58449   2.476282   4.070074   8.641264  3.500828  1.436515 -1.176871   \n",
      "58450   4.990125   8.258702   1.902598 -0.854384 -0.068192 -0.021236   \n",
      "58451  -1.140044   9.454595   5.129984 -0.568959  0.852395  0.280907   \n",
      "\n",
      "               8          9         10        11  ...        18        19  \\\n",
      "0       0.342040   0.640000  10.404010  5.175676  ...  5.620439  1.021552   \n",
      "1      -8.809071  -3.481797   2.094920 -1.578053  ... -3.728639 -1.412274   \n",
      "2       1.214110  19.849260   9.348403 -4.346760  ... -3.469470 -3.222960   \n",
      "3      -2.503096   2.096946  10.126280  4.376418  ...  4.914395  2.487463   \n",
      "4       4.405783  10.593320   2.382686  6.280255  ...  6.411526 -0.094429   \n",
      "...          ...        ...        ...       ...  ...       ...       ...   \n",
      "58447   0.745382  -0.543266  11.489610  4.809857  ...  4.877403 -1.783661   \n",
      "58448 -11.385060  10.496570  14.993050 -2.067175  ... -1.594757  2.103529   \n",
      "58449   2.489052   4.070299   9.331122  4.660241  ...  5.549547  2.213091   \n",
      "58450   0.100576   8.566462   4.133553 -0.932789  ... -0.925692 -0.543098   \n",
      "58451  -1.893223   8.513388   4.253884 -0.576500  ... -0.664271  1.034618   \n",
      "\n",
      "             20        22         23         24        25        26        27  \\\n",
      "0      1.279464 -0.036050  -1.471864   9.152086  5.805314  0.550576  1.484114   \n",
      "1     -0.625922 -8.380100  28.535880  -4.083969 -0.656770  3.306867  0.357802   \n",
      "2     -0.249272 -5.485085  10.735840  16.148350 -2.144037 -1.373014  0.325597   \n",
      "3     -0.172177  1.434496   1.462806  11.624630  5.941699  3.205086  0.317472   \n",
      "4     -1.104388 -0.483425   8.970580   2.288946  5.711234 -0.416255 -1.286935   \n",
      "...         ...       ...        ...        ...       ...       ...       ...   \n",
      "58447 -1.736846 -2.066530  -0.016650  10.737030  4.927195 -1.851372 -1.648768   \n",
      "58448  1.193513  0.137377   7.185249   9.931312 -1.402347  1.236648  0.541063   \n",
      "58449 -1.029874  7.386633   1.827574   9.671781  6.626860  1.909471 -0.847999   \n",
      "58450 -0.176426 -0.816739   8.776761   6.573435 -0.810178 -0.177498 -0.080125   \n",
      "58451  0.342696  3.258174   9.095700   2.012454 -0.747876  0.891328  0.290699   \n",
      "\n",
      "       Label  \n",
      "0        0.0  \n",
      "1        0.0  \n",
      "2        0.0  \n",
      "3        0.0  \n",
      "4        0.0  \n",
      "...      ...  \n",
      "58447    3.0  \n",
      "58448    3.0  \n",
      "58449    3.0  \n",
      "58450    3.0  \n",
      "58451    3.0  \n",
      "\n",
      "[58452 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "data_resampled = pd.concat([X_resampled, y_resampled], axis = 1)\n",
    "print(data_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-satellite",
   "metadata": {},
   "source": [
    "# Training, Validation, Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "coral-criminal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "                1         2          3         4         5         6  \\\n",
      "27331   2.684021  5.902239   3.960992 -1.068728  0.113616 -0.135065   \n",
      "11165   4.435768  2.178142   7.088589  3.425281  0.169380 -1.571216   \n",
      "54313   1.000521  0.358844  10.525170  4.789847  1.985422  0.554309   \n",
      "15865   2.546577  8.408928   6.857072 -0.054817  0.343550  0.251634   \n",
      "45397  -3.893779 -0.750334  11.454740  5.242827  2.705046  1.335865   \n",
      "...          ...       ...        ...       ...       ...       ...   \n",
      "1115   -0.620051  9.030956   1.275923 -0.543841 -0.872618 -0.349009   \n",
      "4101    0.401814  1.858139  12.001980  5.295598  2.284205 -0.554545   \n",
      "48340  -1.301530  8.668470   1.268832 -0.733699 -0.972354 -0.224547   \n",
      "19551  14.742420 -2.004139   3.249742 -2.650505  3.852304  1.230034   \n",
      "44950   5.667555  8.399123   5.325120 -0.633430 -0.803683 -0.160945   \n",
      "\n",
      "               8         9         10        11  ...        18        19  \\\n",
      "27331   1.447139  5.602395   4.693619 -1.434231  ... -1.576595 -0.914314   \n",
      "11165   4.729639  1.964007   7.675524  4.035050  ...  5.037721  0.425558   \n",
      "54313   3.536028 -0.640265   8.935463  5.555773  ...  5.831987  0.810923   \n",
      "15865   3.585647  8.187913   5.423836  0.005448  ... -0.027064 -0.458593   \n",
      "45397   0.583758 -4.740218  10.499010  6.370040  ...  6.828296  2.568704   \n",
      "...          ...       ...        ...       ...  ...       ...       ...   \n",
      "1115   -2.877986  7.044079   1.479215 -0.723916  ... -0.927870 -0.446696   \n",
      "4101    1.338488  1.552087  12.766730  6.092764  ...  7.011380  2.632725   \n",
      "48340  -1.428690  7.683724   0.503104 -0.977253  ... -1.166791 -0.585698   \n",
      "19551  15.991300  8.343276   5.069586 -2.807355  ... -2.903185 -0.835199   \n",
      "44950   1.953335  8.194615   4.270462 -0.589658  ... -0.556154 -1.035829   \n",
      "\n",
      "             20        22         23         24        25        26        27  \\\n",
      "27331 -0.493324 -3.176794   6.520765   0.833588 -2.139801 -0.836646  0.074295   \n",
      "11165 -1.547252  0.424123   3.122213   9.005343  5.561376  0.866719 -1.441923   \n",
      "54313  0.727937  2.718257  -1.193092   9.252486  6.240690 -0.449477  0.435977   \n",
      "15865  0.046433  0.373186   7.054284   3.313704 -0.101149 -0.709368  0.014097   \n",
      "45397  2.331325  4.672149  -0.299075  12.746310  7.469323  0.458039  2.450636   \n",
      "...         ...       ...        ...        ...       ...       ...       ...   \n",
      "1115  -0.419207 -0.557028   9.246116   1.449254 -1.181305 -0.922031 -0.654273   \n",
      "4101  -0.045818  4.195475   2.482163  15.746200  7.676783  2.269166  0.152074   \n",
      "48340 -0.029691 -0.759595   9.824368   4.273276 -1.384466 -0.320099  0.076030   \n",
      "19551 -0.831930 -7.076043  14.490800  10.629060 -2.595493 -0.055263 -0.539583   \n",
      "44950 -0.170346 -0.315090   9.184811   3.505189 -0.561181 -0.968368 -0.160746   \n",
      "\n",
      "       Label  \n",
      "27331    1.0  \n",
      "11165    0.0  \n",
      "54313    3.0  \n",
      "15865    1.0  \n",
      "45397    3.0  \n",
      "...      ...  \n",
      "1115     0.0  \n",
      "4101     0.0  \n",
      "48340    3.0  \n",
      "19551    1.0  \n",
      "44950    3.0  \n",
      "\n",
      "[43839 rows x 25 columns]\n",
      "Validation:\n",
      "               1          2          3         4         5         6         8  \\\n",
      "25765  0.704543  10.901280   5.866338 -1.844300 -1.218660  0.377492 -3.849082   \n",
      "33055 -0.694742   8.693233   6.273908  0.743417 -0.501204 -0.082970 -1.279178   \n",
      "22234  4.721225  10.641430   5.672293 -1.771422 -1.027065 -0.266080  0.523227   \n",
      "55648  1.157651  -3.163440  15.457550 -4.133381  2.646774  0.862439  1.854145   \n",
      "55796  1.172066   7.244584  -0.244299 -1.388400  0.511397  0.161223  1.092120   \n",
      "...         ...        ...        ...       ...       ...       ...       ...   \n",
      "3436  -1.960026   8.183108   9.487281 -2.471348 -1.636062  0.111808  0.203514   \n",
      "19892 -1.401075  11.074040   4.009415 -2.247557 -0.942331 -0.328427 -1.583589   \n",
      "2139  -3.165805   8.305430  -0.653208 -0.715723 -0.997124 -0.140738 -3.761164   \n",
      "24417  1.175891   8.500072   5.275982 -2.442305 -0.382662 -0.718109  2.630140   \n",
      "24683 -6.703156   5.530209  10.549410  3.833398  0.587242 -0.029665 -0.922584   \n",
      "\n",
      "               9         10        11  ...        18        19        20  \\\n",
      "25765  -0.849069   8.738415  0.247620  ...  1.648066  0.020099  0.028852   \n",
      "33055   7.682694   5.819087  0.698353  ...  0.700458 -0.932304 -0.083840   \n",
      "22234  10.301660   6.555146 -1.340225  ... -1.207778 -1.051561 -0.217265   \n",
      "55648  12.761630  16.309630 -2.558911  ... -1.282210  1.178188  0.130365   \n",
      "55796   8.945449   0.318023 -1.716734  ... -2.166031  0.321706  0.112042   \n",
      "...          ...        ...       ...  ...       ...       ...       ...   \n",
      "3436    8.222532   6.991636 -1.117252  ... -1.263488  0.762035 -0.120580   \n",
      "19892   6.174867   5.803200 -2.571422  ... -3.089883 -0.969705 -0.260391   \n",
      "2139    8.119102   0.006406 -0.977718  ... -1.216523 -0.244500  0.176335   \n",
      "24417   8.852995   8.221868 -2.660766  ... -2.981640 -0.834874 -1.067597   \n",
      "24683   4.552646  12.670680  4.776964  ...  5.244251  1.771699  0.655951   \n",
      "\n",
      "              22         23         24        25        26        27  Label  \n",
      "25765 -12.146110   3.881046  12.623640  2.849029  1.306150  0.400882    1.0  \n",
      "33055  -3.508620   7.086352   5.470756  0.751230 -0.682254  0.031354    2.0  \n",
      "22234  -0.345366   9.913184   5.037245 -1.159521  0.127169 -0.061762    1.0  \n",
      "55648   1.442638   9.258290   9.239270 -0.774267  0.775700 -0.011762    3.0  \n",
      "55796   1.042599  10.381230   1.322728 -2.452983  0.153923  0.058875    3.0  \n",
      "...          ...        ...        ...       ...       ...       ...    ...  \n",
      "3436    3.403407   7.922368   4.063867  0.851039 -0.778332  0.156176    0.0  \n",
      "19892   1.788430  12.193080   5.773588 -3.355660 -1.306219 -0.340210    1.0  \n",
      "2139    2.198431   9.028274   4.817604 -1.337701 -0.246208  0.215441    0.0  \n",
      "24417   1.865604  19.874190  13.724920 -3.148271 -1.508920 -0.952249    1.0  \n",
      "24683   7.958278  -1.706113   9.317402  5.087526  0.370918  0.526366    1.0  \n",
      "\n",
      "[7306 rows x 25 columns]\n",
      "Test:\n",
      "                1          2          3         4         5         6  \\\n",
      "5       4.529190   2.441756  10.608650  5.839411  3.300385  0.448383   \n",
      "10     25.069780   9.606020   7.162625 -2.067335  3.444150  0.757161   \n",
      "11     -3.092719   9.036177   2.677937 -0.998793 -0.105356 -0.261810   \n",
      "13     -2.925221   8.295869   0.363806 -1.199252  0.150038  0.088586   \n",
      "19     -3.585952   8.021689  11.641290 -2.879605 -0.565083 -0.377137   \n",
      "...          ...        ...        ...       ...       ...       ...   \n",
      "58411   0.459674   8.961967   1.029515 -0.843777 -1.325987 -0.233630   \n",
      "58412  -4.661109   8.403633  18.771990 -2.426711 -1.325415  0.226010   \n",
      "58426  -0.009033   8.215645   2.015806 -0.347025 -0.527097  0.038423   \n",
      "58430   1.139370  11.287890   0.434312 -2.005235 -0.599011  0.145495   \n",
      "58438  -3.961234   2.152352  12.433280  6.828323 -1.798621 -1.545160   \n",
      "\n",
      "               8          9         10        11  ...        18        19  \\\n",
      "5       4.237524   2.020841  12.200910  6.710980  ...  7.251123  1.693294   \n",
      "10     13.081280   7.340094  10.139790 -1.635967  ... -1.224641 -3.605789   \n",
      "11     -1.088364   9.089777   2.308895 -1.184002  ... -1.398424  0.300701   \n",
      "13     -0.920247   8.783355   0.342385 -1.437137  ... -1.844610  0.266368   \n",
      "19     -6.946529   9.867287  12.033520 -2.501069  ... -2.035369  0.689104   \n",
      "...          ...        ...        ...       ...  ...       ...       ...   \n",
      "58411  -0.507080   8.671752  -1.063575 -1.029893  ... -1.516866 -1.250225   \n",
      "58412   7.165062   8.531060  17.595520 -2.499851  ... -0.652062  0.380767   \n",
      "58426   0.551612   7.759237   1.628897 -0.547675  ... -0.718970 -0.245872   \n",
      "58430   1.281453  10.617550   0.819073 -2.407173  ... -2.650394 -0.658382   \n",
      "58438  -5.356261   1.024872  11.760480  7.191319  ...  7.648683 -0.575807   \n",
      "\n",
      "             20         22         23         24        25        26  \\\n",
      "5      0.891586   1.650993   7.477162  12.922150  8.187883  1.004444   \n",
      "10    -1.753808 -17.541710  12.531610  10.832200 -0.618548 -3.016339   \n",
      "11    -0.063199  -0.796682   8.284425   1.394291 -1.914358  0.103143   \n",
      "13     0.129117   0.994247   9.843010   2.540680 -2.002487  0.078820   \n",
      "19    -0.064466   3.340875   9.900338   6.664226 -1.579274 -0.953224   \n",
      "...         ...        ...        ...        ...       ...       ...   \n",
      "58411 -0.026428  -2.040790   8.994359  -0.788401 -1.936474 -0.595543   \n",
      "58412 -0.401073  -2.018238   6.935137  13.186960  0.832448  0.312144   \n",
      "58426  0.197123   0.981955   8.448129   2.676829 -0.914550 -0.421809   \n",
      "58430  0.275786   5.727385  12.649300  -3.068957 -2.978361 -0.834308   \n",
      "58438 -1.747304   2.401736   2.816520  14.490760  7.878852 -1.111573   \n",
      "\n",
      "             27  Label  \n",
      "5      1.096158    0.0  \n",
      "10    -0.981569    0.0  \n",
      "11    -0.035110    0.0  \n",
      "13     0.022939    0.0  \n",
      "19    -0.345866    0.0  \n",
      "...         ...    ...  \n",
      "58411  0.240956    3.0  \n",
      "58412 -0.874186    3.0  \n",
      "58426  0.226723    3.0  \n",
      "58430  0.310544    3.0  \n",
      "58438 -1.880790    3.0  \n",
      "\n",
      "[7307 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Creating training, validation, and test sets from a data frame.\n",
    "    \n",
    "    @param frame: dataframe passed in\n",
    "    @return training, validation, and test sets created from frame passed in\n",
    "\"\"\"\n",
    "def training_validation_test_split(frame):\n",
    "    frame_copy = frame.copy()\n",
    "    training_set = frame_copy.sample(frac = 0.75, random_state = 0)\n",
    "    val_temp = frame_copy.drop(training_set.index)\n",
    "    validation_set = val_temp.sample(frac = 0.5, random_state = 0)\n",
    "    test_set = val_temp.drop(validation_set.index)\n",
    "    return training_set, validation_set, test_set\n",
    "\n",
    "training, val, test = training_validation_test_split(data_resampled)\n",
    "\n",
    "print(\"Training:\\n\", training)\n",
    "print(\"Validation:\\n\", val)\n",
    "print(\"Test:\\n\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "furnished-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, Flatten, Dense, Activation, BatchNormalization, Dropout\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "suspended-failing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 23, 128)           384       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                90176     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 90,820\n",
      "Trainable params: 90,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define a CNN model\n",
    "# from https://www.datatechnotes.com/2020/02/classification-example-with-keras-cnn.html\n",
    "def define_CNN_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(128, 2, activation=\"relu\", input_shape=(24,1)))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Flatten())   \n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(4, activation = 'softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])    \n",
    "    \n",
    "    return model\n",
    "\n",
    "# Creating an instance\n",
    "base_model = define_CNN_model()\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "under-uganda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   7/1370 [..............................] - ETA: 11s - loss: 1.5485 - accuracy: 0.2411"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User1\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3349: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User1\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3349: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1367/1370 [============================>.] - ETA: 0s - loss: 1.0149 - accuracy: 0.5383"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User1\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3349: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1370/1370 [==============================] - 13s 9ms/step - loss: 1.0144 - accuracy: 0.5386 - val_loss: 0.8600 - val_accuracy: 0.6158\n",
      "Epoch 2/50\n",
      "1370/1370 [==============================] - 13s 9ms/step - loss: 0.8190 - accuracy: 0.6352 - val_loss: 0.7798 - val_accuracy: 0.6434\n",
      "Epoch 3/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.7684 - accuracy: 0.6623 - val_loss: 0.7422 - val_accuracy: 0.6738\n",
      "Epoch 4/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.7382 - accuracy: 0.6775 - val_loss: 0.7090 - val_accuracy: 0.6931\n",
      "Epoch 5/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.7184 - accuracy: 0.6873 - val_loss: 0.7008 - val_accuracy: 0.6956\n",
      "Epoch 6/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.6999 - accuracy: 0.6986 - val_loss: 0.7167 - val_accuracy: 0.6945\n",
      "Epoch 7/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.6879 - accuracy: 0.7029 - val_loss: 0.6779 - val_accuracy: 0.7106\n",
      "Epoch 8/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.6749 - accuracy: 0.7078 - val_loss: 0.6817 - val_accuracy: 0.7085\n",
      "Epoch 9/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.6628 - accuracy: 0.7157 - val_loss: 0.6884 - val_accuracy: 0.7057\n",
      "Epoch 10/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.6556 - accuracy: 0.7179 - val_loss: 0.6639 - val_accuracy: 0.7064\n",
      "Epoch 11/50\n",
      "1370/1370 [==============================] - 13s 9ms/step - loss: 0.6486 - accuracy: 0.7215 - val_loss: 0.6631 - val_accuracy: 0.7123\n",
      "Epoch 12/50\n",
      "1370/1370 [==============================] - 14s 10ms/step - loss: 0.6418 - accuracy: 0.7266 - val_loss: 0.6426 - val_accuracy: 0.7228\n",
      "Epoch 13/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.6353 - accuracy: 0.7276 - val_loss: 0.6444 - val_accuracy: 0.7212\n",
      "Epoch 14/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.6285 - accuracy: 0.7275 - val_loss: 0.6395 - val_accuracy: 0.7257\n",
      "Epoch 15/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.6244 - accuracy: 0.7297 - val_loss: 0.6395 - val_accuracy: 0.7232\n",
      "Epoch 16/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.6176 - accuracy: 0.7308 - val_loss: 0.6351 - val_accuracy: 0.7287\n",
      "Epoch 17/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.6159 - accuracy: 0.7324 - val_loss: 0.6261 - val_accuracy: 0.7316\n",
      "Epoch 18/50\n",
      "1370/1370 [==============================] - 13s 9ms/step - loss: 0.6112 - accuracy: 0.7356 - val_loss: 0.6222 - val_accuracy: 0.7336\n",
      "Epoch 19/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.6061 - accuracy: 0.7372 - val_loss: 0.6283 - val_accuracy: 0.7280\n",
      "Epoch 20/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.6038 - accuracy: 0.7379 - val_loss: 0.6303 - val_accuracy: 0.7258\n",
      "Epoch 21/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.6009 - accuracy: 0.7395 - val_loss: 0.6428 - val_accuracy: 0.7243\n",
      "Epoch 22/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5971 - accuracy: 0.7402 - val_loss: 0.6215 - val_accuracy: 0.7342\n",
      "Epoch 23/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5940 - accuracy: 0.7416 - val_loss: 0.6113 - val_accuracy: 0.7394\n",
      "Epoch 24/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5941 - accuracy: 0.7426 - val_loss: 0.6217 - val_accuracy: 0.7312\n",
      "Epoch 25/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5898 - accuracy: 0.7433 - val_loss: 0.6192 - val_accuracy: 0.7294\n",
      "Epoch 26/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5857 - accuracy: 0.7446 - val_loss: 0.6212 - val_accuracy: 0.7346\n",
      "Epoch 27/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5840 - accuracy: 0.7470 - val_loss: 0.6194 - val_accuracy: 0.7375\n",
      "Epoch 28/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5812 - accuracy: 0.7464 - val_loss: 0.6149 - val_accuracy: 0.7372\n",
      "Epoch 29/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5805 - accuracy: 0.7486 - val_loss: 0.6125 - val_accuracy: 0.7328\n",
      "Epoch 30/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5777 - accuracy: 0.7480 - val_loss: 0.6163 - val_accuracy: 0.7341\n",
      "Epoch 31/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5763 - accuracy: 0.7477 - val_loss: 0.6104 - val_accuracy: 0.7373\n",
      "Epoch 32/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5744 - accuracy: 0.7493 - val_loss: 0.6100 - val_accuracy: 0.7438\n",
      "Epoch 33/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5718 - accuracy: 0.7494 - val_loss: 0.6201 - val_accuracy: 0.7302\n",
      "Epoch 34/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5702 - accuracy: 0.7508 - val_loss: 0.6143 - val_accuracy: 0.7358\n",
      "Epoch 35/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5667 - accuracy: 0.7513 - val_loss: 0.6055 - val_accuracy: 0.7383\n",
      "Epoch 36/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5650 - accuracy: 0.7535 - val_loss: 0.6174 - val_accuracy: 0.7360\n",
      "Epoch 37/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5658 - accuracy: 0.7532 - val_loss: 0.6104 - val_accuracy: 0.7350\n",
      "Epoch 38/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5617 - accuracy: 0.7542 - val_loss: 0.6149 - val_accuracy: 0.7341\n",
      "Epoch 39/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5600 - accuracy: 0.7533 - val_loss: 0.6051 - val_accuracy: 0.7356\n",
      "Epoch 40/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5585 - accuracy: 0.7550 - val_loss: 0.6002 - val_accuracy: 0.7413\n",
      "Epoch 41/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5603 - accuracy: 0.7551 - val_loss: 0.5948 - val_accuracy: 0.7442\n",
      "Epoch 42/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5556 - accuracy: 0.7557 - val_loss: 0.6133 - val_accuracy: 0.7386\n",
      "Epoch 43/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5539 - accuracy: 0.7572 - val_loss: 0.5963 - val_accuracy: 0.7390\n",
      "Epoch 44/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5540 - accuracy: 0.7578 - val_loss: 0.5984 - val_accuracy: 0.7413\n",
      "Epoch 45/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5493 - accuracy: 0.7604 - val_loss: 0.6497 - val_accuracy: 0.7357\n",
      "Epoch 46/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5483 - accuracy: 0.7587 - val_loss: 0.6113 - val_accuracy: 0.7399\n",
      "Epoch 47/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5474 - accuracy: 0.7586 - val_loss: 0.6140 - val_accuracy: 0.7382\n",
      "Epoch 48/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5462 - accuracy: 0.7620 - val_loss: 0.6014 - val_accuracy: 0.7413\n",
      "Epoch 49/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5430 - accuracy: 0.7641 - val_loss: 0.6039 - val_accuracy: 0.7382\n",
      "Epoch 50/50\n",
      "1370/1370 [==============================] - 12s 9ms/step - loss: 0.5422 - accuracy: 0.7625 - val_loss: 0.5933 - val_accuracy: 0.7465\n"
     ]
    }
   ],
   "source": [
    "# Create X and y for training and validation data\n",
    "training_X = training[[1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27]]\n",
    "training_y = training['Label']\n",
    "training_y_encoded = to_categorical(training_y)\n",
    "\n",
    "val_X = val[[1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27]]\n",
    "val_y = val['Label']\n",
    "val_y_encoded = to_categorical(val_y)\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "base_history = base_model.fit(training_X, training_y_encoded, epochs = 50, validation_data = (val_X, val_y_encoded), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "painful-austin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining a function for plotting training and validation learning curves\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_history(history):\n",
    "\t  # plot loss\n",
    "    plt.title('Loss')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_loss'], color='red', label='test')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()\n",
    "    \n",
    "    # plot accuracy\n",
    "    plt.title('Accuracy')\n",
    "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_accuracy'], color='red', label='test')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()\n",
    "  \n",
    "plot_history(base_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-stewart",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
