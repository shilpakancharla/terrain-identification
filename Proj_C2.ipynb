{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "confident-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics as st\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, LSTM\n",
    "from tensorflow.python.keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from keras.utils import to_categorical\n",
    "#!{sys.executable} -m pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-purple",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "anonymous-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Based on the training data given, we are able to extract 7 attributes:\n",
    "    1. x accelerometer measurement\n",
    "    2. y accelerometer measurement\n",
    "    3. z accelerometer measurement\n",
    "    4. x gyroscope measurement\n",
    "    5. y gyroscope measurement\n",
    "    6. z gyroscope measurement\n",
    "    7. time stamp for accelerometer and gyroscope measures\n",
    "    \n",
    "    We start by creating a dataframe using the csv files provided for readability.\n",
    "    \n",
    "    @param x_file: contains the xyz accelerometers and xyz gyroscope measures from the lower limb\n",
    "    @param x_time_file: contain the time stamps for the accelerometer and gyroscope measures\n",
    "    @return dataframe of 7 attributes mentioned\n",
    "\"\"\"\n",
    "def create_dataframe_X(x_file, x_time_file):\n",
    "    df1 = pd.read_csv(x_file, sep = ',', names = ['X_acc', 'Y_acc', 'Z_acc', 'X_gyr', 'Y_gyr', 'Z_gyr'])\n",
    "    df1 = scale_data(df1, ['X_acc', 'Y_acc', 'Z_acc', 'X_gyr', 'Y_gyr', 'Z_gyr'])\n",
    "    df2 = pd.read_csv(x_time_file, names = ['Time stamp'])\n",
    "    frames = [df1, df2]\n",
    "    result = pd.concat(frames, axis = 1)\n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "    Scale the values of X to make it robust to outliers.\n",
    "    \n",
    "    @param df: input dataframe\n",
    "    @param columns: columns to scale\n",
    "    @return scaled dataframe\n",
    "\"\"\"\n",
    "def scale_data(df, columns):\n",
    "    scaler = RobustScaler()\n",
    "    scaler = scaler.fit(df[columns])\n",
    "    df.loc[:, columns] = scaler.transform(df[columns])\n",
    "    return df\n",
    "    \n",
    "\"\"\"\n",
    "    We have both the labels and the time stamps for the labels. We create a dataframe from these for\n",
    "    readability.\n",
    "    \n",
    "    @param y_file: contain the labels: \n",
    "        (0) indicates standing or walking in solid ground, \n",
    "        (1) indicates going down the stairs, \n",
    "        (2) indicates going up the stairs, and \n",
    "        (3) indicates walking on grass\n",
    "    @param y_time_file: contain the time stamps for the labels\n",
    "    @return dataframe of labels and time stamps\n",
    "\"\"\" \n",
    "def create_dataframe_Y(y_file, y_time_file):\n",
    "    df1 = pd.read_csv(y_file, names = ['Label'])\n",
    "    df2 = pd.read_csv(y_time_file, names = ['Time stamp'])\n",
    "    frames = [df1, df2]\n",
    "    result = pd.concat(frames, axis = 1)\n",
    "    return result\n",
    "    \n",
    "\"\"\"\n",
    "    We take the outputs of create_dataframe_X and create_dataframe_Y. In order to combine both of these\n",
    "    dataframes, we need look at the time intervals present for when the labels were assigned. We down-sample\n",
    "    the X to the shape of the y.\n",
    "    \n",
    "    @param x_frame: dataframe from create_dataframe_X\n",
    "    @param y_frame: dataframe from create_dataframe_Y\n",
    "    @return dataframe with 9 columns (8 attributes and 1 label)\n",
    "\"\"\"\n",
    "def combine_frames(x_frame, y_frame):\n",
    "    # Change each dataframe column to a list for iterations\n",
    "    time_stamp_y = y_frame['Time stamp'].tolist()\n",
    "    time_stamp_x = x_frame['Time stamp'].tolist()\n",
    "    \n",
    "    x_range = [] # Empty list to append data points to\n",
    "    x_random_row = 0 # Initializing variable to hold randomly selected row instance\n",
    "    refs = []\n",
    "    count = 0\n",
    "    for i in range(0, len(time_stamp_y)):\n",
    "        while (time_stamp_x[count] <= time_stamp_y[i]) and (count <= len(time_stamp_x)):\n",
    "            x_range.append(time_stamp_x.index(time_stamp_x[count]))\n",
    "            count += 1\n",
    "        x_random_row = random.choice(x_range) # Pick a random value\n",
    "        refs.append(x_random_row) # Keep record of selected rows\n",
    "        x_range.clear() # Clear the cache\n",
    "        continue\n",
    "    \n",
    "    # Create a new dataframe based on the refs collected - should be roughly the same length as the y_frame\n",
    "    entries = []\n",
    "    for item in refs:\n",
    "        entry = x_frame.iloc[item]\n",
    "        entries.append(entry)\n",
    "    \n",
    "    found_df = pd.concat(entries, axis = 1)\n",
    "    found_df = found_df.transpose()\n",
    "    \n",
    "    # Combine found_df with y_frame for downsampling\n",
    "    found_df = found_df.reset_index()\n",
    "    found_df = found_df.drop(['index'], axis = 1)\n",
    "    found_df = found_df.drop(['Time stamp'], axis = 1)\n",
    "    combined_frame = pd.concat([found_df, y_frame], axis = 1)\n",
    "    return combined_frame\n",
    "\n",
    "\"\"\"\n",
    "    Takes in the sequential X and y and creates windows of time-series data.\n",
    "    \n",
    "    @param X: input data\n",
    "    @param y: label data\n",
    "    @param time_steps: determines size of window\n",
    "    @param step: incremental value that window will slide over\n",
    "    @return time series of X and y data\n",
    "\"\"\"\n",
    "def mode_labels(X, y, time_steps, step):\n",
    "    X_values = []\n",
    "    y_values = []\n",
    "    for i in range(0, len(X) - time_steps, step):\n",
    "        value = X.iloc[i:(i + time_steps)].values\n",
    "        labels = y.iloc[i: (i + time_steps)]\n",
    "        X_values.append(value)\n",
    "        y_values.append(stats.mode(labels)[0][0])\n",
    "    return np.array(X_values), np.array(y_values).reshape(-1, 1)\n",
    "\n",
    "\"\"\"\n",
    "    Generating data frames from training data.\n",
    "    \n",
    "    @param X_file: list of input X files\n",
    "    @param X_t_file: list of input X_time files\n",
    "    @param y_file: list of input y files\n",
    "    @param y_t file: list of y_time files\n",
    "    @return stacked window of instances across all training files, stack window of labels across all label files\n",
    "\"\"\"\n",
    "def generate_data(X_file, X_t_file, y_file, y_t_file):\n",
    "    all_X = []\n",
    "    all_y = []\n",
    "    for item_X, item_X_t, item_y, item_y_t in zip(X_file, X_t_file, y_file, y_t_file):\n",
    "        df_x = create_dataframe_X(item_X, item_X_t)\n",
    "        df_y = create_dataframe_Y(item_y, item_y_t)\n",
    "        combined_frame = combine_frames(df_x, df_y)\n",
    "        X_temp = combined_frame[['X_acc', 'Y_acc', 'Z_acc', 'X_gyr', 'Y_gyr', 'Z_gyr']]\n",
    "        y_temp = combined_frame['Label']\n",
    "        X, y = mode_labels(X_temp, y_temp, 30, 1)\n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "    return np.concatenate(all_X), np.concatenate(all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opposed-moment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301655, 30, 6) (301655, 1)\n",
      "(33762, 30, 6) (33762, 1)\n"
     ]
    }
   ],
   "source": [
    "# List of training X_files\n",
    "X_files = ['TrainingData/subject_001_01__x.csv', 'TrainingData/subject_001_02__x.csv', \n",
    "           'TrainingData/subject_001_03__x.csv', 'TrainingData/subject_001_04__x.csv',\n",
    "           'TrainingData/subject_001_05__x.csv', 'TrainingData/subject_001_06__x.csv',\n",
    "           'TrainingData/subject_001_07__x.csv', 'TrainingData/subject_001_08__x.csv',\n",
    "           'TrainingData/subject_002_01__x.csv', 'TrainingData/subject_002_02__x.csv',\n",
    "           'TrainingData/subject_002_03__x.csv', 'TrainingData/subject_001_04__x.csv',\n",
    "           'TrainingData/subject_002_05__x.csv', 'TrainingData/subject_003_01__x.csv',\n",
    "           'TrainingData/subject_005_01__x.csv', 'TrainingData/subject_005_02__x.csv',\n",
    "           'TrainingData/subject_005_03__x.csv', 'TrainingData/subject_006_01__x.csv',\n",
    "           'TrainingData/subject_006_02__x.csv', 'TrainingData/subject_006_03__x.csv',\n",
    "           'TrainingData/subject_007_01__x.csv', 'TrainingData/subject_007_02__x.csv',\n",
    "           'TrainingData/subject_007_03__x.csv', 'TrainingData/subject_007_04__x.csv',\n",
    "           'TrainingData/subject_008_01__x.csv']\n",
    "\n",
    "# List of training X_t_files\n",
    "X_t_files = ['TrainingData/subject_001_01__x_time.csv', 'TrainingData/subject_001_02__x_time.csv', \n",
    "             'TrainingData/subject_001_03__x_time.csv', 'TrainingData/subject_001_04__x_time.csv',\n",
    "             'TrainingData/subject_001_05__x_time.csv', 'TrainingData/subject_001_06__x_time.csv',\n",
    "             'TrainingData/subject_001_07__x_time.csv', 'TrainingData/subject_001_08__x_time.csv',\n",
    "             'TrainingData/subject_002_01__x_time.csv', 'TrainingData/subject_002_02__x_time.csv',\n",
    "             'TrainingData/subject_002_03__x_time.csv', 'TrainingData/subject_001_04__x_time.csv',\n",
    "             'TrainingData/subject_002_05__x_time.csv', 'TrainingData/subject_003_01__x_time.csv',\n",
    "             'TrainingData/subject_005_01__x_time.csv', 'TrainingData/subject_005_02__x_time.csv',\n",
    "             'TrainingData/subject_005_03__x_time.csv', 'TrainingData/subject_006_01__x_time.csv',\n",
    "             'TrainingData/subject_006_02__x_time.csv', 'TrainingData/subject_006_03__x_time.csv',\n",
    "             'TrainingData/subject_007_01__x_time.csv', 'TrainingData/subject_007_02__x_time.csv',\n",
    "             'TrainingData/subject_007_03__x_time.csv', 'TrainingData/subject_007_04__x_time.csv',\n",
    "             'TrainingData/subject_008_01__x_time.csv']\n",
    "\n",
    "# List of training y_files\n",
    "y_files = ['TrainingData/subject_001_01__y.csv', 'TrainingData/subject_001_02__y.csv', \n",
    "           'TrainingData/subject_001_03__y.csv', 'TrainingData/subject_001_04__y.csv',\n",
    "           'TrainingData/subject_001_05__y.csv', 'TrainingData/subject_001_06__y.csv',\n",
    "           'TrainingData/subject_001_07__y.csv', 'TrainingData/subject_001_08__y.csv',\n",
    "           'TrainingData/subject_002_01__y.csv', 'TrainingData/subject_002_02__y.csv',\n",
    "           'TrainingData/subject_002_03__y.csv', 'TrainingData/subject_001_04__y.csv',\n",
    "           'TrainingData/subject_002_05__y.csv', 'TrainingData/subject_003_01__y.csv',\n",
    "           'TrainingData/subject_005_01__y.csv', 'TrainingData/subject_005_02__y.csv',\n",
    "           'TrainingData/subject_005_03__y.csv', 'TrainingData/subject_006_01__y.csv',\n",
    "           'TrainingData/subject_006_02__y.csv', 'TrainingData/subject_006_03__y.csv',\n",
    "           'TrainingData/subject_007_01__y.csv', 'TrainingData/subject_007_02__y.csv',\n",
    "           'TrainingData/subject_007_03__y.csv', 'TrainingData/subject_007_04__y.csv',\n",
    "           'TrainingData/subject_008_01__y.csv']\n",
    "\n",
    "# List of training y_t_files\n",
    "y_t_files = ['TrainingData/subject_001_01__y_time.csv', 'TrainingData/subject_001_02__y_time.csv', \n",
    "             'TrainingData/subject_001_03__y_time.csv', 'TrainingData/subject_001_04__y_time.csv',\n",
    "             'TrainingData/subject_001_05__y_time.csv', 'TrainingData/subject_001_06__y_time.csv',\n",
    "             'TrainingData/subject_001_07__y_time.csv', 'TrainingData/subject_001_08__y_time.csv',\n",
    "             'TrainingData/subject_002_01__y_time.csv', 'TrainingData/subject_002_02__y_time.csv',\n",
    "             'TrainingData/subject_002_03__y_time.csv', 'TrainingData/subject_001_04__y_time.csv',\n",
    "             'TrainingData/subject_002_05__y_time.csv', 'TrainingData/subject_003_01__y_time.csv',\n",
    "             'TrainingData/subject_005_01__y_time.csv', 'TrainingData/subject_005_02__y_time.csv',\n",
    "             'TrainingData/subject_005_03__y_time.csv', 'TrainingData/subject_006_01__y_time.csv',\n",
    "             'TrainingData/subject_006_02__y_time.csv', 'TrainingData/subject_006_03__y_time.csv',\n",
    "             'TrainingData/subject_007_01__y_time.csv', 'TrainingData/subject_007_02__y_time.csv',\n",
    "             'TrainingData/subject_007_03__y_time.csv', 'TrainingData/subject_007_04__y_time.csv',\n",
    "             'TrainingData/subject_008_01__y_time.csv']\n",
    "\n",
    "# Use some files to create validation set\n",
    "val_X = ['TrainingData/subject_003_02__x.csv', 'TrainingData/subject_003_03__x.csv',\n",
    "         'TrainingData/subject_004_01__x.csv', 'TrainingData/subject_004_02__x.csv',]\n",
    "val_X_t = ['TrainingData/subject_003_02__x_time.csv', 'TrainingData/subject_003_03__x_time.csv',\n",
    "           'TrainingData/subject_004_01__x_time.csv', 'TrainingData/subject_004_02__x_time.csv',]\n",
    "val_y = ['TrainingData/subject_003_02__y.csv', 'TrainingData/subject_003_03__y.csv',\n",
    "         'TrainingData/subject_004_01__y.csv', 'TrainingData/subject_004_02__y.csv',]\n",
    "val_y_t = ['TrainingData/subject_003_02__y_time.csv', 'TrainingData/subject_003_03__y_time.csv',\n",
    "           'TrainingData/subject_004_01__y_time.csv', 'TrainingData/subject_004_02__y_time.csv',]\n",
    "\n",
    "# TODO: Create the test set\n",
    "#test_X = ['TestData/subject_009_01__x.csv', 'TestData/subject_010_01__x.csv',\n",
    "#          'TestData/subject_011_01__x.csv', 'TestData/subject_012_01__x.csv']\n",
    "#test_X_t = ['TestData/subject_009_01__x_time.csv', 'TestData/subject_010_01__x_time.csv',\n",
    "#           'TestData/subject_011_01__x_time.csv', 'TestData/subject_012_01__x_time.csv']\n",
    "\n",
    "training_X, training_y = generate_data(X_files, X_t_files, y_files, y_t_files)\n",
    "val_X, val_y = generate_data(val_X, val_X_t, val_y, val_y_t)\n",
    "print(training_X.shape, training_y.shape)\n",
    "print(val_X.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "legislative-combination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33593218 5.81133929 4.44263623 1.59734284]\n",
      "{0: 0.3359321754546953, 1: 5.811339292594591, 2: 4.442636229749632, 3: 1.5973428365669744}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1 2 3], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "label_weights = class_weight.compute_class_weight('balanced', np.unique(training_y), training_y.ravel())\n",
    "print(label_weights)\n",
    "label_weights = {i:label_weights[i] for i in range(len(label_weights))} # Create dictionary\n",
    "print(label_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "relative-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "encoder = encoder.fit(training_y)\n",
    "training_y_encoded = encoder.transform(training_y)\n",
    "val_y_encoded = encoder.transform(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "novel-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_measure(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_measure(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    precision = precision_measure(y_true, y_pred)\n",
    "    recall = recall_measure(y_true, y_pred)\n",
    "    return 2 * ((precision * recall)/(precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "annual-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps, n_features, n_outputs = training_X.shape[1], training_X.shape[2], training_y_encoded.shape[1]\n",
    "\n",
    "def define_LSTM_model(dropout_rate, l1_value, l2_value):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = 125, kernel_regularizer = regularizers.l1_l2(l1=l1_value, l2=l2_value),\n",
    "                   input_shape = (n_timesteps, n_features)))\n",
    "    model.add(Dropout(rate = dropout_rate))\n",
    "    model.add(Dense(units = 125, activation = 'relu'))\n",
    "    model.add(Dense(units = n_outputs, activation = 'softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', \n",
    "                  metrics = ['accuracy', f1, precision_measure, recall_measure])\n",
    "    return model\n",
    "    \n",
    "def evaluate_model(training_X, training_y_encoded, val_X, val_y_encoded, dropout_rate, l1_value, l2_value):\n",
    "    verbose, epochs, batch_size = 1, 15, 64\n",
    "    model = define_LSTM_model(dropout_rate, l1_value, l2_value)\n",
    "    model.summary()\n",
    "    # Fit network\n",
    "    history = model.fit(training_X, training_y_encoded, epochs = epochs, batch_size = batch_size, \n",
    "              validation_data = (val_X, val_y_encoded), class_weight = label_weights, verbose = verbose)\n",
    "    # Evaluate model\n",
    "    loss, accuracy, f1, precision, recall = model.evaluate(val_X, val_y_encoded, batch_size = batch_size, verbose = verbose)\n",
    "    return history, accuracy, f1, precision, recall\n",
    "\n",
    "# Defining a function for plotting training and validation learning curves\n",
    "def plot_history(history):\n",
    "\t# Plot loss\n",
    "    plt.title('Loss')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_loss'], color='red', label='test')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.title('Accuracy')\n",
    "    plt.plot(history.history['acc'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_acc'], color='red', label='test')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot F1\n",
    "    plt.title('Accuracy')\n",
    "    plt.plot(history.history['f1'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_f1'], color='red', label='test')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot precision\n",
    "    plt.title('Accuracy')\n",
    "    plt.plot(history.history['precision_measure'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_precision_measure'], color='red', label='test')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot recall\n",
    "    plt.title('Accuracy')\n",
    "    plt.plot(history.history['recall_measure'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_recall_measure'], color='red', label='test')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "optical-chemical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting  1 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 310s 1ms/step - loss: 0.7947 - acc: 0.5508 - f1: 0.4722 - precision_measure: 0.5823 - recall_measure: 0.4294 - val_loss: 0.8487 - val_acc: 0.5053 - val_f1: 0.4855 - val_precision_measure: 0.5074 - val_recall_measure: 0.4686\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 205s 680us/step - loss: 0.4590 - acc: 0.7079 - f1: 0.7024 - precision_measure: 0.7151 - recall_measure: 0.6903 - val_loss: 0.9917 - val_acc: 0.5042 - val_f1: 0.4989 - val_precision_measure: 0.5046 - val_recall_measure: 0.4938\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 203s 674us/step - loss: 0.3812 - acc: 0.7785 - f1: 0.7764 - precision_measure: 0.7840 - recall_measure: 0.7692 - val_loss: 0.7051 - val_acc: 0.7158 - val_f1: 0.7134 - val_precision_measure: 0.7201 - val_recall_measure: 0.7073\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 187s 620us/step - loss: 0.3316 - acc: 0.8185 - f1: 0.8176 - precision_measure: 0.8224 - recall_measure: 0.8128 - val_loss: 0.4614 - val_acc: 0.8180 - val_f1: 0.8177 - val_precision_measure: 0.8190 - val_recall_measure: 0.8164\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 197s 653us/step - loss: 0.2951 - acc: 0.8391 - f1: 0.8386 - precision_measure: 0.8414 - recall_measure: 0.8358 - val_loss: 0.4891 - val_acc: 0.8150 - val_f1: 0.8143 - val_precision_measure: 0.8162 - val_recall_measure: 0.8125\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 196s 649us/step - loss: 0.2744 - acc: 0.8517 - f1: 0.8514 - precision_measure: 0.8537 - recall_measure: 0.8491 - val_loss: 0.7023 - val_acc: 0.7045 - val_f1: 0.7034 - val_precision_measure: 0.7049 - val_recall_measure: 0.7019\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 197s 653us/step - loss: 0.2572 - acc: 0.8631 - f1: 0.8629 - precision_measure: 0.8647 - recall_measure: 0.8612 - val_loss: 0.4104 - val_acc: 0.8564 - val_f1: 0.8557 - val_precision_measure: 0.8567 - val_recall_measure: 0.8547\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.2420 - acc: 0.8719 - f1: 0.8717 - precision_measure: 0.8732 - recall_measure: 0.8703 - val_loss: 0.4160 - val_acc: 0.8549 - val_f1: 0.8548 - val_precision_measure: 0.8556 - val_recall_measure: 0.8540\n",
      "33762/33762 [==============================] - 7s 206us/step\n",
      "Fitting  2 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 225s 746us/step - loss: 0.7072 - acc: 0.5856 - f1: 0.5225 - precision_measure: 0.5997 - recall_measure: 0.4911 - val_loss: 0.6426 - val_acc: 0.6875 - val_f1: 0.6829 - val_precision_measure: 0.6901 - val_recall_measure: 0.6766\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 196s 651us/step - loss: 0.4395 - acc: 0.7176 - f1: 0.7138 - precision_measure: 0.7242 - recall_measure: 0.7038 - val_loss: 0.8535 - val_acc: 0.5804 - val_f1: 0.5677 - val_precision_measure: 0.5816 - val_recall_measure: 0.5560\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 197s 653us/step - loss: 0.3785 - acc: 0.7761 - f1: 0.7743 - precision_measure: 0.7815 - recall_measure: 0.7674 - val_loss: 0.8438 - val_acc: 0.5723 - val_f1: 0.5688 - val_precision_measure: 0.5726 - val_recall_measure: 0.5653\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 201s 666us/step - loss: 0.3338 - acc: 0.8074 - f1: 0.8067 - precision_measure: 0.8112 - recall_measure: 0.8023 - val_loss: 0.4895 - val_acc: 0.8215 - val_f1: 0.8203 - val_precision_measure: 0.8240 - val_recall_measure: 0.8168\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 197s 654us/step - loss: 0.3003 - acc: 0.8346 - f1: 0.8342 - precision_measure: 0.8376 - recall_measure: 0.8308 - val_loss: 0.4553 - val_acc: 0.8432 - val_f1: 0.8415 - val_precision_measure: 0.8446 - val_recall_measure: 0.8385\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 196s 650us/step - loss: 0.2740 - acc: 0.8496 - f1: 0.8494 - precision_measure: 0.8519 - recall_measure: 0.8470 - val_loss: 0.7482 - val_acc: 0.6999 - val_f1: 0.6991 - val_precision_measure: 0.7012 - val_recall_measure: 0.6971\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 234s 777us/step - loss: 0.2572 - acc: 0.8623 - f1: 0.8621 - precision_measure: 0.8641 - recall_measure: 0.8602 - val_loss: 0.4972 - val_acc: 0.8133 - val_f1: 0.8125 - val_precision_measure: 0.8143 - val_recall_measure: 0.8108\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 283s 937us/step - loss: 0.2342 - acc: 0.8759 - f1: 0.8760 - precision_measure: 0.8773 - recall_measure: 0.8747 - val_loss: 0.4609 - val_acc: 0.8369 - val_f1: 0.8364 - val_precision_measure: 0.8382 - val_recall_measure: 0.8348\n",
      "33762/33762 [==============================] - 7s 214us/step\n",
      "Fitting  3 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 231s 766us/step - loss: 0.7348 - acc: 0.5559 - f1: 0.4904 - precision_measure: 0.5817 - recall_measure: 0.4544 - val_loss: 0.8335 - val_acc: 0.5097 - val_f1: 0.5034 - val_precision_measure: 0.5103 - val_recall_measure: 0.4974\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 223s 739us/step - loss: 0.4639 - acc: 0.6493 - f1: 0.6431 - precision_measure: 0.6548 - recall_measure: 0.6320 - val_loss: 0.8544 - val_acc: 0.5386 - val_f1: 0.5305 - val_precision_measure: 0.5404 - val_recall_measure: 0.5219\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 208s 691us/step - loss: 0.4186 - acc: 0.7096 - f1: 0.7058 - precision_measure: 0.7148 - recall_measure: 0.6972 - val_loss: 0.6681 - val_acc: 0.6905 - val_f1: 0.6887 - val_precision_measure: 0.6927 - val_recall_measure: 0.6850\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 207s 686us/step - loss: 0.3662 - acc: 0.7768 - f1: 0.7751 - precision_measure: 0.7810 - recall_measure: 0.7694 - val_loss: 0.5470 - val_acc: 0.7772 - val_f1: 0.7742 - val_precision_measure: 0.7792 - val_recall_measure: 0.7696\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 198s 656us/step - loss: 0.3232 - acc: 0.8165 - f1: 0.8156 - precision_measure: 0.8199 - recall_measure: 0.8115 - val_loss: 0.4814 - val_acc: 0.8286 - val_f1: 0.8276 - val_precision_measure: 0.8312 - val_recall_measure: 0.8242\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 243s 807us/step - loss: 0.2958 - acc: 0.8367 - f1: 0.8361 - precision_measure: 0.8394 - recall_measure: 0.8328 - val_loss: 0.5085 - val_acc: 0.8013 - val_f1: 0.7996 - val_precision_measure: 0.8041 - val_recall_measure: 0.7955\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 204s 675us/step - loss: 0.2756 - acc: 0.8500 - f1: 0.8496 - precision_measure: 0.8519 - recall_measure: 0.8474 - val_loss: 0.4733 - val_acc: 0.8363 - val_f1: 0.8346 - val_precision_measure: 0.8379 - val_recall_measure: 0.8314\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 205s 680us/step - loss: 0.2592 - acc: 0.8596 - f1: 0.8594 - precision_measure: 0.8611 - recall_measure: 0.8578 - val_loss: 0.5783 - val_acc: 0.7806 - val_f1: 0.7799 - val_precision_measure: 0.7815 - val_recall_measure: 0.7782\n",
      "33762/33762 [==============================] - 7s 216us/step\n",
      "Fitting  4 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 203s 674us/step - loss: 0.7483 - acc: 0.5383 - f1: 0.4717 - precision_measure: 0.5620 - recall_measure: 0.4357 - val_loss: 0.9708 - val_acc: 0.3608 - val_f1: 0.3498 - val_precision_measure: 0.3632 - val_recall_measure: 0.3390\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 196s 650us/step - loss: 0.4705 - acc: 0.6510 - f1: 0.6448 - precision_measure: 0.6595 - recall_measure: 0.6311 - val_loss: 0.9347 - val_acc: 0.4164 - val_f1: 0.4151 - val_precision_measure: 0.4181 - val_recall_measure: 0.4124\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 208s 689us/step - loss: 0.3862 - acc: 0.7650 - f1: 0.7629 - precision_measure: 0.7711 - recall_measure: 0.7550 - val_loss: 0.5144 - val_acc: 0.8040 - val_f1: 0.8025 - val_precision_measure: 0.8072 - val_recall_measure: 0.7983\n",
      "Epoch 4/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 185s 614us/step - loss: 0.3354 - acc: 0.8140 - f1: 0.8129 - precision_measure: 0.8188 - recall_measure: 0.8072 - val_loss: 0.5623 - val_acc: 0.7681 - val_f1: 0.7674 - val_precision_measure: 0.7696 - val_recall_measure: 0.7654\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 186s 618us/step - loss: 0.3014 - acc: 0.8364 - f1: 0.8359 - precision_measure: 0.8398 - recall_measure: 0.8320 - val_loss: 0.3944 - val_acc: 0.8846 - val_f1: 0.8833 - val_precision_measure: 0.8864 - val_recall_measure: 0.8804\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 188s 623us/step - loss: 0.2718 - acc: 0.8556 - f1: 0.8552 - precision_measure: 0.8578 - recall_measure: 0.8528 - val_loss: 0.5374 - val_acc: 0.7941 - val_f1: 0.7936 - val_precision_measure: 0.7951 - val_recall_measure: 0.7923\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 191s 633us/step - loss: 0.2488 - acc: 0.8698 - f1: 0.8697 - precision_measure: 0.8715 - recall_measure: 0.8680 - val_loss: 0.4683 - val_acc: 0.8460 - val_f1: 0.8459 - val_precision_measure: 0.8465 - val_recall_measure: 0.8453\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 195s 647us/step - loss: 0.2292 - acc: 0.8833 - f1: 0.8832 - precision_measure: 0.8845 - recall_measure: 0.8820 - val_loss: 0.3601 - val_acc: 0.8934 - val_f1: 0.8930 - val_precision_measure: 0.8947 - val_recall_measure: 0.8914\n",
      "33762/33762 [==============================] - 6s 190us/step\n",
      "Fitting  5 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 199s 659us/step - loss: 0.6567 - acc: 0.5739 - f1: 0.5259 - precision_measure: 0.5943 - recall_measure: 0.4953 - val_loss: 0.7781 - val_acc: 0.6219 - val_f1: 0.6120 - val_precision_measure: 0.6253 - val_recall_measure: 0.6006\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.4089 - acc: 0.7464 - f1: 0.7423 - precision_measure: 0.7531 - recall_measure: 0.7321 - val_loss: 0.6919 - val_acc: 0.7011 - val_f1: 0.6979 - val_precision_measure: 0.7045 - val_recall_measure: 0.6920\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 202s 671us/step - loss: 0.3552 - acc: 0.7945 - f1: 0.7927 - precision_measure: 0.7999 - recall_measure: 0.7857 - val_loss: 0.7686 - val_acc: 0.6386 - val_f1: 0.6337 - val_precision_measure: 0.6412 - val_recall_measure: 0.6271\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 189s 628us/step - loss: 0.3207 - acc: 0.8201 - f1: 0.8191 - precision_measure: 0.8241 - recall_measure: 0.8142 - val_loss: 0.5990 - val_acc: 0.7945 - val_f1: 0.7929 - val_precision_measure: 0.7979 - val_recall_measure: 0.7883\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 190s 630us/step - loss: 0.2891 - acc: 0.8389 - f1: 0.8383 - precision_measure: 0.8420 - recall_measure: 0.8347 - val_loss: 0.4827 - val_acc: 0.8043 - val_f1: 0.8034 - val_precision_measure: 0.8064 - val_recall_measure: 0.8006\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 192s 637us/step - loss: 0.2624 - acc: 0.8556 - f1: 0.8553 - precision_measure: 0.8578 - recall_measure: 0.8529 - val_loss: 0.4191 - val_acc: 0.8654 - val_f1: 0.8634 - val_precision_measure: 0.8666 - val_recall_measure: 0.8605\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 190s 629us/step - loss: 0.2473 - acc: 0.8638 - f1: 0.8637 - precision_measure: 0.8657 - recall_measure: 0.8617 - val_loss: 0.4594 - val_acc: 0.8383 - val_f1: 0.8374 - val_precision_measure: 0.8400 - val_recall_measure: 0.8350\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.2266 - acc: 0.8764 - f1: 0.8763 - precision_measure: 0.8776 - recall_measure: 0.8750 - val_loss: 0.7031 - val_acc: 0.7361 - val_f1: 0.7359 - val_precision_measure: 0.7374 - val_recall_measure: 0.7344\n",
      "33762/33762 [==============================] - 7s 202us/step\n",
      "Fitting  6 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 198s 656us/step - loss: 0.6640 - acc: 0.5976 - f1: 0.5410 - precision_measure: 0.6151 - recall_measure: 0.5098 - val_loss: 0.9544 - val_acc: 0.5076 - val_f1: 0.5011 - val_precision_measure: 0.5080 - val_recall_measure: 0.4951\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 196s 651us/step - loss: 0.4105 - acc: 0.7369 - f1: 0.7332 - precision_measure: 0.7429 - recall_measure: 0.7240 - val_loss: 1.0905 - val_acc: 0.5202 - val_f1: 0.5087 - val_precision_measure: 0.5213 - val_recall_measure: 0.4983\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 197s 652us/step - loss: 0.3491 - acc: 0.7900 - f1: 0.7888 - precision_measure: 0.7947 - recall_measure: 0.7830 - val_loss: 0.6643 - val_acc: 0.7095 - val_f1: 0.7079 - val_precision_measure: 0.7113 - val_recall_measure: 0.7047\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 199s 661us/step - loss: 0.3097 - acc: 0.8224 - f1: 0.8216 - precision_measure: 0.8255 - recall_measure: 0.8179 - val_loss: 0.5005 - val_acc: 0.8136 - val_f1: 0.8114 - val_precision_measure: 0.8175 - val_recall_measure: 0.8058\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 203s 672us/step - loss: 0.2817 - acc: 0.8407 - f1: 0.8403 - precision_measure: 0.8432 - recall_measure: 0.8376 - val_loss: 0.5901 - val_acc: 0.7433 - val_f1: 0.7414 - val_precision_measure: 0.7442 - val_recall_measure: 0.7388\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 199s 659us/step - loss: 0.2596 - acc: 0.8577 - f1: 0.8575 - precision_measure: 0.8597 - recall_measure: 0.8553 - val_loss: 0.6703 - val_acc: 0.7288 - val_f1: 0.7260 - val_precision_measure: 0.7307 - val_recall_measure: 0.7217\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 204s 678us/step - loss: 0.2407 - acc: 0.8687 - f1: 0.8685 - precision_measure: 0.8702 - recall_measure: 0.8669 - val_loss: 0.5445 - val_acc: 0.7821 - val_f1: 0.7817 - val_precision_measure: 0.7828 - val_recall_measure: 0.7806\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 200s 661us/step - loss: 0.2252 - acc: 0.8784 - f1: 0.8783 - precision_measure: 0.8795 - recall_measure: 0.8770 - val_loss: 0.5144 - val_acc: 0.8031 - val_f1: 0.8014 - val_precision_measure: 0.8047 - val_recall_measure: 0.7982\n",
      "33762/33762 [==============================] - 7s 194us/step\n",
      "Fitting  7 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 201s 666us/step - loss: 0.6124 - acc: 0.6075 - f1: 0.5649 - precision_measure: 0.6201 - recall_measure: 0.5388 - val_loss: 0.8679 - val_acc: 0.4882 - val_f1: 0.4757 - val_precision_measure: 0.4886 - val_recall_measure: 0.4650\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 199s 659us/step - loss: 0.3883 - acc: 0.7635 - f1: 0.7607 - precision_measure: 0.7696 - recall_measure: 0.7522 - val_loss: 0.4268 - val_acc: 0.8784 - val_f1: 0.8759 - val_precision_measure: 0.8811 - val_recall_measure: 0.8711\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 210s 696us/step - loss: 0.3299 - acc: 0.8119 - f1: 0.8107 - precision_measure: 0.8160 - recall_measure: 0.8055 - val_loss: 0.6338 - val_acc: 0.7236 - val_f1: 0.7206 - val_precision_measure: 0.7261 - val_recall_measure: 0.7157\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 201s 668us/step - loss: 0.2926 - acc: 0.8364 - f1: 0.8359 - precision_measure: 0.8394 - recall_measure: 0.8325 - val_loss: 0.6078 - val_acc: 0.7676 - val_f1: 0.7669 - val_precision_measure: 0.7689 - val_recall_measure: 0.7651\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 202s 668us/step - loss: 0.2662 - acc: 0.8533 - f1: 0.8530 - precision_measure: 0.8555 - recall_measure: 0.8505 - val_loss: 0.5708 - val_acc: 0.7771 - val_f1: 0.7752 - val_precision_measure: 0.7789 - val_recall_measure: 0.7717\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 203s 674us/step - loss: 0.2411 - acc: 0.8680 - f1: 0.8677 - precision_measure: 0.8695 - recall_measure: 0.8660 - val_loss: 0.2982 - val_acc: 0.9194 - val_f1: 0.9190 - val_precision_measure: 0.9201 - val_recall_measure: 0.9179\n",
      "Epoch 7/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 204s 677us/step - loss: 0.2204 - acc: 0.8794 - f1: 0.8793 - precision_measure: 0.8805 - recall_measure: 0.8780 - val_loss: 0.6791 - val_acc: 0.7359 - val_f1: 0.7352 - val_precision_measure: 0.7368 - val_recall_measure: 0.7337\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.2088 - acc: 0.8876 - f1: 0.8875 - precision_measure: 0.8888 - recall_measure: 0.8864 - val_loss: 0.4178 - val_acc: 0.8638 - val_f1: 0.8636 - val_precision_measure: 0.8642 - val_recall_measure: 0.8630\n",
      "33762/33762 [==============================] - 8s 243us/step\n",
      "Fitting  8 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 193s 641us/step - loss: 0.6156 - acc: 0.6066 - f1: 0.5579 - precision_measure: 0.6166 - recall_measure: 0.5311 - val_loss: 0.6634 - val_acc: 0.6733 - val_f1: 0.6656 - val_precision_measure: 0.6779 - val_recall_measure: 0.6552\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 194s 643us/step - loss: 0.3720 - acc: 0.7790 - f1: 0.7768 - precision_measure: 0.7852 - recall_measure: 0.7687 - val_loss: 0.4802 - val_acc: 0.8307 - val_f1: 0.8282 - val_precision_measure: 0.8333 - val_recall_measure: 0.8234\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 201s 668us/step - loss: 0.3195 - acc: 0.8212 - f1: 0.8204 - precision_measure: 0.8258 - recall_measure: 0.8153 - val_loss: 0.4169 - val_acc: 0.8621 - val_f1: 0.8612 - val_precision_measure: 0.8651 - val_recall_measure: 0.8577\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 211s 701us/step - loss: 0.2858 - acc: 0.8429 - f1: 0.8426 - precision_measure: 0.8462 - recall_measure: 0.8391 - val_loss: 0.4996 - val_acc: 0.8132 - val_f1: 0.8122 - val_precision_measure: 0.8143 - val_recall_measure: 0.8102\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 197s 652us/step - loss: 0.2613 - acc: 0.8583 - f1: 0.8582 - precision_measure: 0.8604 - recall_measure: 0.8561 - val_loss: 0.3570 - val_acc: 0.8887 - val_f1: 0.8883 - val_precision_measure: 0.8894 - val_recall_measure: 0.8873\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 202s 669us/step - loss: 0.2375 - acc: 0.8710 - f1: 0.8709 - precision_measure: 0.8724 - recall_measure: 0.8693 - val_loss: 0.3688 - val_acc: 0.8711 - val_f1: 0.8711 - val_precision_measure: 0.8720 - val_recall_measure: 0.8703\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 199s 659us/step - loss: 0.2216 - acc: 0.8820 - f1: 0.8820 - precision_measure: 0.8832 - recall_measure: 0.8808 - val_loss: 0.3639 - val_acc: 0.8880 - val_f1: 0.8878 - val_precision_measure: 0.8890 - val_recall_measure: 0.8866\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 194s 645us/step - loss: 0.2050 - acc: 0.8919 - f1: 0.8918 - precision_measure: 0.8927 - recall_measure: 0.8910 - val_loss: 0.4478 - val_acc: 0.8375 - val_f1: 0.8372 - val_precision_measure: 0.8384 - val_recall_measure: 0.8361\n",
      "33762/33762 [==============================] - 8s 225us/step\n",
      "Fitting  9 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 209s 693us/step - loss: 0.5876 - acc: 0.5971 - f1: 0.5583 - precision_measure: 0.6092 - recall_measure: 0.5318 - val_loss: 0.8561 - val_acc: 0.5654 - val_f1: 0.5595 - val_precision_measure: 0.5673 - val_recall_measure: 0.5526\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 200s 664us/step - loss: 0.3808 - acc: 0.7603 - f1: 0.7572 - precision_measure: 0.7665 - recall_measure: 0.7482 - val_loss: 0.6005 - val_acc: 0.7420 - val_f1: 0.7369 - val_precision_measure: 0.7446 - val_recall_measure: 0.7300\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 263s 873us/step - loss: 0.3180 - acc: 0.8152 - f1: 0.8140 - precision_measure: 0.8201 - recall_measure: 0.8081 - val_loss: 0.3482 - val_acc: 0.8918 - val_f1: 0.8913 - val_precision_measure: 0.8942 - val_recall_measure: 0.8886\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 242s 804us/step - loss: 0.2816 - acc: 0.8394 - f1: 0.8388 - precision_measure: 0.8430 - recall_measure: 0.8348 - val_loss: 0.3774 - val_acc: 0.8708 - val_f1: 0.8696 - val_precision_measure: 0.8729 - val_recall_measure: 0.8666\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 261s 866us/step - loss: 0.2529 - acc: 0.8582 - f1: 0.8579 - precision_measure: 0.8606 - recall_measure: 0.8552 - val_loss: 0.3456 - val_acc: 0.8859 - val_f1: 0.8853 - val_precision_measure: 0.8882 - val_recall_measure: 0.8826\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 206s 682us/step - loss: 0.2315 - acc: 0.8714 - f1: 0.8712 - precision_measure: 0.8731 - recall_measure: 0.8693 - val_loss: 0.4907 - val_acc: 0.8061 - val_f1: 0.8049 - val_precision_measure: 0.8070 - val_recall_measure: 0.8031\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 202s 669us/step - loss: 0.2084 - acc: 0.8830 - f1: 0.8828 - precision_measure: 0.8841 - recall_measure: 0.8816 - val_loss: 0.4044 - val_acc: 0.8473 - val_f1: 0.8468 - val_precision_measure: 0.8477 - val_recall_measure: 0.8460\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 260s 863us/step - loss: 0.1935 - acc: 0.8935 - f1: 0.8934 - precision_measure: 0.8942 - recall_measure: 0.8926 - val_loss: 0.5411 - val_acc: 0.7989 - val_f1: 0.7988 - val_precision_measure: 0.7996 - val_recall_measure: 0.7981\n",
      "33762/33762 [==============================] - 8s 237us/step\n",
      "Fitting  10 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 210s 696us/step - loss: 0.5775 - acc: 0.5974 - f1: 0.5649 - precision_measure: 0.6093 - recall_measure: 0.5401 - val_loss: 0.7697 - val_acc: 0.5897 - val_f1: 0.5819 - val_precision_measure: 0.5912 - val_recall_measure: 0.5735\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 198s 658us/step - loss: 0.3572 - acc: 0.7914 - f1: 0.7891 - precision_measure: 0.7969 - recall_measure: 0.7816 - val_loss: 0.8890 - val_acc: 0.5718 - val_f1: 0.5663 - val_precision_measure: 0.5741 - val_recall_measure: 0.5597\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 218s 722us/step - loss: 0.3051 - acc: 0.8272 - f1: 0.8265 - precision_measure: 0.8314 - recall_measure: 0.8218 - val_loss: 0.5575 - val_acc: 0.7766 - val_f1: 0.7750 - val_precision_measure: 0.7786 - val_recall_measure: 0.7716\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 203s 674us/step - loss: 0.2758 - acc: 0.8475 - f1: 0.8471 - precision_measure: 0.8504 - recall_measure: 0.8438 - val_loss: 0.4938 - val_acc: 0.8078 - val_f1: 0.8043 - val_precision_measure: 0.8093 - val_recall_measure: 0.7997\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 204s 676us/step - loss: 0.2507 - acc: 0.8609 - f1: 0.8607 - precision_measure: 0.8632 - recall_measure: 0.8582 - val_loss: 0.4179 - val_acc: 0.8308 - val_f1: 0.8301 - val_precision_measure: 0.8327 - val_recall_measure: 0.8276\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 308s 1ms/step - loss: 0.2268 - acc: 0.8734 - f1: 0.8733 - precision_measure: 0.8749 - recall_measure: 0.8717 - val_loss: 0.4346 - val_acc: 0.8364 - val_f1: 0.8362 - val_precision_measure: 0.8369 - val_recall_measure: 0.8355\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 228s 757us/step - loss: 0.2109 - acc: 0.8835 - f1: 0.8834 - precision_measure: 0.8846 - recall_measure: 0.8821 - val_loss: 0.5181 - val_acc: 0.8087 - val_f1: 0.8083 - val_precision_measure: 0.8096 - val_recall_measure: 0.8071\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 206s 684us/step - loss: 0.1956 - acc: 0.8921 - f1: 0.8921 - precision_measure: 0.8930 - recall_measure: 0.8912 - val_loss: 0.4487 - val_acc: 0.8298 - val_f1: 0.8295 - val_precision_measure: 0.8299 - val_recall_measure: 0.8290\n",
      "33762/33762 [==============================] - 8s 243us/step\n",
      "Fitting  11 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 205s 681us/step - loss: 0.5675 - acc: 0.6496 - f1: 0.6233 - precision_measure: 0.6669 - recall_measure: 0.5983 - val_loss: 0.8392 - val_acc: 0.5906 - val_f1: 0.5802 - val_precision_measure: 0.5929 - val_recall_measure: 0.5693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 194s 644us/step - loss: 0.3569 - acc: 0.8004 - f1: 0.7987 - precision_measure: 0.8072 - recall_measure: 0.7905 - val_loss: 0.7583 - val_acc: 0.6407 - val_f1: 0.6378 - val_precision_measure: 0.6426 - val_recall_measure: 0.6334\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 188s 622us/step - loss: 0.3059 - acc: 0.8308 - f1: 0.8302 - precision_measure: 0.8357 - recall_measure: 0.8249 - val_loss: 0.5916 - val_acc: 0.7559 - val_f1: 0.7519 - val_precision_measure: 0.7592 - val_recall_measure: 0.7454\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 189s 627us/step - loss: 0.2744 - acc: 0.8487 - f1: 0.8483 - precision_measure: 0.8521 - recall_measure: 0.8446 - val_loss: 0.5372 - val_acc: 0.7806 - val_f1: 0.7791 - val_precision_measure: 0.7840 - val_recall_measure: 0.7746\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 186s 617us/step - loss: 0.2481 - acc: 0.8639 - f1: 0.8637 - precision_measure: 0.8662 - recall_measure: 0.8612 - val_loss: 0.5915 - val_acc: 0.7558 - val_f1: 0.7549 - val_precision_measure: 0.7579 - val_recall_measure: 0.7522\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 226s 749us/step - loss: 0.2288 - acc: 0.8743 - f1: 0.8742 - precision_measure: 0.8759 - recall_measure: 0.8726 - val_loss: 0.5354 - val_acc: 0.7885 - val_f1: 0.7881 - val_precision_measure: 0.7903 - val_recall_measure: 0.7860\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 245s 811us/step - loss: 0.2125 - acc: 0.8853 - f1: 0.8852 - precision_measure: 0.8865 - recall_measure: 0.8840 - val_loss: 0.5223 - val_acc: 0.7889 - val_f1: 0.7884 - val_precision_measure: 0.7901 - val_recall_measure: 0.7867\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 223s 741us/step - loss: 0.1931 - acc: 0.8957 - f1: 0.8957 - precision_measure: 0.8966 - recall_measure: 0.8949 - val_loss: 0.4704 - val_acc: 0.8200 - val_f1: 0.8196 - val_precision_measure: 0.8206 - val_recall_measure: 0.8186\n",
      "33762/33762 [==============================] - 8s 248us/step\n",
      "Fitting  12 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 211s 701us/step - loss: 0.5597 - acc: 0.6233 - f1: 0.5959 - precision_measure: 0.6405 - recall_measure: 0.5723 - val_loss: 0.8829 - val_acc: 0.5631 - val_f1: 0.5525 - val_precision_measure: 0.5649 - val_recall_measure: 0.5421\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 206s 683us/step - loss: 0.3440 - acc: 0.7967 - f1: 0.7952 - precision_measure: 0.8021 - recall_measure: 0.7885 - val_loss: 0.8648 - val_acc: 0.6014 - val_f1: 0.5996 - val_precision_measure: 0.6045 - val_recall_measure: 0.5951\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 203s 675us/step - loss: 0.2930 - acc: 0.8372 - f1: 0.8367 - precision_measure: 0.8405 - recall_measure: 0.8330 - val_loss: 0.4614 - val_acc: 0.8218 - val_f1: 0.8213 - val_precision_measure: 0.8232 - val_recall_measure: 0.8195\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 228s 755us/step - loss: 0.2582 - acc: 0.8570 - f1: 0.8567 - precision_measure: 0.8591 - recall_measure: 0.8543 - val_loss: 0.5768 - val_acc: 0.7778 - val_f1: 0.7776 - val_precision_measure: 0.7792 - val_recall_measure: 0.7762\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 245s 813us/step - loss: 0.2333 - acc: 0.8722 - f1: 0.8720 - precision_measure: 0.8735 - recall_measure: 0.8705 - val_loss: 0.5171 - val_acc: 0.8085 - val_f1: 0.8076 - val_precision_measure: 0.8094 - val_recall_measure: 0.8059\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 290s 963us/step - loss: 0.2135 - acc: 0.8845 - f1: 0.8844 - precision_measure: 0.8856 - recall_measure: 0.8833 - val_loss: 0.4898 - val_acc: 0.7971 - val_f1: 0.7967 - val_precision_measure: 0.7983 - val_recall_measure: 0.7952\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 283s 939us/step - loss: 0.1912 - acc: 0.8980 - f1: 0.8979 - precision_measure: 0.8986 - recall_measure: 0.8971 - val_loss: 0.7845 - val_acc: 0.7172 - val_f1: 0.7166 - val_precision_measure: 0.7180 - val_recall_measure: 0.7153\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 260s 861us/step - loss: 0.1776 - acc: 0.9087 - f1: 0.9087 - precision_measure: 0.9093 - recall_measure: 0.9081 - val_loss: 0.4200 - val_acc: 0.8510 - val_f1: 0.8504 - val_precision_measure: 0.8521 - val_recall_measure: 0.8489\n",
      "33762/33762 [==============================] - 9s 253us/step\n",
      "Fitting  13 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 235s 780us/step - loss: 0.5459 - acc: 0.6204 - f1: 0.5965 - precision_measure: 0.6355 - recall_measure: 0.5727 - val_loss: 0.5466 - val_acc: 0.7915 - val_f1: 0.7881 - val_precision_measure: 0.7966 - val_recall_measure: 0.7805\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 195s 645us/step - loss: 0.3516 - acc: 0.7872 - f1: 0.7853 - precision_measure: 0.7934 - recall_measure: 0.7776 - val_loss: 0.9239 - val_acc: 0.6096 - val_f1: 0.6064 - val_precision_measure: 0.6115 - val_recall_measure: 0.6018\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 197s 653us/step - loss: 0.2931 - acc: 0.8309 - f1: 0.8302 - precision_measure: 0.8352 - recall_measure: 0.8253 - val_loss: 0.5350 - val_acc: 0.7808 - val_f1: 0.7796 - val_precision_measure: 0.7830 - val_recall_measure: 0.7765\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 203s 673us/step - loss: 0.2666 - acc: 0.8526 - f1: 0.8521 - precision_measure: 0.8558 - recall_measure: 0.8486 - val_loss: 0.2646 - val_acc: 0.9209 - val_f1: 0.9209 - val_precision_measure: 0.9222 - val_recall_measure: 0.9198\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 200s 662us/step - loss: 0.2355 - acc: 0.8672 - f1: 0.8670 - precision_measure: 0.8691 - recall_measure: 0.8649 - val_loss: 0.4202 - val_acc: 0.8445 - val_f1: 0.8438 - val_precision_measure: 0.8453 - val_recall_measure: 0.8425\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 195s 645us/step - loss: 0.2180 - acc: 0.8769 - f1: 0.8768 - precision_measure: 0.8785 - recall_measure: 0.8752 - val_loss: 0.5042 - val_acc: 0.8080 - val_f1: 0.8076 - val_precision_measure: 0.8089 - val_recall_measure: 0.8064\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 198s 655us/step - loss: 0.2027 - acc: 0.8865 - f1: 0.8864 - precision_measure: 0.8877 - recall_measure: 0.8852 - val_loss: 0.4735 - val_acc: 0.8266 - val_f1: 0.8265 - val_precision_measure: 0.8278 - val_recall_measure: 0.8252\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 196s 651us/step - loss: 0.1852 - acc: 0.8977 - f1: 0.8977 - precision_measure: 0.8986 - recall_measure: 0.8968 - val_loss: 0.4668 - val_acc: 0.8314 - val_f1: 0.8310 - val_precision_measure: 0.8324 - val_recall_measure: 0.8297\n",
      "33762/33762 [==============================] - 7s 222us/step\n",
      "Fitting  14 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 209s 693us/step - loss: 0.5358 - acc: 0.6591 - f1: 0.6346 - precision_measure: 0.6741 - recall_measure: 0.6111 - val_loss: 0.7107 - val_acc: 0.6656 - val_f1: 0.6548 - val_precision_measure: 0.6706 - val_recall_measure: 0.6418\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 194s 645us/step - loss: 0.3372 - acc: 0.8087 - f1: 0.8073 - precision_measure: 0.8150 - recall_measure: 0.7999 - val_loss: 0.5695 - val_acc: 0.7745 - val_f1: 0.7708 - val_precision_measure: 0.7788 - val_recall_measure: 0.7637\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 202s 671us/step - loss: 0.2819 - acc: 0.8415 - f1: 0.8411 - precision_measure: 0.8452 - recall_measure: 0.8370 - val_loss: 0.6197 - val_acc: 0.7261 - val_f1: 0.7244 - val_precision_measure: 0.7272 - val_recall_measure: 0.7219\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 200s 664us/step - loss: 0.2509 - acc: 0.8587 - f1: 0.8586 - precision_measure: 0.8613 - recall_measure: 0.8559 - val_loss: 0.5930 - val_acc: 0.7636 - val_f1: 0.7620 - val_precision_measure: 0.7660 - val_recall_measure: 0.7582\n",
      "Epoch 5/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 180s 597us/step - loss: 0.2268 - acc: 0.8715 - f1: 0.8713 - precision_measure: 0.8734 - recall_measure: 0.8692 - val_loss: 0.5144 - val_acc: 0.7965 - val_f1: 0.7962 - val_precision_measure: 0.7974 - val_recall_measure: 0.7951\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 180s 595us/step - loss: 0.2074 - acc: 0.8822 - f1: 0.8821 - precision_measure: 0.8837 - recall_measure: 0.8807 - val_loss: 0.2834 - val_acc: 0.9091 - val_f1: 0.9091 - val_precision_measure: 0.9104 - val_recall_measure: 0.9080\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 176s 583us/step - loss: 0.1898 - acc: 0.8935 - f1: 0.8935 - precision_measure: 0.8946 - recall_measure: 0.8924 - val_loss: 0.4796 - val_acc: 0.8296 - val_f1: 0.8296 - val_precision_measure: 0.8308 - val_recall_measure: 0.8284\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 176s 585us/step - loss: 0.1756 - acc: 0.9037 - f1: 0.9036 - precision_measure: 0.9046 - recall_measure: 0.9027 - val_loss: 0.4251 - val_acc: 0.8306 - val_f1: 0.8304 - val_precision_measure: 0.8311 - val_recall_measure: 0.8297\n",
      "33762/33762 [==============================] - 6s 179us/step\n",
      "Fitting  15 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 179s 593us/step - loss: 0.5136 - acc: 0.6699 - f1: 0.6498 - precision_measure: 0.6827 - recall_measure: 0.6291 - val_loss: 0.6726 - val_acc: 0.6708 - val_f1: 0.6679 - val_precision_measure: 0.6733 - val_recall_measure: 0.6629\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 178s 590us/step - loss: 0.3187 - acc: 0.8200 - f1: 0.8188 - precision_measure: 0.8249 - recall_measure: 0.8129 - val_loss: 0.5814 - val_acc: 0.7780 - val_f1: 0.7743 - val_precision_measure: 0.7821 - val_recall_measure: 0.7674\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.2697 - acc: 0.8502 - f1: 0.8499 - precision_measure: 0.8536 - recall_measure: 0.8462 - val_loss: 0.4770 - val_acc: 0.8122 - val_f1: 0.8116 - val_precision_measure: 0.8144 - val_recall_measure: 0.8089\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 180s 595us/step - loss: 0.2383 - acc: 0.8678 - f1: 0.8677 - precision_measure: 0.8701 - recall_measure: 0.8653 - val_loss: 0.4011 - val_acc: 0.8490 - val_f1: 0.8488 - val_precision_measure: 0.8507 - val_recall_measure: 0.8471\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 180s 595us/step - loss: 0.2189 - acc: 0.8787 - f1: 0.8785 - precision_measure: 0.8803 - recall_measure: 0.8768 - val_loss: 0.4553 - val_acc: 0.8321 - val_f1: 0.8312 - val_precision_measure: 0.8343 - val_recall_measure: 0.8283\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 181s 599us/step - loss: 0.1963 - acc: 0.8916 - f1: 0.8915 - precision_measure: 0.8927 - recall_measure: 0.8904 - val_loss: 0.6102 - val_acc: 0.7473 - val_f1: 0.7466 - val_precision_measure: 0.7483 - val_recall_measure: 0.7450\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 180s 597us/step - loss: 0.1840 - acc: 0.9011 - f1: 0.9011 - precision_measure: 0.9021 - recall_measure: 0.9001 - val_loss: 0.4496 - val_acc: 0.8373 - val_f1: 0.8373 - val_precision_measure: 0.8379 - val_recall_measure: 0.8368\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.1644 - acc: 0.9122 - f1: 0.9122 - precision_measure: 0.9128 - recall_measure: 0.9116 - val_loss: 0.5442 - val_acc: 0.7955 - val_f1: 0.7952 - val_precision_measure: 0.7958 - val_recall_measure: 0.7947\n",
      "33762/33762 [==============================] - 6s 183us/step\n",
      "Fitting  16 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 180s 595us/step - loss: 0.4939 - acc: 0.7017 - f1: 0.6815 - precision_measure: 0.7122 - recall_measure: 0.6635 - val_loss: 0.6638 - val_acc: 0.7065 - val_f1: 0.7034 - val_precision_measure: 0.7097 - val_recall_measure: 0.6978\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 176s 582us/step - loss: 0.3085 - acc: 0.8257 - f1: 0.8247 - precision_measure: 0.8305 - recall_measure: 0.8191 - val_loss: 0.4450 - val_acc: 0.8321 - val_f1: 0.8308 - val_precision_measure: 0.8361 - val_recall_measure: 0.8261\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 177s 586us/step - loss: 0.2618 - acc: 0.8553 - f1: 0.8549 - precision_measure: 0.8585 - recall_measure: 0.8514 - val_loss: 0.3317 - val_acc: 0.8879 - val_f1: 0.8872 - val_precision_measure: 0.8893 - val_recall_measure: 0.8851\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 179s 595us/step - loss: 0.2327 - acc: 0.8716 - f1: 0.8715 - precision_measure: 0.8737 - recall_measure: 0.8693 - val_loss: 0.5395 - val_acc: 0.7742 - val_f1: 0.7730 - val_precision_measure: 0.7764 - val_recall_measure: 0.7699\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.2101 - acc: 0.8839 - f1: 0.8838 - precision_measure: 0.8852 - recall_measure: 0.8824 - val_loss: 0.6449 - val_acc: 0.7515 - val_f1: 0.7508 - val_precision_measure: 0.7541 - val_recall_measure: 0.7478\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 592us/step - loss: 0.1965 - acc: 0.8937 - f1: 0.8936 - precision_measure: 0.8947 - recall_measure: 0.8926 - val_loss: 0.5408 - val_acc: 0.7835 - val_f1: 0.7830 - val_precision_measure: 0.7840 - val_recall_measure: 0.7820\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 178s 591us/step - loss: 0.1771 - acc: 0.9056 - f1: 0.9055 - precision_measure: 0.9063 - recall_measure: 0.9047 - val_loss: 0.3975 - val_acc: 0.8629 - val_f1: 0.8623 - val_precision_measure: 0.8643 - val_recall_measure: 0.8605\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 177s 585us/step - loss: 0.1619 - acc: 0.9167 - f1: 0.9166 - precision_measure: 0.9173 - recall_measure: 0.9160 - val_loss: 0.4442 - val_acc: 0.8465 - val_f1: 0.8462 - val_precision_measure: 0.8471 - val_recall_measure: 0.8454\n",
      "33762/33762 [==============================] - 7s 197us/step\n",
      "Fitting  17 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.7837 - acc: 0.5449 - f1: 0.4638 - precision_measure: 0.5724 - recall_measure: 0.4227 - val_loss: 1.0414 - val_acc: 0.4199 - val_f1: 0.4076 - val_precision_measure: 0.4211 - val_recall_measure: 0.3969\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 180s 598us/step - loss: 0.4968 - acc: 0.6169 - f1: 0.6068 - precision_measure: 0.6231 - recall_measure: 0.5917 - val_loss: 0.8440 - val_acc: 0.4979 - val_f1: 0.4869 - val_precision_measure: 0.4988 - val_recall_measure: 0.4768\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.4500 - acc: 0.6775 - f1: 0.6713 - precision_measure: 0.6837 - recall_measure: 0.6595 - val_loss: 0.9658 - val_acc: 0.4972 - val_f1: 0.4922 - val_precision_measure: 0.4966 - val_recall_measure: 0.4883\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 180s 596us/step - loss: 0.4069 - acc: 0.7370 - f1: 0.7338 - precision_measure: 0.7425 - recall_measure: 0.7255 - val_loss: 0.7307 - val_acc: 0.6281 - val_f1: 0.6265 - val_precision_measure: 0.6301 - val_recall_measure: 0.6232\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.3689 - acc: 0.7804 - f1: 0.7786 - precision_measure: 0.7852 - recall_measure: 0.7723 - val_loss: 0.5568 - val_acc: 0.7643 - val_f1: 0.7623 - val_precision_measure: 0.7657 - val_recall_measure: 0.7591\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 593us/step - loss: 0.3333 - acc: 0.8120 - f1: 0.8109 - precision_measure: 0.8159 - recall_measure: 0.8061 - val_loss: 0.5538 - val_acc: 0.7893 - val_f1: 0.7861 - val_precision_measure: 0.7917 - val_recall_measure: 0.7811\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.3081 - acc: 0.8300 - f1: 0.8294 - precision_measure: 0.8332 - recall_measure: 0.8257 - val_loss: 0.4843 - val_acc: 0.8194 - val_f1: 0.8181 - val_precision_measure: 0.8202 - val_recall_measure: 0.8161\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 174s 578us/step - loss: 0.2854 - acc: 0.8443 - f1: 0.8440 - precision_measure: 0.8469 - recall_measure: 0.8413 - val_loss: 0.4702 - val_acc: 0.8320 - val_f1: 0.8313 - val_precision_measure: 0.8336 - val_recall_measure: 0.8291\n",
      "33762/33762 [==============================] - 7s 193us/step\n",
      "Fitting  18 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 187s 621us/step - loss: 0.7903 - acc: 0.5577 - f1: 0.4745 - precision_measure: 0.5876 - recall_measure: 0.4338 - val_loss: 1.0269 - val_acc: 0.4622 - val_f1: 0.4279 - val_precision_measure: 0.4649 - val_recall_measure: 0.4027\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 181s 601us/step - loss: 0.4708 - acc: 0.6968 - f1: 0.6898 - precision_measure: 0.7038 - recall_measure: 0.6766 - val_loss: 0.9185 - val_acc: 0.5635 - val_f1: 0.5574 - val_precision_measure: 0.5637 - val_recall_measure: 0.5517\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 184s 609us/step - loss: 0.4047 - acc: 0.7644 - f1: 0.7620 - precision_measure: 0.7704 - recall_measure: 0.7540 - val_loss: 0.8262 - val_acc: 0.5416 - val_f1: 0.5353 - val_precision_measure: 0.5428 - val_recall_measure: 0.5288\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 185s 613us/step - loss: 0.3640 - acc: 0.7947 - f1: 0.7930 - precision_measure: 0.7994 - recall_measure: 0.7867 - val_loss: 0.5444 - val_acc: 0.7996 - val_f1: 0.7968 - val_precision_measure: 0.8020 - val_recall_measure: 0.7920\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 182s 605us/step - loss: 0.3389 - acc: 0.8093 - f1: 0.8081 - precision_measure: 0.8130 - recall_measure: 0.8034 - val_loss: 0.4961 - val_acc: 0.8255 - val_f1: 0.8244 - val_precision_measure: 0.8276 - val_recall_measure: 0.8214\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 184s 609us/step - loss: 0.3142 - acc: 0.8254 - f1: 0.8249 - precision_measure: 0.8288 - recall_measure: 0.8211 - val_loss: 0.5991 - val_acc: 0.7753 - val_f1: 0.7727 - val_precision_measure: 0.7775 - val_recall_measure: 0.7684\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 182s 602us/step - loss: 0.2911 - acc: 0.8390 - f1: 0.8386 - precision_measure: 0.8416 - recall_measure: 0.8356 - val_loss: 0.4867 - val_acc: 0.8230 - val_f1: 0.8226 - val_precision_measure: 0.8238 - val_recall_measure: 0.8215\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 186s 617us/step - loss: 0.2781 - acc: 0.8474 - f1: 0.8470 - precision_measure: 0.8496 - recall_measure: 0.8445 - val_loss: 0.5059 - val_acc: 0.8219 - val_f1: 0.8217 - val_precision_measure: 0.8230 - val_recall_measure: 0.8205\n",
      "33762/33762 [==============================] - 7s 198us/step\n",
      "Fitting  19 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 191s 634us/step - loss: 0.8023 - acc: 0.5478 - f1: 0.4647 - precision_measure: 0.5767 - recall_measure: 0.4232 - val_loss: 0.9870 - val_acc: 0.4657 - val_f1: 0.4447 - val_precision_measure: 0.4675 - val_recall_measure: 0.4282\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 185s 615us/step - loss: 0.4881 - acc: 0.6665 - f1: 0.6584 - precision_measure: 0.6750 - recall_measure: 0.6430 - val_loss: 0.7444 - val_acc: 0.6118 - val_f1: 0.6079 - val_precision_measure: 0.6134 - val_recall_measure: 0.6030\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 190s 630us/step - loss: 0.4393 - acc: 0.7144 - f1: 0.7098 - precision_measure: 0.7214 - recall_measure: 0.6988 - val_loss: 0.8256 - val_acc: 0.5355 - val_f1: 0.5330 - val_precision_measure: 0.5366 - val_recall_measure: 0.5297\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 186s 616us/step - loss: 0.4042 - acc: 0.7445 - f1: 0.7419 - precision_measure: 0.7513 - recall_measure: 0.7330 - val_loss: 0.7147 - val_acc: 0.6439 - val_f1: 0.6402 - val_precision_measure: 0.6459 - val_recall_measure: 0.6349\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 188s 622us/step - loss: 0.3862 - acc: 0.7613 - f1: 0.7595 - precision_measure: 0.7672 - recall_measure: 0.7521 - val_loss: 0.4863 - val_acc: 0.8195 - val_f1: 0.8172 - val_precision_measure: 0.8214 - val_recall_measure: 0.8132\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 190s 628us/step - loss: 0.3569 - acc: 0.7794 - f1: 0.7779 - precision_measure: 0.7840 - recall_measure: 0.7720 - val_loss: 0.7626 - val_acc: 0.6556 - val_f1: 0.6515 - val_precision_measure: 0.6572 - val_recall_measure: 0.6462\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 186s 616us/step - loss: 0.3381 - acc: 0.7986 - f1: 0.7975 - precision_measure: 0.8022 - recall_measure: 0.7930 - val_loss: 0.5507 - val_acc: 0.7781 - val_f1: 0.7761 - val_precision_measure: 0.7804 - val_recall_measure: 0.7721\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 188s 625us/step - loss: 0.3132 - acc: 0.8218 - f1: 0.8212 - precision_measure: 0.8248 - recall_measure: 0.8176 - val_loss: 0.4646 - val_acc: 0.8249 - val_f1: 0.8241 - val_precision_measure: 0.8260 - val_recall_measure: 0.8224\n",
      "33762/33762 [==============================] - 7s 204us/step\n",
      "Fitting  20 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.7759 - acc: 0.5468 - f1: 0.4717 - precision_measure: 0.5724 - recall_measure: 0.4315 - val_loss: 0.9906 - val_acc: 0.4225 - val_f1: 0.4090 - val_precision_measure: 0.4220 - val_recall_measure: 0.3983\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 184s 609us/step - loss: 0.4860 - acc: 0.6564 - f1: 0.6484 - precision_measure: 0.6640 - recall_measure: 0.6338 - val_loss: 0.7642 - val_acc: 0.6062 - val_f1: 0.6018 - val_precision_measure: 0.6090 - val_recall_measure: 0.5956\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 191s 632us/step - loss: 0.4355 - acc: 0.7136 - f1: 0.7089 - precision_measure: 0.7206 - recall_measure: 0.6978 - val_loss: 0.7630 - val_acc: 0.6380 - val_f1: 0.6344 - val_precision_measure: 0.6401 - val_recall_measure: 0.6293\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 185s 613us/step - loss: 0.4059 - acc: 0.7417 - f1: 0.7388 - precision_measure: 0.7480 - recall_measure: 0.7299 - val_loss: 0.6699 - val_acc: 0.6960 - val_f1: 0.6877 - val_precision_measure: 0.6989 - val_recall_measure: 0.6782\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 187s 621us/step - loss: 0.3803 - acc: 0.7630 - f1: 0.7608 - precision_measure: 0.7683 - recall_measure: 0.7536 - val_loss: 1.2118 - val_acc: 0.4847 - val_f1: 0.4817 - val_precision_measure: 0.4861 - val_recall_measure: 0.4776\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 187s 619us/step - loss: 0.3606 - acc: 0.7793 - f1: 0.7776 - precision_measure: 0.7837 - recall_measure: 0.7717 - val_loss: 0.7039 - val_acc: 0.7006 - val_f1: 0.6964 - val_precision_measure: 0.7029 - val_recall_measure: 0.6906\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 186s 618us/step - loss: 0.3428 - acc: 0.7924 - f1: 0.7913 - precision_measure: 0.7963 - recall_measure: 0.7864 - val_loss: 0.5333 - val_acc: 0.8001 - val_f1: 0.7989 - val_precision_measure: 0.8021 - val_recall_measure: 0.7959\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 188s 623us/step - loss: 0.3304 - acc: 0.8047 - f1: 0.8037 - precision_measure: 0.8077 - recall_measure: 0.7998 - val_loss: 0.4762 - val_acc: 0.8239 - val_f1: 0.8217 - val_precision_measure: 0.8252 - val_recall_measure: 0.8184\n",
      "33762/33762 [==============================] - 8s 224us/step\n",
      "Fitting  21 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 200s 663us/step - loss: 0.6804 - acc: 0.5395 - f1: 0.4826 - precision_measure: 0.5567 - recall_measure: 0.4491 - val_loss: 0.9091 - val_acc: 0.5368 - val_f1: 0.5272 - val_precision_measure: 0.5406 - val_recall_measure: 0.5159\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 188s 624us/step - loss: 0.4270 - acc: 0.7190 - f1: 0.7137 - precision_measure: 0.7273 - recall_measure: 0.7010 - val_loss: 0.7066 - val_acc: 0.6727 - val_f1: 0.6699 - val_precision_measure: 0.6747 - val_recall_measure: 0.6654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 177s 587us/step - loss: 0.3653 - acc: 0.7888 - f1: 0.7870 - precision_measure: 0.7952 - recall_measure: 0.7792 - val_loss: 0.5355 - val_acc: 0.7941 - val_f1: 0.7924 - val_precision_measure: 0.7961 - val_recall_measure: 0.7891\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 179s 595us/step - loss: 0.3287 - acc: 0.8149 - f1: 0.8139 - precision_measure: 0.8200 - recall_measure: 0.8079 - val_loss: 0.4719 - val_acc: 0.7974 - val_f1: 0.7960 - val_precision_measure: 0.7989 - val_recall_measure: 0.7934\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.3038 - acc: 0.8307 - f1: 0.8300 - precision_measure: 0.8349 - recall_measure: 0.8252 - val_loss: 0.5042 - val_acc: 0.8066 - val_f1: 0.8058 - val_precision_measure: 0.8085 - val_recall_measure: 0.8032\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 594us/step - loss: 0.2834 - acc: 0.8428 - f1: 0.8424 - precision_measure: 0.8463 - recall_measure: 0.8386 - val_loss: 0.4006 - val_acc: 0.8726 - val_f1: 0.8715 - val_precision_measure: 0.8740 - val_recall_measure: 0.8693\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 180s 595us/step - loss: 0.2691 - acc: 0.8523 - f1: 0.8521 - precision_measure: 0.8553 - recall_measure: 0.8489 - val_loss: 0.4008 - val_acc: 0.8665 - val_f1: 0.8656 - val_precision_measure: 0.8681 - val_recall_measure: 0.8632\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.2517 - acc: 0.8627 - f1: 0.8624 - precision_measure: 0.8648 - recall_measure: 0.8600 - val_loss: 0.6173 - val_acc: 0.7269 - val_f1: 0.7264 - val_precision_measure: 0.7281 - val_recall_measure: 0.7249\n",
      "33762/33762 [==============================] - 7s 195us/step\n",
      "Fitting  22 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 183s 606us/step - loss: 0.6705 - acc: 0.5790 - f1: 0.5210 - precision_measure: 0.5972 - recall_measure: 0.4898 - val_loss: 0.9155 - val_acc: 0.5448 - val_f1: 0.5346 - val_precision_measure: 0.5482 - val_recall_measure: 0.5236\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 178s 588us/step - loss: 0.4272 - acc: 0.7181 - f1: 0.7133 - precision_measure: 0.7248 - recall_measure: 0.7023 - val_loss: 0.8372 - val_acc: 0.5915 - val_f1: 0.5618 - val_precision_measure: 0.5968 - val_recall_measure: 0.5360\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 180s 598us/step - loss: 0.3752 - acc: 0.7709 - f1: 0.7687 - precision_measure: 0.7765 - recall_measure: 0.7612 - val_loss: 0.7135 - val_acc: 0.6637 - val_f1: 0.6579 - val_precision_measure: 0.6654 - val_recall_measure: 0.6514\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 178s 591us/step - loss: 0.3364 - acc: 0.8052 - f1: 0.8038 - precision_measure: 0.8092 - recall_measure: 0.7986 - val_loss: 0.6320 - val_acc: 0.7395 - val_f1: 0.7373 - val_precision_measure: 0.7410 - val_recall_measure: 0.7339\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 180s 597us/step - loss: 0.3081 - acc: 0.8272 - f1: 0.8267 - precision_measure: 0.8305 - recall_measure: 0.8229 - val_loss: 0.8680 - val_acc: 0.6272 - val_f1: 0.6249 - val_precision_measure: 0.6284 - val_recall_measure: 0.6216\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 178s 591us/step - loss: 0.2826 - acc: 0.8441 - f1: 0.8438 - precision_measure: 0.8468 - recall_measure: 0.8408 - val_loss: 0.4305 - val_acc: 0.8442 - val_f1: 0.8437 - val_precision_measure: 0.8456 - val_recall_measure: 0.8419\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 176s 585us/step - loss: 0.2689 - acc: 0.8554 - f1: 0.8551 - precision_measure: 0.8577 - recall_measure: 0.8525 - val_loss: 0.5948 - val_acc: 0.7632 - val_f1: 0.7623 - val_precision_measure: 0.7649 - val_recall_measure: 0.7599\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.2516 - acc: 0.8642 - f1: 0.8640 - precision_measure: 0.8661 - recall_measure: 0.8620 - val_loss: 0.5289 - val_acc: 0.7867 - val_f1: 0.7862 - val_precision_measure: 0.7873 - val_recall_measure: 0.7852\n",
      "33762/33762 [==============================] - 7s 203us/step\n",
      "Fitting  23 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 182s 602us/step - loss: 0.6625 - acc: 0.5361 - f1: 0.4859 - precision_measure: 0.5499 - recall_measure: 0.4543 - val_loss: 0.8049 - val_acc: 0.5615 - val_f1: 0.5502 - val_precision_measure: 0.5654 - val_recall_measure: 0.5377\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 181s 599us/step - loss: 0.4346 - acc: 0.7126 - f1: 0.7064 - precision_measure: 0.7200 - recall_measure: 0.6936 - val_loss: 0.9335 - val_acc: 0.5120 - val_f1: 0.5016 - val_precision_measure: 0.5125 - val_recall_measure: 0.4922\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 180s 597us/step - loss: 0.3623 - acc: 0.7916 - f1: 0.7897 - precision_measure: 0.7968 - recall_measure: 0.7829 - val_loss: 1.0249 - val_acc: 0.5014 - val_f1: 0.4998 - val_precision_measure: 0.5019 - val_recall_measure: 0.4978\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 178s 590us/step - loss: 0.3267 - acc: 0.8188 - f1: 0.8179 - precision_measure: 0.8230 - recall_measure: 0.8129 - val_loss: 0.6229 - val_acc: 0.7267 - val_f1: 0.7250 - val_precision_measure: 0.7278 - val_recall_measure: 0.7224\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 178s 590us/step - loss: 0.3030 - acc: 0.8363 - f1: 0.8356 - precision_measure: 0.8395 - recall_measure: 0.8318 - val_loss: 0.3935 - val_acc: 0.8645 - val_f1: 0.8635 - val_precision_measure: 0.8664 - val_recall_measure: 0.8608\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 594us/step - loss: 0.2844 - acc: 0.8469 - f1: 0.8464 - precision_measure: 0.8496 - recall_measure: 0.8433 - val_loss: 0.4723 - val_acc: 0.8210 - val_f1: 0.8200 - val_precision_measure: 0.8221 - val_recall_measure: 0.8180\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 180s 596us/step - loss: 0.2676 - acc: 0.8563 - f1: 0.8560 - precision_measure: 0.8586 - recall_measure: 0.8534 - val_loss: 0.5911 - val_acc: 0.7549 - val_f1: 0.7545 - val_precision_measure: 0.7559 - val_recall_measure: 0.7531\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 185s 614us/step - loss: 0.2572 - acc: 0.8630 - f1: 0.8627 - precision_measure: 0.8649 - recall_measure: 0.8606 - val_loss: 0.3764 - val_acc: 0.8736 - val_f1: 0.8733 - val_precision_measure: 0.8750 - val_recall_measure: 0.8717\n",
      "33762/33762 [==============================] - 8s 226us/step\n",
      "Fitting  24 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 182s 603us/step - loss: 0.6711 - acc: 0.5274 - f1: 0.4705 - precision_measure: 0.5438 - recall_measure: 0.4360 - val_loss: 0.9554 - val_acc: 0.4598 - val_f1: 0.4411 - val_precision_measure: 0.4589 - val_recall_measure: 0.4272\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 182s 602us/step - loss: 0.4230 - acc: 0.7142 - f1: 0.7081 - precision_measure: 0.7218 - recall_measure: 0.6953 - val_loss: 0.7582 - val_acc: 0.6226 - val_f1: 0.6123 - val_precision_measure: 0.6231 - val_recall_measure: 0.6032\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 180s 596us/step - loss: 0.3533 - acc: 0.7959 - f1: 0.7941 - precision_measure: 0.8017 - recall_measure: 0.7867 - val_loss: 0.9119 - val_acc: 0.5592 - val_f1: 0.5546 - val_precision_measure: 0.5597 - val_recall_measure: 0.5500\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 180s 596us/step - loss: 0.3174 - acc: 0.8208 - f1: 0.8199 - precision_measure: 0.8248 - recall_measure: 0.8150 - val_loss: 0.4341 - val_acc: 0.8485 - val_f1: 0.8466 - val_precision_measure: 0.8510 - val_recall_measure: 0.8427\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 180s 597us/step - loss: 0.2999 - acc: 0.8342 - f1: 0.8334 - precision_measure: 0.8375 - recall_measure: 0.8294 - val_loss: 0.5851 - val_acc: 0.7540 - val_f1: 0.7504 - val_precision_measure: 0.7559 - val_recall_measure: 0.7453\n",
      "Epoch 6/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 175s 581us/step - loss: 0.2743 - acc: 0.8472 - f1: 0.8467 - precision_measure: 0.8499 - recall_measure: 0.8437 - val_loss: 0.5825 - val_acc: 0.7407 - val_f1: 0.7397 - val_precision_measure: 0.7419 - val_recall_measure: 0.7376\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 175s 581us/step - loss: 0.2557 - acc: 0.8580 - f1: 0.8578 - precision_measure: 0.8602 - recall_measure: 0.8555 - val_loss: 0.5077 - val_acc: 0.7938 - val_f1: 0.7930 - val_precision_measure: 0.7952 - val_recall_measure: 0.7909\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 174s 578us/step - loss: 0.2413 - acc: 0.8687 - f1: 0.8684 - precision_measure: 0.8704 - recall_measure: 0.8665 - val_loss: 0.6346 - val_acc: 0.7440 - val_f1: 0.7426 - val_precision_measure: 0.7456 - val_recall_measure: 0.7398\n",
      "33762/33762 [==============================] - 7s 205us/step\n",
      "Fitting  25 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 184s 609us/step - loss: 0.6121 - acc: 0.5817 - f1: 0.5408 - precision_measure: 0.5979 - recall_measure: 0.5109 - val_loss: 0.7903 - val_acc: 0.6215 - val_f1: 0.6170 - val_precision_measure: 0.6254 - val_recall_measure: 0.6097\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 176s 582us/step - loss: 0.3902 - acc: 0.7616 - f1: 0.7584 - precision_measure: 0.7684 - recall_measure: 0.7489 - val_loss: 0.5906 - val_acc: 0.7623 - val_f1: 0.7593 - val_precision_measure: 0.7655 - val_recall_measure: 0.7536\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.3348 - acc: 0.8116 - f1: 0.8103 - precision_measure: 0.8169 - recall_measure: 0.8039 - val_loss: 0.6886 - val_acc: 0.7042 - val_f1: 0.6974 - val_precision_measure: 0.7071 - val_recall_measure: 0.6889\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 176s 583us/step - loss: 0.3018 - acc: 0.8294 - f1: 0.8288 - precision_measure: 0.8340 - recall_measure: 0.8237 - val_loss: 0.3581 - val_acc: 0.8877 - val_f1: 0.8870 - val_precision_measure: 0.8906 - val_recall_measure: 0.8837\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 175s 581us/step - loss: 0.2802 - acc: 0.8429 - f1: 0.8423 - precision_measure: 0.8460 - recall_measure: 0.8386 - val_loss: 0.3761 - val_acc: 0.8775 - val_f1: 0.8764 - val_precision_measure: 0.8795 - val_recall_measure: 0.8735\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 176s 584us/step - loss: 0.2636 - acc: 0.8527 - f1: 0.8524 - precision_measure: 0.8553 - recall_measure: 0.8495 - val_loss: 0.4296 - val_acc: 0.8362 - val_f1: 0.8353 - val_precision_measure: 0.8369 - val_recall_measure: 0.8338\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.2519 - acc: 0.8600 - f1: 0.8597 - precision_measure: 0.8624 - recall_measure: 0.8571 - val_loss: 0.3649 - val_acc: 0.8644 - val_f1: 0.8642 - val_precision_measure: 0.8650 - val_recall_measure: 0.8635\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 177s 585us/step - loss: 0.2381 - acc: 0.8692 - f1: 0.8690 - precision_measure: 0.8711 - recall_measure: 0.8670 - val_loss: 0.3839 - val_acc: 0.8748 - val_f1: 0.8745 - val_precision_measure: 0.8764 - val_recall_measure: 0.8728\n",
      "33762/33762 [==============================] - 7s 213us/step\n",
      "Fitting  26 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 184s 610us/step - loss: 0.6092 - acc: 0.5963 - f1: 0.5588 - precision_measure: 0.6161 - recall_measure: 0.5285 - val_loss: 0.8745 - val_acc: 0.5699 - val_f1: 0.5566 - val_precision_measure: 0.5717 - val_recall_measure: 0.5443\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.3996 - acc: 0.7500 - f1: 0.7460 - precision_measure: 0.7567 - recall_measure: 0.7358 - val_loss: 0.6999 - val_acc: 0.6070 - val_f1: 0.6041 - val_precision_measure: 0.6097 - val_recall_measure: 0.5990\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 179s 593us/step - loss: 0.3479 - acc: 0.7933 - f1: 0.7916 - precision_measure: 0.7989 - recall_measure: 0.7846 - val_loss: 0.6356 - val_acc: 0.7232 - val_f1: 0.7222 - val_precision_measure: 0.7248 - val_recall_measure: 0.7197\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 179s 592us/step - loss: 0.3088 - acc: 0.8258 - f1: 0.8249 - precision_measure: 0.8300 - recall_measure: 0.8200 - val_loss: 0.5691 - val_acc: 0.7630 - val_f1: 0.7627 - val_precision_measure: 0.7652 - val_recall_measure: 0.7603\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 178s 590us/step - loss: 0.2837 - acc: 0.8411 - f1: 0.8404 - precision_measure: 0.8446 - recall_measure: 0.8364 - val_loss: 0.5740 - val_acc: 0.7628 - val_f1: 0.7619 - val_precision_measure: 0.7645 - val_recall_measure: 0.7594\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 187s 621us/step - loss: 0.2644 - acc: 0.8519 - f1: 0.8515 - precision_measure: 0.8545 - recall_measure: 0.8487 - val_loss: 0.4908 - val_acc: 0.8255 - val_f1: 0.8228 - val_precision_measure: 0.8285 - val_recall_measure: 0.8177\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 178s 591us/step - loss: 0.2469 - acc: 0.8618 - f1: 0.8614 - precision_measure: 0.8638 - recall_measure: 0.8591 - val_loss: 0.4928 - val_acc: 0.8136 - val_f1: 0.8131 - val_precision_measure: 0.8148 - val_recall_measure: 0.8114\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 179s 595us/step - loss: 0.2305 - acc: 0.8706 - f1: 0.8705 - precision_measure: 0.8721 - recall_measure: 0.8688 - val_loss: 0.5964 - val_acc: 0.7742 - val_f1: 0.7736 - val_precision_measure: 0.7750 - val_recall_measure: 0.7723\n",
      "33762/33762 [==============================] - 7s 206us/step\n",
      "Fitting  27 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 182s 603us/step - loss: 0.5886 - acc: 0.6073 - f1: 0.5752 - precision_measure: 0.6245 - recall_measure: 0.5483 - val_loss: 0.8812 - val_acc: 0.6098 - val_f1: 0.6007 - val_precision_measure: 0.6167 - val_recall_measure: 0.5874\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 177s 586us/step - loss: 0.3746 - acc: 0.7851 - f1: 0.7828 - precision_measure: 0.7917 - recall_measure: 0.7742 - val_loss: 0.5240 - val_acc: 0.8080 - val_f1: 0.8050 - val_precision_measure: 0.8113 - val_recall_measure: 0.7992\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.3252 - acc: 0.8187 - f1: 0.8176 - precision_measure: 0.8239 - recall_measure: 0.8114 - val_loss: 0.6868 - val_acc: 0.6911 - val_f1: 0.6896 - val_precision_measure: 0.6935 - val_recall_measure: 0.6861\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 177s 585us/step - loss: 0.2938 - acc: 0.8383 - f1: 0.8374 - precision_measure: 0.8423 - recall_measure: 0.8326 - val_loss: 0.4754 - val_acc: 0.8213 - val_f1: 0.8202 - val_precision_measure: 0.8227 - val_recall_measure: 0.8178\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 180s 596us/step - loss: 0.2699 - acc: 0.8521 - f1: 0.8516 - precision_measure: 0.8552 - recall_measure: 0.8480 - val_loss: 0.6873 - val_acc: 0.7506 - val_f1: 0.7502 - val_precision_measure: 0.7519 - val_recall_measure: 0.7487\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 594us/step - loss: 0.2505 - acc: 0.8625 - f1: 0.8623 - precision_measure: 0.8649 - recall_measure: 0.8596 - val_loss: 0.4776 - val_acc: 0.8122 - val_f1: 0.8118 - val_precision_measure: 0.8146 - val_recall_measure: 0.8092\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.2326 - acc: 0.8716 - f1: 0.8713 - precision_measure: 0.8733 - recall_measure: 0.8694 - val_loss: 0.4425 - val_acc: 0.8346 - val_f1: 0.8344 - val_precision_measure: 0.8363 - val_recall_measure: 0.8327\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 188s 622us/step - loss: 0.2200 - acc: 0.8806 - f1: 0.8804 - precision_measure: 0.8820 - recall_measure: 0.8788 - val_loss: 0.6309 - val_acc: 0.7580 - val_f1: 0.7575 - val_precision_measure: 0.7584 - val_recall_measure: 0.7566\n",
      "33762/33762 [==============================] - 7s 208us/step\n",
      "Fitting  28 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 181s 601us/step - loss: 0.5797 - acc: 0.6095 - f1: 0.5784 - precision_measure: 0.6261 - recall_measure: 0.5517 - val_loss: 0.8433 - val_acc: 0.5708 - val_f1: 0.5503 - val_precision_measure: 0.5727 - val_recall_measure: 0.5326\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 182s 603us/step - loss: 0.3772 - acc: 0.7672 - f1: 0.7641 - precision_measure: 0.7733 - recall_measure: 0.7552 - val_loss: 0.8040 - val_acc: 0.6046 - val_f1: 0.6029 - val_precision_measure: 0.6064 - val_recall_measure: 0.5997\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 179s 592us/step - loss: 0.3234 - acc: 0.8167 - f1: 0.8157 - precision_measure: 0.8210 - recall_measure: 0.8104 - val_loss: 0.4420 - val_acc: 0.8572 - val_f1: 0.8560 - val_precision_measure: 0.8602 - val_recall_measure: 0.8523\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 179s 593us/step - loss: 0.2867 - acc: 0.8402 - f1: 0.8395 - precision_measure: 0.8434 - recall_measure: 0.8358 - val_loss: 0.2966 - val_acc: 0.9071 - val_f1: 0.9068 - val_precision_measure: 0.9082 - val_recall_measure: 0.9054\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 181s 602us/step - loss: 0.2658 - acc: 0.8522 - f1: 0.8518 - precision_measure: 0.8549 - recall_measure: 0.8488 - val_loss: 0.4301 - val_acc: 0.8459 - val_f1: 0.8455 - val_precision_measure: 0.8467 - val_recall_measure: 0.8444\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 594us/step - loss: 0.2499 - acc: 0.8633 - f1: 0.8631 - precision_measure: 0.8654 - recall_measure: 0.8608 - val_loss: 0.4817 - val_acc: 0.8267 - val_f1: 0.8253 - val_precision_measure: 0.8327 - val_recall_measure: 0.8186\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 180s 596us/step - loss: 0.2278 - acc: 0.8749 - f1: 0.8748 - precision_measure: 0.8765 - recall_measure: 0.8731 - val_loss: 0.3865 - val_acc: 0.8678 - val_f1: 0.8675 - val_precision_measure: 0.8688 - val_recall_measure: 0.8663\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 183s 606us/step - loss: 0.2181 - acc: 0.8827 - f1: 0.8827 - precision_measure: 0.8841 - recall_measure: 0.8813 - val_loss: 0.4185 - val_acc: 0.8510 - val_f1: 0.8508 - val_precision_measure: 0.8517 - val_recall_measure: 0.8500\n",
      "33762/33762 [==============================] - 7s 221us/step\n",
      "Fitting  29 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 179s 594us/step - loss: 0.5772 - acc: 0.6085 - f1: 0.5768 - precision_measure: 0.6249 - recall_measure: 0.5487 - val_loss: 0.8395 - val_acc: 0.6016 - val_f1: 0.5947 - val_precision_measure: 0.6028 - val_recall_measure: 0.5876\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 178s 590us/step - loss: 0.3867 - acc: 0.7468 - f1: 0.7437 - precision_measure: 0.7535 - recall_measure: 0.7343 - val_loss: 0.7293 - val_acc: 0.6166 - val_f1: 0.6114 - val_precision_measure: 0.6185 - val_recall_measure: 0.6051\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 177s 586us/step - loss: 0.3346 - acc: 0.8009 - f1: 0.7997 - precision_measure: 0.8066 - recall_measure: 0.7931 - val_loss: 0.5619 - val_acc: 0.7627 - val_f1: 0.7574 - val_precision_measure: 0.7673 - val_recall_measure: 0.7487\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 177s 587us/step - loss: 0.2985 - acc: 0.8260 - f1: 0.8251 - precision_measure: 0.8301 - recall_measure: 0.8202 - val_loss: 0.4674 - val_acc: 0.8166 - val_f1: 0.8157 - val_precision_measure: 0.8181 - val_recall_measure: 0.8135\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 178s 591us/step - loss: 0.2703 - acc: 0.8426 - f1: 0.8421 - precision_measure: 0.8454 - recall_measure: 0.8390 - val_loss: 0.7005 - val_acc: 0.7038 - val_f1: 0.7023 - val_precision_measure: 0.7060 - val_recall_measure: 0.6988\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 177s 587us/step - loss: 0.2517 - acc: 0.8554 - f1: 0.8550 - precision_measure: 0.8577 - recall_measure: 0.8523 - val_loss: 0.5449 - val_acc: 0.7725 - val_f1: 0.7718 - val_precision_measure: 0.7745 - val_recall_measure: 0.7692\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 182s 604us/step - loss: 0.2388 - acc: 0.8623 - f1: 0.8621 - precision_measure: 0.8642 - recall_measure: 0.8601 - val_loss: 0.4038 - val_acc: 0.8394 - val_f1: 0.8390 - val_precision_measure: 0.8409 - val_recall_measure: 0.8372\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.2200 - acc: 0.8719 - f1: 0.8718 - precision_measure: 0.8734 - recall_measure: 0.8701 - val_loss: 0.3738 - val_acc: 0.8605 - val_f1: 0.8604 - val_precision_measure: 0.8615 - val_recall_measure: 0.8593\n",
      "33762/33762 [==============================] - 7s 218us/step\n",
      "Fitting  30 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 187s 621us/step - loss: 0.5512 - acc: 0.6553 - f1: 0.6315 - precision_measure: 0.6732 - recall_measure: 0.6058 - val_loss: 1.1003 - val_acc: 0.4542 - val_f1: 0.4509 - val_precision_measure: 0.4550 - val_recall_measure: 0.4472\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.3681 - acc: 0.7842 - f1: 0.7817 - precision_measure: 0.7900 - recall_measure: 0.7737 - val_loss: 0.7119 - val_acc: 0.6624 - val_f1: 0.6591 - val_precision_measure: 0.6635 - val_recall_measure: 0.6551\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 190s 631us/step - loss: 0.3216 - acc: 0.8137 - f1: 0.8123 - precision_measure: 0.8181 - recall_measure: 0.8066 - val_loss: 0.7276 - val_acc: 0.6614 - val_f1: 0.6593 - val_precision_measure: 0.6634 - val_recall_measure: 0.6556\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 194s 644us/step - loss: 0.2924 - acc: 0.8324 - f1: 0.8318 - precision_measure: 0.8364 - recall_measure: 0.8273 - val_loss: 0.4356 - val_acc: 0.8348 - val_f1: 0.8340 - val_precision_measure: 0.8364 - val_recall_measure: 0.8317\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 197s 653us/step - loss: 0.2720 - acc: 0.8439 - f1: 0.8435 - precision_measure: 0.8470 - recall_measure: 0.8400 - val_loss: 0.3413 - val_acc: 0.8977 - val_f1: 0.8966 - val_precision_measure: 0.8987 - val_recall_measure: 0.8946\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 194s 642us/step - loss: 0.2533 - acc: 0.8544 - f1: 0.8541 - precision_measure: 0.8568 - recall_measure: 0.8516 - val_loss: 0.6720 - val_acc: 0.7168 - val_f1: 0.7160 - val_precision_measure: 0.7174 - val_recall_measure: 0.7147\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 196s 651us/step - loss: 0.2357 - acc: 0.8657 - f1: 0.8654 - precision_measure: 0.8676 - recall_measure: 0.8633 - val_loss: 0.3749 - val_acc: 0.8609 - val_f1: 0.8605 - val_precision_measure: 0.8620 - val_recall_measure: 0.8591\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 198s 656us/step - loss: 0.2246 - acc: 0.8744 - f1: 0.8742 - precision_measure: 0.8761 - recall_measure: 0.8723 - val_loss: 0.4791 - val_acc: 0.8179 - val_f1: 0.8168 - val_precision_measure: 0.8193 - val_recall_measure: 0.8143\n",
      "33762/33762 [==============================] - 9s 272us/step\n",
      "Fitting  31 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 202s 670us/step - loss: 0.5285 - acc: 0.6741 - f1: 0.6480 - precision_measure: 0.6889 - recall_measure: 0.6246 - val_loss: 0.6498 - val_acc: 0.6960 - val_f1: 0.6915 - val_precision_measure: 0.6981 - val_recall_measure: 0.6857\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 201s 666us/step - loss: 0.3449 - acc: 0.7990 - f1: 0.7970 - precision_measure: 0.8044 - recall_measure: 0.7898 - val_loss: 0.4029 - val_acc: 0.8497 - val_f1: 0.8482 - val_precision_measure: 0.8510 - val_recall_measure: 0.8456\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 200s 664us/step - loss: 0.2894 - acc: 0.8375 - f1: 0.8369 - precision_measure: 0.8412 - recall_measure: 0.8328 - val_loss: 0.4079 - val_acc: 0.8549 - val_f1: 0.8545 - val_precision_measure: 0.8571 - val_recall_measure: 0.8521\n",
      "Epoch 4/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 180s 595us/step - loss: 0.2679 - acc: 0.8514 - f1: 0.8509 - precision_measure: 0.8543 - recall_measure: 0.8477 - val_loss: 0.5444 - val_acc: 0.7842 - val_f1: 0.7840 - val_precision_measure: 0.7858 - val_recall_measure: 0.7822\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 183s 605us/step - loss: 0.2489 - acc: 0.8633 - f1: 0.8631 - precision_measure: 0.8656 - recall_measure: 0.8606 - val_loss: 0.4242 - val_acc: 0.8474 - val_f1: 0.8474 - val_precision_measure: 0.8482 - val_recall_measure: 0.8467\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 594us/step - loss: 0.2347 - acc: 0.8705 - f1: 0.8704 - precision_measure: 0.8725 - recall_measure: 0.8683 - val_loss: 0.3644 - val_acc: 0.8691 - val_f1: 0.8684 - val_precision_measure: 0.8704 - val_recall_measure: 0.8666\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 182s 603us/step - loss: 0.2181 - acc: 0.8798 - f1: 0.8796 - precision_measure: 0.8811 - recall_measure: 0.8782 - val_loss: 0.4183 - val_acc: 0.8468 - val_f1: 0.8465 - val_precision_measure: 0.8476 - val_recall_measure: 0.8455\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 200s 663us/step - loss: 0.2071 - acc: 0.8862 - f1: 0.8861 - precision_measure: 0.8873 - recall_measure: 0.8850 - val_loss: 0.4743 - val_acc: 0.8182 - val_f1: 0.8178 - val_precision_measure: 0.8190 - val_recall_measure: 0.8166\n",
      "33762/33762 [==============================] - 8s 235us/step\n",
      "Fitting  32 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 199s 659us/step - loss: 0.5174 - acc: 0.6854 - f1: 0.6639 - precision_measure: 0.7004 - recall_measure: 0.6421 - val_loss: 0.6151 - val_acc: 0.7089 - val_f1: 0.7020 - val_precision_measure: 0.7131 - val_recall_measure: 0.6923\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 194s 642us/step - loss: 0.3387 - acc: 0.8035 - f1: 0.8021 - precision_measure: 0.8095 - recall_measure: 0.7949 - val_loss: 0.4648 - val_acc: 0.8399 - val_f1: 0.8377 - val_precision_measure: 0.8464 - val_recall_measure: 0.8300\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 192s 637us/step - loss: 0.2957 - acc: 0.8309 - f1: 0.8303 - precision_measure: 0.8353 - recall_measure: 0.8254 - val_loss: 0.6795 - val_acc: 0.6997 - val_f1: 0.6973 - val_precision_measure: 0.7012 - val_recall_measure: 0.6936\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.2668 - acc: 0.8483 - f1: 0.8480 - precision_measure: 0.8512 - recall_measure: 0.8447 - val_loss: 0.4502 - val_acc: 0.8179 - val_f1: 0.8170 - val_precision_measure: 0.8203 - val_recall_measure: 0.8140\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 202s 669us/step - loss: 0.2420 - acc: 0.8614 - f1: 0.8610 - precision_measure: 0.8635 - recall_measure: 0.8585 - val_loss: 0.8288 - val_acc: 0.6585 - val_f1: 0.6561 - val_precision_measure: 0.6612 - val_recall_measure: 0.6515\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 206s 683us/step - loss: 0.2267 - acc: 0.8704 - f1: 0.8703 - precision_measure: 0.8723 - recall_measure: 0.8684 - val_loss: 0.5035 - val_acc: 0.7962 - val_f1: 0.7958 - val_precision_measure: 0.7971 - val_recall_measure: 0.7946\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 194s 643us/step - loss: 0.2069 - acc: 0.8840 - f1: 0.8839 - precision_measure: 0.8854 - recall_measure: 0.8825 - val_loss: 0.4885 - val_acc: 0.8315 - val_f1: 0.8298 - val_precision_measure: 0.8350 - val_recall_measure: 0.8250\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 200s 661us/step - loss: 0.1950 - acc: 0.8916 - f1: 0.8915 - precision_measure: 0.8927 - recall_measure: 0.8903 - val_loss: 0.4311 - val_acc: 0.8303 - val_f1: 0.8293 - val_precision_measure: 0.8321 - val_recall_measure: 0.8266\n",
      "33762/33762 [==============================] - 8s 232us/step\n",
      "Fitting  33 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 203s 673us/step - loss: 1.0381 - acc: 0.4908 - f1: 0.3265 - precision_measure: 0.5547 - recall_measure: 0.2579 - val_loss: 0.8786 - val_acc: 0.3037 - val_f1: 0.2721 - val_precision_measure: 0.3007 - val_recall_measure: 0.2567\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 194s 642us/step - loss: 0.6043 - acc: 0.5334 - f1: 0.4986 - precision_measure: 0.5360 - recall_measure: 0.4673 - val_loss: 0.8909 - val_acc: 0.4783 - val_f1: 0.4518 - val_precision_measure: 0.4789 - val_recall_measure: 0.4327\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 200s 663us/step - loss: 0.5485 - acc: 0.6154 - f1: 0.5961 - precision_measure: 0.6205 - recall_measure: 0.5742 - val_loss: 0.9470 - val_acc: 0.4166 - val_f1: 0.3972 - val_precision_measure: 0.4149 - val_recall_measure: 0.3835\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 206s 684us/step - loss: 0.5154 - acc: 0.6488 - f1: 0.6354 - precision_measure: 0.6550 - recall_measure: 0.6174 - val_loss: 0.8960 - val_acc: 0.4232 - val_f1: 0.4161 - val_precision_measure: 0.4225 - val_recall_measure: 0.4106\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 191s 632us/step - loss: 0.4866 - acc: 0.6827 - f1: 0.6732 - precision_measure: 0.6897 - recall_measure: 0.6577 - val_loss: 0.9758 - val_acc: 0.4480 - val_f1: 0.4384 - val_precision_measure: 0.4483 - val_recall_measure: 0.4300\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 196s 650us/step - loss: 0.4711 - acc: 0.6982 - f1: 0.6903 - precision_measure: 0.7060 - recall_measure: 0.6757 - val_loss: 0.9371 - val_acc: 0.4664 - val_f1: 0.4518 - val_precision_measure: 0.4680 - val_recall_measure: 0.4392\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 195s 646us/step - loss: 0.4499 - acc: 0.7174 - f1: 0.7114 - precision_measure: 0.7252 - recall_measure: 0.6985 - val_loss: 0.7840 - val_acc: 0.5283 - val_f1: 0.5191 - val_precision_measure: 0.5284 - val_recall_measure: 0.5111\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 194s 642us/step - loss: 0.4252 - acc: 0.7382 - f1: 0.7336 - precision_measure: 0.7456 - recall_measure: 0.7222 - val_loss: 0.6995 - val_acc: 0.5836 - val_f1: 0.5776 - val_precision_measure: 0.5843 - val_recall_measure: 0.5716\n",
      "33762/33762 [==============================] - 9s 257us/step\n",
      "Fitting  34 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 207s 688us/step - loss: 0.9607 - acc: 0.4707 - f1: 0.3210 - precision_measure: 0.5196 - recall_measure: 0.2604 - val_loss: 0.9451 - val_acc: 0.2857 - val_f1: 0.2261 - val_precision_measure: 0.2797 - val_recall_measure: 0.2052\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 195s 647us/step - loss: 0.6091 - acc: 0.4658 - f1: 0.4230 - precision_measure: 0.4632 - recall_measure: 0.3910 - val_loss: 0.8222 - val_acc: 0.3690 - val_f1: 0.3450 - val_precision_measure: 0.3667 - val_recall_measure: 0.3304\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 198s 655us/step - loss: 0.5633 - acc: 0.5563 - f1: 0.5303 - precision_measure: 0.5581 - recall_measure: 0.5060 - val_loss: 0.7376 - val_acc: 0.4858 - val_f1: 0.4774 - val_precision_measure: 0.4867 - val_recall_measure: 0.4694\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 206s 682us/step - loss: 0.5260 - acc: 0.5990 - f1: 0.5831 - precision_measure: 0.6037 - recall_measure: 0.5643 - val_loss: 0.7990 - val_acc: 0.4891 - val_f1: 0.4709 - val_precision_measure: 0.4864 - val_recall_measure: 0.4579\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 214s 709us/step - loss: 0.5035 - acc: 0.6398 - f1: 0.6293 - precision_measure: 0.6463 - recall_measure: 0.6136 - val_loss: 0.7632 - val_acc: 0.5088 - val_f1: 0.4998 - val_precision_measure: 0.5087 - val_recall_measure: 0.4921\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 196s 651us/step - loss: 0.4989 - acc: 0.6197 - f1: 0.6078 - precision_measure: 0.6261 - recall_measure: 0.5911 - val_loss: 0.9073 - val_acc: 0.4395 - val_f1: 0.4325 - val_precision_measure: 0.4407 - val_recall_measure: 0.4257\n",
      "Epoch 7/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 195s 647us/step - loss: 0.4646 - acc: 0.6795 - f1: 0.6726 - precision_measure: 0.6863 - recall_measure: 0.6598 - val_loss: 0.8543 - val_acc: 0.4523 - val_f1: 0.4455 - val_precision_measure: 0.4531 - val_recall_measure: 0.4390\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 206s 684us/step - loss: 0.4502 - acc: 0.6905 - f1: 0.6839 - precision_measure: 0.6966 - recall_measure: 0.6720 - val_loss: 0.8500 - val_acc: 0.4607 - val_f1: 0.4561 - val_precision_measure: 0.4602 - val_recall_measure: 0.4524\n",
      "33762/33762 [==============================] - 10s 303us/step\n",
      "Fitting  35 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 236s 784us/step - loss: 0.9664 - acc: 0.4667 - f1: 0.3206 - precision_measure: 0.5116 - recall_measure: 0.2666 - val_loss: 0.8225 - val_acc: 0.3130 - val_f1: 0.2689 - val_precision_measure: 0.3215 - val_recall_measure: 0.2482\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 198s 656us/step - loss: 0.5963 - acc: 0.4664 - f1: 0.4308 - precision_measure: 0.4648 - recall_measure: 0.4027 - val_loss: 0.7680 - val_acc: 0.4685 - val_f1: 0.4581 - val_precision_measure: 0.4695 - val_recall_measure: 0.4484\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 193s 640us/step - loss: 0.5499 - acc: 0.5825 - f1: 0.5596 - precision_measure: 0.5847 - recall_measure: 0.5373 - val_loss: 0.8198 - val_acc: 0.4938 - val_f1: 0.4630 - val_precision_measure: 0.4905 - val_recall_measure: 0.4420\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 195s 645us/step - loss: 0.5281 - acc: 0.6190 - f1: 0.6016 - precision_measure: 0.6232 - recall_measure: 0.5821 - val_loss: 0.8320 - val_acc: 0.5092 - val_f1: 0.4864 - val_precision_measure: 0.5070 - val_recall_measure: 0.4709\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 193s 641us/step - loss: 0.4964 - acc: 0.6603 - f1: 0.6486 - precision_measure: 0.6669 - recall_measure: 0.6317 - val_loss: 0.8145 - val_acc: 0.5690 - val_f1: 0.5575 - val_precision_measure: 0.5711 - val_recall_measure: 0.5460\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 193s 640us/step - loss: 0.4730 - acc: 0.6925 - f1: 0.6841 - precision_measure: 0.7006 - recall_measure: 0.6689 - val_loss: 0.8687 - val_acc: 0.5082 - val_f1: 0.4861 - val_precision_measure: 0.5096 - val_recall_measure: 0.4678\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 194s 645us/step - loss: 0.4511 - acc: 0.7078 - f1: 0.7019 - precision_measure: 0.7157 - recall_measure: 0.6888 - val_loss: 0.7977 - val_acc: 0.5799 - val_f1: 0.5749 - val_precision_measure: 0.5802 - val_recall_measure: 0.5702\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 201s 665us/step - loss: 0.4384 - acc: 0.7179 - f1: 0.7123 - precision_measure: 0.7248 - recall_measure: 0.7004 - val_loss: 0.8568 - val_acc: 0.5081 - val_f1: 0.4959 - val_precision_measure: 0.5059 - val_recall_measure: 0.4873\n",
      "33762/33762 [==============================] - 10s 300us/step\n",
      "Fitting  36 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 196s 650us/step - loss: 1.0028 - acc: 0.4969 - f1: 0.3566 - precision_measure: 0.5657 - recall_measure: 0.2936 - val_loss: 1.0169 - val_acc: 0.2809 - val_f1: 0.2697 - val_precision_measure: 0.2818 - val_recall_measure: 0.2612\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 195s 645us/step - loss: 0.6122 - acc: 0.4626 - f1: 0.4382 - precision_measure: 0.4756 - recall_measure: 0.4075 - val_loss: 0.8219 - val_acc: 0.3022 - val_f1: 0.2914 - val_precision_measure: 0.2990 - val_recall_measure: 0.2851\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 195s 647us/step - loss: 0.5529 - acc: 0.5076 - f1: 0.4738 - precision_measure: 0.5033 - recall_measure: 0.4484 - val_loss: 0.7825 - val_acc: 0.4571 - val_f1: 0.4237 - val_precision_measure: 0.4499 - val_recall_measure: 0.4049\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 193s 639us/step - loss: 0.5199 - acc: 0.5996 - f1: 0.5828 - precision_measure: 0.6020 - recall_measure: 0.5654 - val_loss: 0.7960 - val_acc: 0.7929 - val_f1: 0.7590 - val_precision_measure: 0.8019 - val_recall_measure: 0.7257\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 194s 642us/step - loss: 0.4873 - acc: 0.6715 - f1: 0.6612 - precision_measure: 0.6771 - recall_measure: 0.6463 - val_loss: 0.7686 - val_acc: 0.5733 - val_f1: 0.5671 - val_precision_measure: 0.5754 - val_recall_measure: 0.5597\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 192s 637us/step - loss: 0.4563 - acc: 0.7173 - f1: 0.7112 - precision_measure: 0.7241 - recall_measure: 0.6991 - val_loss: 0.7678 - val_acc: 0.5563 - val_f1: 0.5542 - val_precision_measure: 0.5590 - val_recall_measure: 0.5498\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 195s 645us/step - loss: 0.4468 - acc: 0.7253 - f1: 0.7194 - precision_measure: 0.7330 - recall_measure: 0.7067 - val_loss: 0.6618 - val_acc: 0.5863 - val_f1: 0.5835 - val_precision_measure: 0.5871 - val_recall_measure: 0.5803\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 191s 635us/step - loss: 0.4249 - acc: 0.7552 - f1: 0.7508 - precision_measure: 0.7615 - recall_measure: 0.7406 - val_loss: 0.8127 - val_acc: 0.5165 - val_f1: 0.5132 - val_precision_measure: 0.5167 - val_recall_measure: 0.5098\n",
      "33762/33762 [==============================] - 9s 264us/step\n",
      "Fitting  37 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 256s 847us/step - loss: 0.8585 - acc: 0.4734 - f1: 0.3646 - precision_measure: 0.5061 - recall_measure: 0.3143 - val_loss: 0.8464 - val_acc: 0.3324 - val_f1: 0.2937 - val_precision_measure: 0.3383 - val_recall_measure: 0.2738\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 197s 655us/step - loss: 0.5631 - acc: 0.5172 - f1: 0.4847 - precision_measure: 0.5206 - recall_measure: 0.4549 - val_loss: 0.7856 - val_acc: 0.5611 - val_f1: 0.5416 - val_precision_measure: 0.5629 - val_recall_measure: 0.5249\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 241s 799us/step - loss: 0.5121 - acc: 0.6272 - f1: 0.6108 - precision_measure: 0.6348 - recall_measure: 0.5891 - val_loss: 0.9142 - val_acc: 0.5419 - val_f1: 0.5120 - val_precision_measure: 0.5425 - val_recall_measure: 0.4896\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 382s 1ms/step - loss: 0.4810 - acc: 0.6608 - f1: 0.6495 - precision_measure: 0.6678 - recall_measure: 0.6325 - val_loss: 0.8342 - val_acc: 0.5417 - val_f1: 0.5299 - val_precision_measure: 0.5411 - val_recall_measure: 0.5204\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 380s 1ms/step - loss: 0.4541 - acc: 0.6884 - f1: 0.6802 - precision_measure: 0.6956 - recall_measure: 0.6658 - val_loss: 0.7301 - val_acc: 0.5242 - val_f1: 0.5132 - val_precision_measure: 0.5228 - val_recall_measure: 0.5055\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 299s 990us/step - loss: 0.4468 - acc: 0.6822 - f1: 0.6740 - precision_measure: 0.6874 - recall_measure: 0.6615 - val_loss: 0.7209 - val_acc: 0.6374 - val_f1: 0.6284 - val_precision_measure: 0.6416 - val_recall_measure: 0.6170\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 272s 902us/step - loss: 0.4206 - acc: 0.7263 - f1: 0.7210 - precision_measure: 0.7324 - recall_measure: 0.7101 - val_loss: 0.5980 - val_acc: 0.6988 - val_f1: 0.6954 - val_precision_measure: 0.7008 - val_recall_measure: 0.6903\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 256s 847us/step - loss: 0.3985 - acc: 0.7545 - f1: 0.7502 - precision_measure: 0.7603 - recall_measure: 0.7404 - val_loss: 0.6897 - val_acc: 0.6683 - val_f1: 0.6590 - val_precision_measure: 0.6698 - val_recall_measure: 0.6494\n",
      "33762/33762 [==============================] - 29s 868us/step\n",
      "Fitting  38 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 317s 1ms/step - loss: 0.8568 - acc: 0.4755 - f1: 0.3420 - precision_measure: 0.4979 - recall_measure: 0.2927 - val_loss: 0.8089 - val_acc: 0.4082 - val_f1: 0.2909 - val_precision_measure: 0.3752 - val_recall_measure: 0.2600\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 190s 630us/step - loss: 0.5365 - acc: 0.5880 - f1: 0.5643 - precision_measure: 0.5937 - recall_measure: 0.5388 - val_loss: 0.9324 - val_acc: 0.5062 - val_f1: 0.4801 - val_precision_measure: 0.4998 - val_recall_measure: 0.4646\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.4832 - acc: 0.6912 - f1: 0.6819 - precision_measure: 0.6993 - recall_measure: 0.6657 - val_loss: 0.7317 - val_acc: 0.6092 - val_f1: 0.6010 - val_precision_measure: 0.6084 - val_recall_measure: 0.5945\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 182s 604us/step - loss: 0.4399 - acc: 0.7358 - f1: 0.7306 - precision_measure: 0.7445 - recall_measure: 0.7175 - val_loss: 0.7159 - val_acc: 0.5933 - val_f1: 0.5871 - val_precision_measure: 0.5934 - val_recall_measure: 0.5816\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 205s 681us/step - loss: 0.4169 - acc: 0.7623 - f1: 0.7583 - precision_measure: 0.7707 - recall_measure: 0.7465 - val_loss: 0.6946 - val_acc: 0.6384 - val_f1: 0.6347 - val_precision_measure: 0.6396 - val_recall_measure: 0.6303\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 384s 1ms/step - loss: 0.3930 - acc: 0.7829 - f1: 0.7793 - precision_measure: 0.7895 - recall_measure: 0.7696 - val_loss: 0.6212 - val_acc: 0.7097 - val_f1: 0.7049 - val_precision_measure: 0.7107 - val_recall_measure: 0.6996\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 253s 839us/step - loss: 0.3881 - acc: 0.7936 - f1: 0.7910 - precision_measure: 0.7996 - recall_measure: 0.7829 - val_loss: 0.6087 - val_acc: 0.7618 - val_f1: 0.7482 - val_precision_measure: 0.7665 - val_recall_measure: 0.7322\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 192s 637us/step - loss: 0.3582 - acc: 0.8064 - f1: 0.8041 - precision_measure: 0.8119 - recall_measure: 0.7967 - val_loss: 0.5338 - val_acc: 0.7690 - val_f1: 0.7664 - val_precision_measure: 0.7700 - val_recall_measure: 0.7629\n",
      "33762/33762 [==============================] - 12s 367us/step\n",
      "Fitting  39 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 211s 701us/step - loss: 0.7900 - acc: 0.4866 - f1: 0.3839 - precision_measure: 0.5156 - recall_measure: 0.3361 - val_loss: 0.6578 - val_acc: 0.8443 - val_f1: 0.8280 - val_precision_measure: 0.8545 - val_recall_measure: 0.8072\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 191s 633us/step - loss: 0.5350 - acc: 0.5409 - f1: 0.5126 - precision_measure: 0.5438 - recall_measure: 0.4859 - val_loss: 0.6992 - val_acc: 0.5189 - val_f1: 0.5095 - val_precision_measure: 0.5212 - val_recall_measure: 0.4996\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 193s 639us/step - loss: 0.4922 - acc: 0.6284 - f1: 0.6142 - precision_measure: 0.6352 - recall_measure: 0.5950 - val_loss: 0.7931 - val_acc: 0.5241 - val_f1: 0.5200 - val_precision_measure: 0.5244 - val_recall_measure: 0.5161\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 189s 627us/step - loss: 0.4575 - acc: 0.6917 - f1: 0.6842 - precision_measure: 0.6995 - recall_measure: 0.6698 - val_loss: 0.7219 - val_acc: 0.5798 - val_f1: 0.5762 - val_precision_measure: 0.5800 - val_recall_measure: 0.5727\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 193s 641us/step - loss: 0.4305 - acc: 0.7302 - f1: 0.7253 - precision_measure: 0.7383 - recall_measure: 0.7130 - val_loss: 0.7658 - val_acc: 0.5535 - val_f1: 0.5486 - val_precision_measure: 0.5537 - val_recall_measure: 0.5440\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 301s 999us/step - loss: 0.4017 - acc: 0.7574 - f1: 0.7536 - precision_measure: 0.7650 - recall_measure: 0.7426 - val_loss: 0.8943 - val_acc: 0.5130 - val_f1: 0.5082 - val_precision_measure: 0.5150 - val_recall_measure: 0.5022\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 416s 1ms/step - loss: 0.3833 - acc: 0.7783 - f1: 0.7754 - precision_measure: 0.7854 - recall_measure: 0.7658 - val_loss: 0.6824 - val_acc: 0.6373 - val_f1: 0.6349 - val_precision_measure: 0.6384 - val_recall_measure: 0.6317\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 291s 964us/step - loss: 0.3687 - acc: 0.7935 - f1: 0.7911 - precision_measure: 0.7994 - recall_measure: 0.7831 - val_loss: 0.6722 - val_acc: 0.6742 - val_f1: 0.6700 - val_precision_measure: 0.6750 - val_recall_measure: 0.6655\n",
      "33762/33762 [==============================] - 13s 376us/step\n",
      "Fitting  40 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 288s 956us/step - loss: 0.8784 - acc: 0.4756 - f1: 0.3612 - precision_measure: 0.5244 - recall_measure: 0.3061 - val_loss: 0.8145 - val_acc: 0.3049 - val_f1: 0.2906 - val_precision_measure: 0.3038 - val_recall_measure: 0.2805\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 181s 600us/step - loss: 0.5416 - acc: 0.5482 - f1: 0.5219 - precision_measure: 0.5510 - recall_measure: 0.4966 - val_loss: 0.7919 - val_acc: 0.5186 - val_f1: 0.5096 - val_precision_measure: 0.5189 - val_recall_measure: 0.5018\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 246s 814us/step - loss: 0.4812 - acc: 0.6657 - f1: 0.6558 - precision_measure: 0.6726 - recall_measure: 0.6403 - val_loss: 0.7203 - val_acc: 0.5695 - val_f1: 0.5646 - val_precision_measure: 0.5709 - val_recall_measure: 0.5591\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 182s 604us/step - loss: 0.4410 - acc: 0.7147 - f1: 0.7091 - precision_measure: 0.7222 - recall_measure: 0.6968 - val_loss: 0.6557 - val_acc: 0.6716 - val_f1: 0.6578 - val_precision_measure: 0.6713 - val_recall_measure: 0.6465\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 186s 617us/step - loss: 0.4152 - acc: 0.7487 - f1: 0.7445 - precision_measure: 0.7563 - recall_measure: 0.7334 - val_loss: 0.6789 - val_acc: 0.6389 - val_f1: 0.6320 - val_precision_measure: 0.6403 - val_recall_measure: 0.6248\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 226s 750us/step - loss: 0.3879 - acc: 0.7781 - f1: 0.7749 - precision_measure: 0.7846 - recall_measure: 0.7656 - val_loss: 0.7846 - val_acc: 0.6134 - val_f1: 0.6069 - val_precision_measure: 0.6152 - val_recall_measure: 0.5995\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 227s 752us/step - loss: 0.3662 - acc: 0.7927 - f1: 0.7906 - precision_measure: 0.7987 - recall_measure: 0.7829 - val_loss: 0.8076 - val_acc: 0.5796 - val_f1: 0.5745 - val_precision_measure: 0.5824 - val_recall_measure: 0.5679\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 224s 742us/step - loss: 0.3624 - acc: 0.8003 - f1: 0.7980 - precision_measure: 0.8054 - recall_measure: 0.7909 - val_loss: 0.4417 - val_acc: 0.8361 - val_f1: 0.8352 - val_precision_measure: 0.8380 - val_recall_measure: 0.8325\n",
      "33762/33762 [==============================] - 13s 398us/step\n",
      "Fitting  41 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 242s 802us/step - loss: 0.7515 - acc: 0.4734 - f1: 0.4080 - precision_measure: 0.5112 - recall_measure: 0.3636 - val_loss: 0.8810 - val_acc: 0.2823 - val_f1: 0.2740 - val_precision_measure: 0.2827 - val_recall_measure: 0.2675\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 209s 692us/step - loss: 0.5452 - acc: 0.4580 - f1: 0.4346 - precision_measure: 0.4653 - recall_measure: 0.4087 - val_loss: 0.8436 - val_acc: 0.2976 - val_f1: 0.2865 - val_precision_measure: 0.2942 - val_recall_measure: 0.2806\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 207s 688us/step - loss: 0.5177 - acc: 0.5048 - f1: 0.4746 - precision_measure: 0.5037 - recall_measure: 0.4496 - val_loss: 0.9269 - val_acc: 0.3111 - val_f1: 0.2949 - val_precision_measure: 0.3065 - val_recall_measure: 0.2865\n",
      "Epoch 4/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 273s 906us/step - loss: 0.4753 - acc: 0.6369 - f1: 0.6214 - precision_measure: 0.6409 - recall_measure: 0.6036 - val_loss: 0.7970 - val_acc: 0.5633 - val_f1: 0.5493 - val_precision_measure: 0.5611 - val_recall_measure: 0.5397\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 223s 741us/step - loss: 0.4388 - acc: 0.6903 - f1: 0.6828 - precision_measure: 0.6966 - recall_measure: 0.6698 - val_loss: 0.7217 - val_acc: 0.5997 - val_f1: 0.5930 - val_precision_measure: 0.5992 - val_recall_measure: 0.5877\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 238s 789us/step - loss: 0.4161 - acc: 0.7208 - f1: 0.7160 - precision_measure: 0.7275 - recall_measure: 0.7050 - val_loss: 0.7697 - val_acc: 0.5393 - val_f1: 0.5305 - val_precision_measure: 0.5384 - val_recall_measure: 0.5237\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 193s 641us/step - loss: 0.4013 - acc: 0.7342 - f1: 0.7285 - precision_measure: 0.7398 - recall_measure: 0.7178 - val_loss: 0.6100 - val_acc: 0.6772 - val_f1: 0.6741 - val_precision_measure: 0.6777 - val_recall_measure: 0.6708\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 222s 735us/step - loss: 0.3652 - acc: 0.7890 - f1: 0.7864 - precision_measure: 0.7949 - recall_measure: 0.7782 - val_loss: 0.8681 - val_acc: 0.7903 - val_f1: 0.7888 - val_precision_measure: 0.7949 - val_recall_measure: 0.7832\n",
      "33762/33762 [==============================] - 15s 437us/step\n",
      "Fitting  42 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 249s 826us/step - loss: 0.7475 - acc: 0.4709 - f1: 0.3903 - precision_measure: 0.5001 - recall_measure: 0.3472 - val_loss: 0.8065 - val_acc: 0.2955 - val_f1: 0.2769 - val_precision_measure: 0.2926 - val_recall_measure: 0.2656\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 266s 881us/step - loss: 0.5139 - acc: 0.5595 - f1: 0.5345 - precision_measure: 0.5613 - recall_measure: 0.5112 - val_loss: 0.7832 - val_acc: 0.5719 - val_f1: 0.5652 - val_precision_measure: 0.5730 - val_recall_measure: 0.5589\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 306s 1ms/step - loss: 0.4543 - acc: 0.7048 - f1: 0.6970 - precision_measure: 0.7127 - recall_measure: 0.6823 - val_loss: 0.7425 - val_acc: 0.6384 - val_f1: 0.6318 - val_precision_measure: 0.6386 - val_recall_measure: 0.6260\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 396s 1ms/step - loss: 0.4103 - acc: 0.7604 - f1: 0.7565 - precision_measure: 0.7675 - recall_measure: 0.7460 - val_loss: 0.7767 - val_acc: 0.6342 - val_f1: 0.6292 - val_precision_measure: 0.6357 - val_recall_measure: 0.6233\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 349s 1ms/step - loss: 0.3969 - acc: 0.7724 - f1: 0.7694 - precision_measure: 0.7803 - recall_measure: 0.7591 - val_loss: 0.5308 - val_acc: 0.8406 - val_f1: 0.8345 - val_precision_measure: 0.8460 - val_recall_measure: 0.8242\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 356s 1ms/step - loss: 0.3686 - acc: 0.7988 - f1: 0.7961 - precision_measure: 0.8055 - recall_measure: 0.7871 - val_loss: 0.8140 - val_acc: 0.5985 - val_f1: 0.5952 - val_precision_measure: 0.5997 - val_recall_measure: 0.5911\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 326s 1ms/step - loss: 0.3489 - acc: 0.8097 - f1: 0.8076 - precision_measure: 0.8155 - recall_measure: 0.8001 - val_loss: 0.6636 - val_acc: 0.6834 - val_f1: 0.6825 - val_precision_measure: 0.6850 - val_recall_measure: 0.6802\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 341s 1ms/step - loss: 0.3387 - acc: 0.8179 - f1: 0.8162 - precision_measure: 0.8230 - recall_measure: 0.8098 - val_loss: 0.5648 - val_acc: 0.7152 - val_f1: 0.7141 - val_precision_measure: 0.7166 - val_recall_measure: 0.7117\n",
      "33762/33762 [==============================] - 17s 509us/step\n",
      "Fitting  43 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 304s 1ms/step - loss: 0.7161 - acc: 0.4838 - f1: 0.4162 - precision_measure: 0.5084 - recall_measure: 0.3744 - val_loss: 0.7590 - val_acc: 0.3348 - val_f1: 0.3208 - val_precision_measure: 0.3344 - val_recall_measure: 0.3107\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 327s 1ms/step - loss: 0.5110 - acc: 0.5582 - f1: 0.5384 - precision_measure: 0.5645 - recall_measure: 0.5158 - val_loss: 0.8085 - val_acc: 0.4429 - val_f1: 0.4337 - val_precision_measure: 0.4414 - val_recall_measure: 0.4273\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 207s 685us/step - loss: 0.4427 - acc: 0.6983 - f1: 0.6905 - precision_measure: 0.7051 - recall_measure: 0.6768 - val_loss: 0.8769 - val_acc: 0.5199 - val_f1: 0.5139 - val_precision_measure: 0.5200 - val_recall_measure: 0.5085\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 201s 667us/step - loss: 0.4020 - acc: 0.7539 - f1: 0.7495 - precision_measure: 0.7599 - recall_measure: 0.7396 - val_loss: 0.5854 - val_acc: 0.7625 - val_f1: 0.7584 - val_precision_measure: 0.7666 - val_recall_measure: 0.7511\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 199s 659us/step - loss: 0.3741 - acc: 0.7861 - f1: 0.7835 - precision_measure: 0.7920 - recall_measure: 0.7754 - val_loss: 0.5960 - val_acc: 0.7232 - val_f1: 0.7185 - val_precision_measure: 0.7257 - val_recall_measure: 0.7119\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 200s 663us/step - loss: 0.3572 - acc: 0.8014 - f1: 0.7996 - precision_measure: 0.8073 - recall_measure: 0.7921 - val_loss: 0.6634 - val_acc: 0.6524 - val_f1: 0.6502 - val_precision_measure: 0.6532 - val_recall_measure: 0.6474\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 202s 670us/step - loss: 0.3408 - acc: 0.8136 - f1: 0.8118 - precision_measure: 0.8185 - recall_measure: 0.8054 - val_loss: 0.4554 - val_acc: 0.8277 - val_f1: 0.8264 - val_precision_measure: 0.8289 - val_recall_measure: 0.8241\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 197s 652us/step - loss: 0.3254 - acc: 0.8242 - f1: 0.8229 - precision_measure: 0.8289 - recall_measure: 0.8170 - val_loss: 0.6155 - val_acc: 0.7537 - val_f1: 0.7446 - val_precision_measure: 0.7589 - val_recall_measure: 0.7321\n",
      "33762/33762 [==============================] - 14s 422us/step\n",
      "Fitting  44 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 221s 732us/step - loss: 0.7498 - acc: 0.4812 - f1: 0.4058 - precision_measure: 0.5153 - recall_measure: 0.3595 - val_loss: 0.8322 - val_acc: 0.2828 - val_f1: 0.2663 - val_precision_measure: 0.2759 - val_recall_measure: 0.2590\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 204s 676us/step - loss: 0.5198 - acc: 0.5213 - f1: 0.4992 - precision_measure: 0.5258 - recall_measure: 0.4761 - val_loss: 0.7532 - val_acc: 0.5077 - val_f1: 0.4965 - val_precision_measure: 0.5083 - val_recall_measure: 0.4865\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 207s 685us/step - loss: 0.4575 - acc: 0.6789 - f1: 0.6689 - precision_measure: 0.6866 - recall_measure: 0.6527 - val_loss: 0.7045 - val_acc: 0.6246 - val_f1: 0.6133 - val_precision_measure: 0.6236 - val_recall_measure: 0.6047\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 209s 694us/step - loss: 0.4032 - acc: 0.7588 - f1: 0.7539 - precision_measure: 0.7663 - recall_measure: 0.7422 - val_loss: 0.6887 - val_acc: 0.6563 - val_f1: 0.6533 - val_precision_measure: 0.6568 - val_recall_measure: 0.6503\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 208s 689us/step - loss: 0.3712 - acc: 0.7957 - f1: 0.7928 - precision_measure: 0.8019 - recall_measure: 0.7840 - val_loss: 0.5944 - val_acc: 0.7138 - val_f1: 0.7097 - val_precision_measure: 0.7157 - val_recall_measure: 0.7043\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 209s 694us/step - loss: 0.3545 - acc: 0.8081 - f1: 0.8060 - precision_measure: 0.8142 - recall_measure: 0.7981 - val_loss: 0.4519 - val_acc: 0.8361 - val_f1: 0.8336 - val_precision_measure: 0.8383 - val_recall_measure: 0.8294\n",
      "Epoch 7/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 187s 618us/step - loss: 0.3357 - acc: 0.8178 - f1: 0.8161 - precision_measure: 0.8236 - recall_measure: 0.8089 - val_loss: 0.6734 - val_acc: 0.6873 - val_f1: 0.6848 - val_precision_measure: 0.6880 - val_recall_measure: 0.6817\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 183s 607us/step - loss: 0.3240 - acc: 0.8279 - f1: 0.8263 - precision_measure: 0.8330 - recall_measure: 0.8199 - val_loss: 0.4845 - val_acc: 0.8076 - val_f1: 0.8070 - val_precision_measure: 0.8085 - val_recall_measure: 0.8055\n",
      "33762/33762 [==============================] - 10s 293us/step\n",
      "Fitting  45 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 329s 1ms/step - loss: 0.7061 - acc: 0.4596 - f1: 0.3899 - precision_measure: 0.4773 - recall_measure: 0.3477 - val_loss: 0.8388 - val_acc: 0.2599 - val_f1: 0.2444 - val_precision_measure: 0.2595 - val_recall_measure: 0.2351\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 226s 748us/step - loss: 0.5195 - acc: 0.4695 - f1: 0.4333 - precision_measure: 0.4648 - recall_measure: 0.4073 - val_loss: 0.7992 - val_acc: 0.4536 - val_f1: 0.4319 - val_precision_measure: 0.4500 - val_recall_measure: 0.4174\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 195s 647us/step - loss: 0.4598 - acc: 0.6578 - f1: 0.6460 - precision_measure: 0.6630 - recall_measure: 0.6303 - val_loss: 0.7079 - val_acc: 0.5889 - val_f1: 0.5787 - val_precision_measure: 0.5879 - val_recall_measure: 0.5708\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 199s 661us/step - loss: 0.4170 - acc: 0.7416 - f1: 0.7360 - precision_measure: 0.7493 - recall_measure: 0.7235 - val_loss: 0.6811 - val_acc: 0.6342 - val_f1: 0.6299 - val_precision_measure: 0.6344 - val_recall_measure: 0.6258\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 196s 649us/step - loss: 0.3926 - acc: 0.7658 - f1: 0.7613 - precision_measure: 0.7727 - recall_measure: 0.7506 - val_loss: 0.5097 - val_acc: 0.7833 - val_f1: 0.7785 - val_precision_measure: 0.7891 - val_recall_measure: 0.7693\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 194s 642us/step - loss: 0.3675 - acc: 0.7929 - f1: 0.7899 - precision_measure: 0.7995 - recall_measure: 0.7806 - val_loss: 0.6179 - val_acc: 0.7197 - val_f1: 0.7176 - val_precision_measure: 0.7234 - val_recall_measure: 0.7125\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 196s 651us/step - loss: 0.3378 - acc: 0.8120 - f1: 0.8102 - precision_measure: 0.8181 - recall_measure: 0.8026 - val_loss: 0.3806 - val_acc: 0.8782 - val_f1: 0.8757 - val_precision_measure: 0.8804 - val_recall_measure: 0.8713\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 195s 646us/step - loss: 0.3342 - acc: 0.8162 - f1: 0.8144 - precision_measure: 0.8222 - recall_measure: 0.8069 - val_loss: 0.3367 - val_acc: 0.8727 - val_f1: 0.8717 - val_precision_measure: 0.8737 - val_recall_measure: 0.8698\n",
      "33762/33762 [==============================] - 12s 362us/step\n",
      "Fitting  46 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 211s 700us/step - loss: 0.6885 - acc: 0.4697 - f1: 0.4062 - precision_measure: 0.4826 - recall_measure: 0.3636 - val_loss: 0.8556 - val_acc: 0.3492 - val_f1: 0.2629 - val_precision_measure: 0.3182 - val_recall_measure: 0.2429\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 207s 688us/step - loss: 0.5039 - acc: 0.5965 - f1: 0.5708 - precision_measure: 0.5981 - recall_measure: 0.5470 - val_loss: 0.8066 - val_acc: 0.6125 - val_f1: 0.5885 - val_precision_measure: 0.6174 - val_recall_measure: 0.5666\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 213s 707us/step - loss: 0.4318 - acc: 0.7216 - f1: 0.7154 - precision_measure: 0.7280 - recall_measure: 0.7036 - val_loss: 0.6567 - val_acc: 0.6385 - val_f1: 0.6326 - val_precision_measure: 0.6392 - val_recall_measure: 0.6267\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 421s 1ms/step - loss: 0.3818 - acc: 0.7784 - f1: 0.7754 - precision_measure: 0.7844 - recall_measure: 0.7667 - val_loss: 0.5035 - val_acc: 0.7548 - val_f1: 0.7535 - val_precision_measure: 0.7573 - val_recall_measure: 0.7500\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 520s 2ms/step - loss: 0.3595 - acc: 0.8004 - f1: 0.7985 - precision_measure: 0.8059 - recall_measure: 0.7915 - val_loss: 0.4254 - val_acc: 0.8452 - val_f1: 0.8444 - val_precision_measure: 0.8474 - val_recall_measure: 0.8416\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 371s 1ms/step - loss: 0.3372 - acc: 0.8151 - f1: 0.8138 - precision_measure: 0.8206 - recall_measure: 0.8072 - val_loss: 0.6077 - val_acc: 0.6614 - val_f1: 0.6584 - val_precision_measure: 0.6626 - val_recall_measure: 0.6546\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 408s 1ms/step - loss: 0.3276 - acc: 0.8191 - f1: 0.8176 - precision_measure: 0.8239 - recall_measure: 0.8115 - val_loss: 0.4494 - val_acc: 0.8074 - val_f1: 0.8055 - val_precision_measure: 0.8090 - val_recall_measure: 0.8022\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 293s 971us/step - loss: 0.3291 - acc: 0.8166 - f1: 0.8149 - precision_measure: 0.8214 - recall_measure: 0.8088 - val_loss: 0.4124 - val_acc: 0.8494 - val_f1: 0.8482 - val_precision_measure: 0.8520 - val_recall_measure: 0.8447\n",
      "33762/33762 [==============================] - 30s 895us/step\n",
      "Fitting  47 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 285s 944us/step - loss: 0.6535 - acc: 0.4993 - f1: 0.4480 - precision_measure: 0.5162 - recall_measure: 0.4089 - val_loss: 0.7920 - val_acc: 0.6711 - val_f1: 0.6410 - val_precision_measure: 0.6889 - val_recall_measure: 0.6090\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 241s 799us/step - loss: 0.4785 - acc: 0.6390 - f1: 0.6241 - precision_measure: 0.6487 - recall_measure: 0.6023 - val_loss: 0.9096 - val_acc: 0.5392 - val_f1: 0.5261 - val_precision_measure: 0.5374 - val_recall_measure: 0.5169\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 242s 802us/step - loss: 0.4038 - acc: 0.7634 - f1: 0.7584 - precision_measure: 0.7720 - recall_measure: 0.7455 - val_loss: 0.7842 - val_acc: 0.5655 - val_f1: 0.5575 - val_precision_measure: 0.5638 - val_recall_measure: 0.5520\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 395s 1ms/step - loss: 0.3654 - acc: 0.7953 - f1: 0.7925 - precision_measure: 0.8022 - recall_measure: 0.7832 - val_loss: 0.5164 - val_acc: 0.7838 - val_f1: 0.7820 - val_precision_measure: 0.7854 - val_recall_measure: 0.7787\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 219s 728us/step - loss: 0.3376 - acc: 0.8156 - f1: 0.8139 - precision_measure: 0.8212 - recall_measure: 0.8069 - val_loss: 0.4749 - val_acc: 0.7840 - val_f1: 0.7831 - val_precision_measure: 0.7855 - val_recall_measure: 0.7808\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 214s 711us/step - loss: 0.3281 - acc: 0.8239 - f1: 0.8224 - precision_measure: 0.8296 - recall_measure: 0.8155 - val_loss: 0.4784 - val_acc: 0.7995 - val_f1: 0.7984 - val_precision_measure: 0.8021 - val_recall_measure: 0.7950\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 207s 686us/step - loss: 0.3159 - acc: 0.8284 - f1: 0.8272 - precision_measure: 0.8336 - recall_measure: 0.8210 - val_loss: 0.4950 - val_acc: 0.8021 - val_f1: 0.8008 - val_precision_measure: 0.8056 - val_recall_measure: 0.7964\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 222s 735us/step - loss: 0.2973 - acc: 0.8380 - f1: 0.8371 - precision_measure: 0.8418 - recall_measure: 0.8325 - val_loss: 0.3739 - val_acc: 0.8564 - val_f1: 0.8558 - val_precision_measure: 0.8578 - val_recall_measure: 0.8540\n",
      "33762/33762 [==============================] - 16s 466us/step\n",
      "Fitting  48 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 302s 1ms/step - loss: 0.6530 - acc: 0.5406 - f1: 0.4850 - precision_measure: 0.5525 - recall_measure: 0.4463 - val_loss: 0.7665 - val_acc: 0.6180 - val_f1: 0.5966 - val_precision_measure: 0.6188 - val_recall_measure: 0.5787\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 275s 911us/step - loss: 0.4464 - acc: 0.7241 - f1: 0.7151 - precision_measure: 0.7324 - recall_measure: 0.6991 - val_loss: 0.5692 - val_acc: 0.7431 - val_f1: 0.7377 - val_precision_measure: 0.7444 - val_recall_measure: 0.7315\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 280s 929us/step - loss: 0.3809 - acc: 0.7920 - f1: 0.7889 - precision_measure: 0.7993 - recall_measure: 0.7789 - val_loss: 0.5787 - val_acc: 0.7232 - val_f1: 0.7181 - val_precision_measure: 0.7235 - val_recall_measure: 0.7132\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 307s 1ms/step - loss: 0.3489 - acc: 0.8112 - f1: 0.8095 - precision_measure: 0.8178 - recall_measure: 0.8015 - val_loss: 0.4751 - val_acc: 0.8083 - val_f1: 0.8064 - val_precision_measure: 0.8107 - val_recall_measure: 0.8023\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 225s 745us/step - loss: 0.3271 - acc: 0.8265 - f1: 0.8254 - precision_measure: 0.8322 - recall_measure: 0.8189 - val_loss: 0.4894 - val_acc: 0.8030 - val_f1: 0.8013 - val_precision_measure: 0.8069 - val_recall_measure: 0.7962\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 211s 701us/step - loss: 0.3154 - acc: 0.8336 - f1: 0.8327 - precision_measure: 0.8385 - recall_measure: 0.8271 - val_loss: 0.6348 - val_acc: 0.6877 - val_f1: 0.6867 - val_precision_measure: 0.6881 - val_recall_measure: 0.6852\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 208s 691us/step - loss: 0.2989 - acc: 0.8424 - f1: 0.8417 - precision_measure: 0.8465 - recall_measure: 0.8370 - val_loss: 0.4491 - val_acc: 0.8125 - val_f1: 0.8107 - val_precision_measure: 0.8152 - val_recall_measure: 0.8065\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 204s 675us/step - loss: 0.2930 - acc: 0.8421 - f1: 0.8411 - precision_measure: 0.8462 - recall_measure: 0.8361 - val_loss: 0.5924 - val_acc: 0.7920 - val_f1: 0.7873 - val_precision_measure: 0.7972 - val_recall_measure: 0.7783\n",
      "33762/33762 [==============================] - 15s 445us/step\n",
      "7\n",
      "0.8655490393539087\n",
      "<keras.callbacks.History object at 0x1307a0d90>\n"
     ]
    }
   ],
   "source": [
    "# Define the dropout grid\n",
    "dropout_grid = [0.1, 0.5, 0.9]\n",
    "l1_grid = [2**-5, 2**-6, 2**-7, 2**-8]\n",
    "l2_grid = [2**-5, 2**-6, 2**-7, 2**-8]\n",
    "tot = len(dropout_grid) * len(l1_grid) * len(l2_grid)\n",
    "\n",
    "# Variables for the best result\n",
    "scores = []\n",
    "best_history = [] # place holder\n",
    "best_ind = 0\n",
    "best_acc = 0\n",
    "\n",
    "# Loop through each combination\n",
    "pos = 0\n",
    "for ii in dropout_grid:\n",
    "    for jj in l1_grid:\n",
    "        for kk in l2_grid:\n",
    "            pos = pos + 1\n",
    "            print(\"Fitting \", pos, \"/\", tot , \" model\")\n",
    "            # define the model\n",
    "            curr_model = define_LSTM_model(ii, jj, kk)\n",
    "            #curr_model.summary()\n",
    "            \n",
    "            # train the model\n",
    "            curr_history = curr_model.fit(training_X, training_y_encoded, epochs = 8, batch_size = 64, \n",
    "                                     validation_data = (val_X, val_y_encoded), class_weight = label_weights, \n",
    "                                     verbose = 1)\n",
    "            curr_acc = st.mean(curr_history.history['val_acc'][5:10])\n",
    "                        \n",
    "            # get prediction report\n",
    "            y_pred = curr_model.predict(val_X, batch_size=64, verbose=1)\n",
    "            y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "            scores.append(classification_report(val_y, y_pred_bool))\n",
    "            \n",
    "            # save the best result\n",
    "            if best_acc < curr_acc:\n",
    "                best_acc = curr_acc\n",
    "                best_ind = pos - 1\n",
    "                best_history = curr_history\n",
    "\n",
    "# Display best best_ind, best_acc, and best_history\n",
    "print(best_ind)\n",
    "print(best_acc)\n",
    "print(best_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-karen",
   "metadata": {},
   "source": [
    "The above hyperparamter search for this LSTM returns that index 7 is the best index combination of hyperparameters, returning an accuracy of 0.8655490393539087. The hyperparamters that correspond to this index are found in 'Fitting Model 8 / 48' (results are in log file). They are `dropout_rate` = 0.1, `l1` = 2e-6, `l2` = 2e-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "wrong-narrative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_60 (LSTM)               (None, 125)               66000     \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 125)               15750     \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 4)                 504       \n",
      "=================================================================\n",
      "Total params: 82,254\n",
      "Trainable params: 82,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/15\n",
      "301655/301655 [==============================] - 314s 1ms/step - loss: 0.6236 - acc: 0.5876 - f1: 0.5467 - precision_measure: 0.6039 - recall_measure: 0.5168 - val_loss: 0.8067 - val_acc: 0.5714 - val_f1: 0.5557 - val_precision_measure: 0.5743 - val_recall_measure: 0.5406\n",
      "Epoch 2/15\n",
      "301655/301655 [==============================] - 214s 710us/step - loss: 0.3948 - acc: 0.7571 - f1: 0.7537 - precision_measure: 0.7635 - recall_measure: 0.7443 - val_loss: 0.5173 - val_acc: 0.8468 - val_f1: 0.8403 - val_precision_measure: 0.8533 - val_recall_measure: 0.8293\n",
      "Epoch 3/15\n",
      "301655/301655 [==============================] - 209s 693us/step - loss: 0.3339 - acc: 0.8098 - f1: 0.8086 - precision_measure: 0.8144 - recall_measure: 0.8030 - val_loss: 0.4779 - val_acc: 0.8300 - val_f1: 0.8288 - val_precision_measure: 0.8324 - val_recall_measure: 0.8255\n",
      "Epoch 4/15\n",
      "301655/301655 [==============================] - 212s 702us/step - loss: 0.2920 - acc: 0.8388 - f1: 0.8383 - precision_measure: 0.8417 - recall_measure: 0.8350 - val_loss: 0.5367 - val_acc: 0.7941 - val_f1: 0.7925 - val_precision_measure: 0.7964 - val_recall_measure: 0.7889\n",
      "Epoch 5/15\n",
      "301655/301655 [==============================] - 209s 693us/step - loss: 0.2636 - acc: 0.8583 - f1: 0.8581 - precision_measure: 0.8602 - recall_measure: 0.8560 - val_loss: 0.4313 - val_acc: 0.8495 - val_f1: 0.8484 - val_precision_measure: 0.8516 - val_recall_measure: 0.8454\n",
      "Epoch 6/15\n",
      "301655/301655 [==============================] - 207s 685us/step - loss: 0.2365 - acc: 0.8726 - f1: 0.8724 - precision_measure: 0.8737 - recall_measure: 0.8711 - val_loss: 0.4749 - val_acc: 0.8215 - val_f1: 0.8212 - val_precision_measure: 0.8222 - val_recall_measure: 0.8203\n",
      "Epoch 7/15\n",
      "301655/301655 [==============================] - 208s 688us/step - loss: 0.2187 - acc: 0.8858 - f1: 0.8856 - precision_measure: 0.8867 - recall_measure: 0.8846 - val_loss: 0.3951 - val_acc: 0.8693 - val_f1: 0.8688 - val_precision_measure: 0.8704 - val_recall_measure: 0.8672\n",
      "Epoch 8/15\n",
      "301655/301655 [==============================] - 218s 722us/step - loss: 0.2018 - acc: 0.8955 - f1: 0.8954 - precision_measure: 0.8963 - recall_measure: 0.8945 - val_loss: 0.4044 - val_acc: 0.8599 - val_f1: 0.8596 - val_precision_measure: 0.8605 - val_recall_measure: 0.8587\n",
      "Epoch 9/15\n",
      "301655/301655 [==============================] - 206s 682us/step - loss: 0.1831 - acc: 0.9078 - f1: 0.9078 - precision_measure: 0.9084 - recall_measure: 0.9072 - val_loss: 0.3529 - val_acc: 0.8897 - val_f1: 0.8893 - val_precision_measure: 0.8901 - val_recall_measure: 0.8885\n",
      "Epoch 10/15\n",
      "301655/301655 [==============================] - 209s 694us/step - loss: 0.1726 - acc: 0.9154 - f1: 0.9153 - precision_measure: 0.9158 - recall_measure: 0.9149 - val_loss: 0.4385 - val_acc: 0.8523 - val_f1: 0.8521 - val_precision_measure: 0.8526 - val_recall_measure: 0.8516\n",
      "Epoch 11/15\n",
      "301655/301655 [==============================] - 298s 987us/step - loss: 0.1604 - acc: 0.9240 - f1: 0.9240 - precision_measure: 0.9244 - recall_measure: 0.9236 - val_loss: 0.3547 - val_acc: 0.8952 - val_f1: 0.8951 - val_precision_measure: 0.8953 - val_recall_measure: 0.8949\n",
      "Epoch 12/15\n",
      "301655/301655 [==============================] - 260s 861us/step - loss: 0.1504 - acc: 0.9313 - f1: 0.9312 - precision_measure: 0.9316 - recall_measure: 0.9309 - val_loss: 0.5406 - val_acc: 0.8180 - val_f1: 0.8177 - val_precision_measure: 0.8193 - val_recall_measure: 0.8162\n",
      "Epoch 13/15\n",
      "301655/301655 [==============================] - 212s 704us/step - loss: 0.1370 - acc: 0.9397 - f1: 0.9397 - precision_measure: 0.9399 - recall_measure: 0.9394 - val_loss: 0.4485 - val_acc: 0.8662 - val_f1: 0.8661 - val_precision_measure: 0.8665 - val_recall_measure: 0.8657\n",
      "Epoch 14/15\n",
      "301655/301655 [==============================] - 250s 828us/step - loss: 0.1331 - acc: 0.9444 - f1: 0.9444 - precision_measure: 0.9446 - recall_measure: 0.9442 - val_loss: 0.5076 - val_acc: 0.8356 - val_f1: 0.8355 - val_precision_measure: 0.8358 - val_recall_measure: 0.8352\n",
      "Epoch 15/15\n",
      "301655/301655 [==============================] - 341s 1ms/step - loss: 0.1223 - acc: 0.9507 - f1: 0.9507 - precision_measure: 0.9508 - recall_measure: 0.9505 - val_loss: 0.5007 - val_acc: 0.8584 - val_f1: 0.8583 - val_precision_measure: 0.8585 - val_recall_measure: 0.8581\n",
      "33762/33762 [==============================] - 8s 225us/step\n"
     ]
    }
   ],
   "source": [
    "# Optimal parameters: dropout_rate = 0.1, l1 = 2e-6, l2 = 2e-8\n",
    "best_history, best_accuracy, best_f1, best_precision, best_recall = evaluate_model(training_X, \n",
    "                                                                                   training_y_encoded, \n",
    "                                                                                   val_X, val_y_encoded, \n",
    "                                                                                   0.1, 2**-6, 2**-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "radio-integral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA3MElEQVR4nO3dd3hUdfb48fcJASIozYAiRUABEekBBKRGXduKBVRcCz/Xumt31xV11UX9qit2cRXdtWBhUVfEioqgIKhEBBFQBESNqPSitEDO748zIUNImzB37iRzXs9zn2m3nMDMnPl0UVWcc86lrrSwA3DOORcuTwTOOZfiPBE451yK80TgnHMpzhOBc86lOE8EzjmX4jwROOdcivNE4FwJRGSZiBwZdhzOBc0TgXPOpThPBM7FQERqisj9IrI8st0vIjUjr2WKyOsisk5E1ojINBFJi7z2NxH5UUQ2isjXIpId7l/iXKH0sANwrpK5ATgc6Awo8CpwI/B34BogF2gY2fdwQEWkLXAp0F1Vl4tIC6BaYsN2rmReInAuNn8ARqrqClVdCfwDODvyWh7QGDhQVfNUdZraZF47gJrAoSJSXVWXqeqSUKJ3rhieCJyLzQHAd1GPv4s8B3A3sBh4R0SWish1AKq6GLgSuAVYISLjROQAnEsSngici81y4MCox80jz6GqG1X1GlVtBZwIXF3QFqCqz6vqEZFjFbgrsWE7VzJPBM6VrrqIZBRswAvAjSLSUEQygZuAZwFE5AQROVhEBFiPVQnli0hbERkUaVTeAmwG8sP5c5zbnScC50r3JvbFXbBlADnAF8A8YDZwW2Tf1sB7wK/ATOARVZ2CtQ/cCawCfgYaASMS9yc4VzrxhWmccy61eYnAOedSnCcC55xLcZ4InHMuxXkicM65FFfpppjIzMzUFi1ahB2Gc85VKp999tkqVW1Y3GuVLhG0aNGCnJycsMNwzrlKRUS+K+k1rxpyzrkU54nAOedSnCcC55xLcZWujcA5V3Xk5eWRm5vLli1bwg6lysjIyKBp06ZUr1693Md4InDOhSY3N5d99tmHFi1aYHP1uT2hqqxevZrc3FxatmxZ7uO8asg5F5otW7aw7777ehKIExFh3333jbmE5YnAORcqTwLxVZF/z0ATgYgcE1moe3HBak1FXm8uIlNE5HMR+UJEjgssmJkz4brrwGdbdc65XQSWCESkGjAaOBY4FBgmIocW2e1GYLyqdgHOAB4JKh5mz4a77oKlSwO7hHOuclm9ejWdO3emc+fO7L///jRp0mTn423btpV6bE5ODpdffnmCIg1WkI3FPYDFqroUQETGAYOBBVH7KFAncr8ukSX/ApGdbbfvvw8HHRTYZZxzlce+++7LnDlzALjlllvYe++9+ctf/rLz9e3bt5OeXvzXZFZWFllZWYkIM3BBVg01AX6IepwbeS7aLcBZIpKLrQR1WXEnEpELRSRHRHJWrlxZsWjatoXGjWHy5Iod75xLCcOHD+fiiy+mZ8+eXHvttXz66af06tWLLl260Lt3b77++msApk6dygknnABYEjnvvPMYMGAArVq14sEHHwzzT4hZ2N1HhwFPqeo9ItILGCsih6nqLuu5quoYYAxAVlZWxSr5RaxUMGkS5OdDmreTO5dMrrwSIj/O46ZzZ7j//tiPy83NZcaMGVSrVo0NGzYwbdo00tPTee+997j++ut5+eWXdzvmq6++YsqUKWzcuJG2bdtyySWXxNSXP0xBJoIfgWZRj5tGnov2R+AYAFWdGVkcPBNYEUhEgwbBs8/C/PnQoUMgl3DOVX5Dhw6lWrVqAKxfv55zzz2Xb775BhEhLy+v2GOOP/54atasSc2aNWnUqBG//PILTZs2TWTYFRZkIpgFtBaRllgCOAM4s8g+3wPZwFMi0g5bGLyCdT/lUNBOMHmyJwLnkkxFfrkHpXbt2jvv//3vf2fgwIG88sorLFu2jAEDBhR7TM2aNXfer1atGtu3bw86zLgJrH5EVbcDlwKTgIVY76D5IjJSRE6M7HYNcIGIzAVeAIarBti/s3lzOPhgazB2zrlyWL9+PU2aWPPmU089FW4wAQm0olxV31TVNqp6kKreHnnuJlWdGLm/QFX7qGonVe2squ8EGQ9g1UMffACVKFs758Jz7bXXMmLECLp06VKpfuXHQoL8AR6ErKws3aOFacaPh9NPh48/hp494xeYcy5mCxcupF27dmGHUeUU9+8qIp+parH9XVOv68zAgXbr3Uidcw5IxUTQsCF07OiJwDnnIlIvEYC1E3z0Efgc6M45l6KJIDsbtm6FGTPCjsQ550KXmomgXz+oVs27kTrnHKmaCOrUge7dvZ3AOedI1UQAVj00axZs2BB2JM65kAwcOJBJkybt8tz999/PJZdcUuz+AwYMoKD7+nHHHce6det22+eWW25h1KhRpV53woQJLFhQOBHzTTfdxHvvvRdj9PGTuolg0CDYsQM+/DDsSJxzIRk2bBjjxo3b5blx48YxbNiwMo998803qVevXoWuWzQRjBw5kiOPPLJC54qH1E0EvXtDRoZXDzmXwoYMGcIbb7yxcxGaZcuWsXz5cl544QWysrJo3749N998c7HHtmjRglWrVgFw++2306ZNG4444oid01QDPP7443Tv3p1OnTpx6qmnsmnTJmbMmMHEiRP561//SufOnVmyZAnDhw/npZdeAmDy5Ml06dKFDh06cN5557F169ad17v55pvp2rUrHTp04Kuvvorbv0PY01CHJyMD+vTxBmPnkkUI81A3aNCAHj168NZbbzF48GDGjRvHaaedxvXXX0+DBg3YsWMH2dnZfPHFF3Ts2LHYc3z22WeMGzeOOXPmsH37drp27Uq3bt0AOOWUU7jgggsAuPHGG/n3v//NZZddxoknnsgJJ5zAkCFDdjnXli1bGD58OJMnT6ZNmzacc845/Otf/+LKK68EIDMzk9mzZ/PII48watQonnjiiT3+J4JULhGAVQ998QWsCGbWa+dc8ouuHiqoFho/fjxdu3alS5cuzJ8/f5dqnKKmTZvGySefTK1atahTpw4nnnjizte+/PJL+vbtS4cOHXjuueeYP39+qbF8/fXXtGzZkjZt2gBw7rnn8mFU9fUpp5wCQLdu3Vi2bFlF/+TdpG6JAKzB+IYbYOpUOO20sKNxLrWFNA/14MGDueqqq5g9ezabNm2iQYMGjBo1ilmzZlG/fn2GDx/OlgoOPh0+fDgTJkygU6dOPPXUU0ydOnWPYi2Y6jre01yndomgWzfrSurtBM6lrL333puBAwdy3nnnMWzYMDZs2EDt2rWpW7cuv/zyC2+99Vapx/fr148JEyawefNmNm7cyGuvvbbztY0bN9K4cWPy8vJ47rnndj6/zz77sHHjxt3O1bZtW5YtW8bixYsBGDt2LP3794/TX1qy1E4E6enQv78nAudS3LBhw5g7dy7Dhg2jU6dOdOnShUMOOYQzzzyTPn36lHps165dOf300+nUqRPHHnss3bt33/narbfeSs+ePenTpw+HHHLIzufPOOMM7r77brp06cKSJUt2Pp+RkcGTTz7J0KFD6dChA2lpaVx88cXx/4OLSL1pqIt64AFrpFq2DA48MH7ndc6VyaehDoZPQx2rQYPs1nsPOedSlCeCww6zqak9ETjnUpQnAhErFUyeDJWsmsy5qqCyVU8nu4r8e3oiAOtG+tNPEDUi0DkXvIyMDFavXu3JIE5UldWrV5ORkRHTcYGOIxCRY4AHgGrAE6p6Z5HX7wMia0dSC2ikqvWCjKlYBe0EkydDVMu+cy5YTZs2JTc3l5UrV4YdSpWRkZFB06ZNYzomsEQgItWA0cBRQC4wS0QmqurOIXqqelXU/pcBXYKKp1StWlmPocmT4c9/DiUE51JR9erVadmyZdhhpLwgq4Z6AItVdamqbgPGAYNL2X8Y8EKA8ZRMxKqHpk61GUmdcy6FBJkImgA/RD3OjTy3GxE5EGgJFNt1R0QuFJEcEckJrAg5aBCsXRv/Sa+ccy7JJUtj8RnAS6pa7M9xVR2jqlmqmtWwYcNgIvDxBM65FBVkIvgRaBb1uGnkueKcQVjVQgUaN4Z27Xy6CedcygkyEcwCWotISxGpgX3ZTyy6k4gcAtQHZgYYS/lkZ8O0aRBZpMI551JBYIlAVbcDlwKTgIXAeFWdLyIjReTEqF3PAMZpMnQkzs6GTZvgk0/CjsQ55xIm0HEEqvom8GaR524q8viWIGOISf/+kJZm1UN9+4YdjXPOJUSyNBYnh/r1oWtXbzB2zqUUTwRFDRoEH38Mv/0WdiTOOZcQngiKys6GvDyYPj3sSJxzLiE8ERR1xBFQvbp3I3XOpQxPBEXVqgW9enkicM6lDE8ExcnOhs8/hzVrwo7EOecC54mgOIMG2SI1U6eGHYlzzgXOE0FxevSA2rW9G6lzLiV4IihOjRrQr5+3EzjnUoIngpIMGgRffQU/ljRPnnPOVQ2eCEqSnW23U6aEG4dzzgXME0FJOnWCBg28esg5V+V5IihJWhoMHGgNxkkwMapzzgXFE0FpBg2C77+HJUvCjsQ55wLjiaA0Be0E3o3UOVeFpUwimDQJzjknxlqeNm2gSRNvJ3DOVWkpkwiWL4exY2H27BgOErHqofffh/z8wGJzzrkwpUwiGDwY0tPhpZdiPDA7G1atgi+/DCQu55wLW8okggYN7Dv9pZdirB4aNMhuvXrIOVdFpUwiABgyBBYvhrlzYzioWTNo3dobjJ1zVVagiUBEjhGRr0VksYhcV8I+p4nIAhGZLyLPBxnPSSdBtWoVrB764APYvj2IsJxzLlSBJQIRqQaMBo4FDgWGicihRfZpDYwA+qhqe+DKoOIByMyEAQPgxRcrUD20cSPk5AQVmnPOhSbIEkEPYLGqLlXVbcA4YHCRfS4ARqvqWgBVXRFgPIBVDy1aBPPnx3DQwIF26+0EzrkqKMhE0AT4IepxbuS5aG2ANiLykYh8LCLHFHciEblQRHJEJGflypV7FNTJJ9vsETFVD2Vm2txDngicc1VQ2I3F6UBrYAAwDHhcROoV3UlVx6hqlqpmNWzYcI8uuN9+ttTAiy/GeGB2NsyYAZs379H1nXMu2QSZCH4EmkU9bhp5LlouMFFV81T1W2ARlhgCNWQILFhgW7llZ8PWrZYMnHOuCgkyEcwCWotISxGpAZwBTCyyzwSsNICIZGJVRUsDjAmAU06xQcMvvxzDQX372og070bqnKtiAksEqroduBSYBCwExqvqfBEZKSInRnabBKwWkQXAFOCvqro6qJgKNG4MRxwRYzvBPvvYWsbeTuCcq2ICbSNQ1TdVtY2qHqSqt0eeu0lVJ0buq6peraqHqmoHVR0XZDzRhgyBL76wHkTlNmgQzJoF69cHFpdzziVa2I3FoTnlFLuNqVSQnW2Tz334YSAxOedcGFI2ETRtCr16xZgIDj8cMjK8esg5V6WkbCIAGDoUPv88hgXIMjKsccEbjJ1zVUhKJ4JTT7XbmKuH5s2DFYEPgnbOuYRI6UTQvLl1BIopERRMSz1lSiAxOedcoqV0IgDrPZSTA8uWlfOArl2hbl1vJ3DOVRmeCIbYbbkHl6WnQ//+ngicc1VGyieCli2hW7cKtBMsXRpDMcI555JXyicCsFLBxx/DDz+UvS9giQC895BzrkrwREBh76FyVw8deqhNY+qJwDlXBXgiwJYk7tQphuohEes9NHlyjEudOeditmIFjBgBa9aEHUmV5YkgYuhQ+Ogj+LHoRNklGTQIfv4ZFi4MNK64WrsWRo+GX38NOxLnym/UKLjzTjjjDF83PCCeCCIKeg/973/lPKCytRN8/rm1il96Kfz5z2FH41z5bN0K//kPHHggvPsuXHtt2BFVSZ4IItq2hcMOi6F6qGVL2ypDN9Knn4bevWHbNjjnHHjmGRiXsIlenau4l1+G1avh8cfh8svhvvvgqafCjqrK8UQQZcgQmDbNanzKZdAgmDoVduwIMqyK27oVLrkEhg+3GfZmz4Z//9vuX3wxfPdd2BE6V7rHHoODDrIS+D332O1FF8HMmWFHVqV4IogyZIi1/b7ySjkPyM6Gdeus2iXZ/PCDLc786KNWnH7nHWjUyAbEPfusTad91lle5+qS14IFNuX7RRdBWpq9d//7X5s6+JRTYmjQc2XxRBClfXto1y6Ghe0HDrTbZGsnmDzZpsJYuNDquu66yz5EBVq1skbj6dPhjjvCi9O50owZAzVqWIm2wL77wsSJ1uHhpJNg8+awoqtSPBEUMWQIfPBBOScX3X9/yx5jxiTHJHSq1rvi6KPt1/+sWYWDJIo66ywYNgz+8Q8bTedcMtm0ydq2Tj0VGjbc9bX27a1Um5MDF1zgXbjjwBNBEUOGWK3JhAnlPOCee6wuftAgOOoo+PTTIMMr2fr1VlweMcL6wn7yibWAl0QE/vUvK2b/4Q+wYUPiYnWuLOPHW7XrxRcX//rgwXDbbfDcc9a91O0ZVa1UW7du3TRI+fmqrVurHnVUDAdt3qx6772qmZmqoHrSSarz5gUW427mzbOgq1VTve8++yPKa/p01bQ01XPOCSw852J2+OGq7dqV/l7Oz1c97TRVEdU330xcbGXZulV1zZrYPocJAORoCd+rgX5pA8cAXwOLgeuKeX04sBKYE9nOL+ucQScCVdXrr7fv1FWrYjxwwwbVkSNV69SxN+dZZ6kuXhxIjDs9/7xqrVqq+++v+uGHFTvHTTfZW+GFF+Ibm3MV8fnn9n68//6y9/31V9XOne0zt3Bh4KGVafp01caNLf4aNVSbNVPt3l31hBNUzz9f9YYbVB96SHX8ePu8fv216vr1CUkapSUC0YDq10SkGrAIOArIBWYBw1R1QdQ+w4EsVb20vOfNysrSnJycOEe7q88/t7bWJ56AP/6xAidYvRr++U946CHIy4Pzz4cbb4QmTeIXZF4e/PWv8MADtnzm+PHQuHHFzrV9u/UwWrAA5s61wTvOheWSS2yswPLlUL9+2ft//z1kZdm+n3wC9eoFHeHuVOHhh+Hqq+3zc9FFsHIl/PKL9UcvuF250uqei8rIsDbH/fbb/Tb6fpMmsNdeFQpRRD5T1awS4g+sNNALmBT1eAQwosg+w4GHYzlvIkoE+fmqrVqpHnPMHp7oxx9V//Qn1fR01YwM1b/8RXXlyj0PcPly1T597FfHlVeqbtu25+dcskR1n31UjzhCNS9vz8/nXEVs2KC6996q554b23Effqhavbp9aLdvDyS0Ev32m5X+wX75r11b8r7bt6v+/LPq3Lmq77yj+swzqnffrXrNNXaOI49U7dBBtWFDq1WwFFO4PfRQhcMkjKohYAjwRNTjs4t+6UcSwU/AF8BLQLMSznUhkAPkNG/evML/ELG49lr7/l6zJg4nW7LE6uBF7Mv2llusOFgRH3ygut9+Vh0U76qcZ56xt8TIkfE9r3Pl9dhj9h6cObPix/7lL/GPqySLF6t27Gif7ZEjVXfsiN+58/LsR9/nn6u+9ZbqU0/tUfVXMieCfYGakfsXAe+Xdd5ElAhUVT/91P51nnoqjif98kvVU06xE++7r+qoUaqbNpXv2Px8a5CuVk21TRs7V7zl56sOG2bXqMgH0bk9kZ+v2qWLfbFWtM78T3+yz9czz8Q3tuK8/rpqvXqq9esnV2N1CfY4EQC1gbTI/TbAiUD1Mo4ps2qoyP7VgPVlxZKoRJCfr3rggarHHx/AyT/9VPXoo+2f/4ADVB99tPTqnY0brXdEQY+kdesCCCpi3Tr7w1u1qnipxbmKKPj19cgjFT/Htm2qAwao1qyp+skn8Yst2o4dqjffbLF27mwl/kogHongM6AW0ARYBrwIPFfGMenAUqAlUAOYC7Qvsk/jqPsnAx+XFUuiEoGqVdtVrx7g9+6UKaq9e9t/Q6tWqs8+u3v95sKF1o0uLU31zjsT0yXNu5S6MJx3nmrt2nv+A2TlStUWLexH1vLl8YmtwJo1qscdZ5/Zc86x9oFKIh6JYHbk9jLg2sj9OeU47jis59AS4IbIcyOBEyP37wDmR5LEFOCQss6ZyEQwc6b9C40dG+BF8vOtiNmpk13ssMNUJ0yw5196yRrOMjNV33svwCCK4V1KXSKtXWvtXhdcEJ/zzZ1rSaVnTxvnEw9z5tgPturVVUePTrpxAmWJRyL4PFLV83HBr3pgXnmOjfeWyESwY4dq06aqgwcn6GLjxtnAMLB2AFDt0UP1++8TEEAReXmqvXqp1q2rumxZ4q/vUstDD9n7PScnfud8+WU757nn7vmX9tixqnvtZaWMGTPiEl6ilZYIyjvFxJWROv5XVHW+iLSK/IKv0tLSbMqJt99OwAwMaWlw+unWl/+JJ6yz2J//bLMvNmsW8MWLkZ5uw/fDmqX0t9/g9tttHidXtanaLLndu9viSfFyyilw8802Z9F991XsHNu2wWWXwdlnW3yffWbTuFc1JWWIkjZsfqI6sR4Xry2RJQJVqy4HG8CbksaOtX+AW29NzPXy81Wfe061SRPd2Xf6wQcTc20XjoIP2RNPxP/cO3aonnyytXm9/XZsx/74Y2Eb3lVXxWe8ToiIQ9XQ80AdrPfQAmyk8F/Lc2y8t0Qngh07bMT4Kack9LLJI5FdSnNyCj94XbuqTp1qvaRA9ckng722C89ZZ9kUEb/+Gsz5N260QVr16qkuWlS+Yz780KZtCWK8TkjikQjmRG7/ANwDVAe+KM+x8d4SnQhUVS+91AYGb9yY8Esnh6C7lP70k/UYEVFt1Mh+GRb0ntqyxWYATEuzxnNXtaxaZV09L7002OssXWpjdw45pPRugPn5NsdRerq11yVy8siAlZYIyttGUF1EqgMnARNVNQ9ImUnAhwyBLVvgzTfDjiQkdetae8GyZVZfGi/bttkUwm3awNixcM01sGiRTfBUrZrtU7OmLRl3+OG2fsLbb8fv+i58Tz9t07hfdFGw12nZ0hZpWrzYpl0vbnnZ336z9rArr4TjjrP1PA47LNi4kkVJGSJ6Ay4HfgTeBAQ4EJhWnmPjvYVRIti+3WZ1GDo04ZdOLvHqUpqfr/raa4U9pI4/3mZhLM3atTZ4Z6+9Kj7LqksuBXO+9+mTuGuOHm3vueuu2/X5b76x6iMR1dtui+9UEUmCIKaYANIreuyebGEkAlXVSy6x6sJKNH4k/uLRpXTBAtXf/c7eem3bxjY0f8UKK9rvs098uxm6cEyerAmbDqJAfr7qhRfqLj1AXnvN3tMNGsTeoFyJ7HEiAOoC9xKZ+A1rJ6hbnmPjvYWVCAresy+/HMrlk8fSpRWbpXTtWpspNT3dPnT33luxXhg//GDtFfvuqzp/fuzHu+Rx2mn25Vve+bbiZetW1b59reHvoovsg92li+q33yY2jgQrLRGUt43gP8BG4LTItgF4Mi51U5VEv36QmWnVjCmtZUt45BFb+P7OO8vef8cOeOwxaN3a1k447zxrB7jqKqhePfbrN20KkyfbouZHHglLl8Z+Dhe+X36B//3PFqav4Pz6FVajhn2QGzWy9+bw4fDRR9CiRWLjSCYlZYjojWKmkyjuuURsYZUIVK1Euffeif8Bk5TOPLPsLqVTpxZOndG3r+rs2fG7/pdf2q/JFi1Uc3Pjd16XGHfcYe+Lr74KL4YlS1QnTqx0U0VUFHEoEWwWkSMKHohIH2Bz3LNSkhsyBH79Fd55J+xIksAjj5S88P1338Fpp8GAAbB2Lfz3v/DBB9ClS/yu37699SBavRqOOspWfnLlt3mz9doKQ36+/RIfOBDatg0nBoBWreD3vweR8GJIEuVNBBcDo0VkmYgsAx7G1g9IKQMGQIMGXj0EFN+l9LffbEj/IYfA66/DP/4BCxdaUgjiw9a9u13n22/hd7+D9evjf42q6OefLZH26AHr1iX++u+8Y++biy9O/LVd8UoqKhS3YaOL60TuXxnLsfHawqwaUrVxT3Xq2Dgnp4VdSq+4wmboAxuJnMiJ8t5802aE7NMnuNGpVcXGjTZqu1Yt+zfr3z9+s3OW10kn2cDBrVsTe90URxyqhgqSxgZVLagHuDquGamSGDrUakLefTfsSJLE3/9uk3A98AA0bAjTpsHzzyd2orxjj7XSycyZNtHY1q2Ju3Zlsn27lc7mzIHx422B+A8+sAnVihtgFYTcXHjtNes0UKNGYq7pyhRTIigiJSvWBg2CevW8emin9HR49VXbZs2CI44o+5ggDB0Kjz9u1Q5nnpn42VKTnSpccgm89Rb8619w/PH273TPPfZmvvJK2ydo//63tRFccEHw13Lllr4Hx6bMFBPRatSAwYPte2/bNv9RA1hJ4MQTw47CfmVu3Ghfan/8Izz5pE3v7WxK7yeegOuvhwsvLHz+6qth+XJLCE2awHXXBRfD9u0Ww9FHW0OtSxqlJgIR2UjxX/gCJLjzb/IYMsSmSHn/fTjmmLCjcbu44gqru7vpJqhTBx580HuFPPOMVeGdfTbcdtvur//zn/DTTzBiBOy/v/WrD8Kbb1rV0EMPBXN+V2GlJgJV3SdRgVQmRx1l3zEvvuiJICndeKP1ILrnHvuPuv32sCMKz3vvWekoO9t+jReXFNPSrPS0YgWcfz7st5+1u8TbY4/BAQfACSfE/9xuj3i5uQJq1rSakAkTIC8v7GjcbkTg7rutHvr//g/uuivsiMLxxRfWeN6uHbz8cun1mDVq2EjfTp2syPvpp/GNZdkya584/3xrV3JJxRNBBQ0ZAmvWwNSpYUfiiiVijaLDhlm99yOPhB1RYv3wg02lXKeOVcnUrVv2MfvsY/vuv781Ji9aFL94Hn/c/k/OPz9+53RxE2giEJFjRORrEVksIiW2QonIqSKiIpIVZDzxdPTRsPfe3nsoqVWrZo05v/+9rf/87LPxv4aq/SL4/HPrOpufH/9rxGrdOksCGzfaF3vTpuU/dr/9bMS2iA3S+/nnPY8nL896Cx1/fDjrb7syBVZGE5FqwGjgKGxpy1kiMlFVFxTZbx/gCuCToGIJwl57WVXnK6/A6NFe2k1a1atbn/njj7dG0L33hpNOKv/xqjZ9xXffWfVGcbcbNxbu37+/1be3bBnXP6Pctm2z6qCvvrIv9I4dYz9H69bwxhs2BcSxx9pYgzp1Kh7Tq6/aJHM+kjhpBfn11QNYrKpLAURkHDAYW/M42q3AXcBfA4wlEEOHwrhx8OGHNr7AJamMDPsyOvJIOP10m5biqKPstfx8+9Vb0pf8d9/ZvDzR6ta1mSpbtbL/+AMPtMcrVsDf/mZfvvfdZ420ieyxpGrXnDLFSkLZ2RU/V/fuVtz9/e8tsbzxhjWOVcSjj9q/0e9+V/F4XLBKGnK8pxswBHgi6vHZwMNF9ukKvBy5PxXIKuFcFxJZC6F58+bBjL+ugN9+s5H6550XdiSuXFavVu3Y0f7TsrNVDz5YtUYNmxYjesvMVO3WTfXUU1Wvvlr1wQdVX31Vdc4cW1ehNN99pzpokO5ceW358oT8aaqqev31dt3bbovfOZ95xs55xhkVW7Vr0aL4x+QqhFKmmAitQkNE0rDFboaXta+qjgHGAGRlZSXNQLZatWyJ0zFjrMZh1KiKTbHvEqRBAxt5fPbZNtagWzf7tduiReGv+ubN7T+zopo3t/lHRo+20sFhh1lD9emnx+uvKN6YMdZD6oILbNBYvJx9to0x+NvfrBH53ntjK+WMGWP1puedF7+YXPyVlCH2dAN6AZOiHo8ARkQ9rgusApZFti3AckooFRRsYU86V1RenupVV9mPnoEDVVeuDDsilzS+/lq1Z097c5x+uuqqVcFc5/XXVdPSVI87LrZV48orP98mFQTVf/6z/Mdt3mwryZ16avxjcjEjiDWLy9qw9oelQEugBjAXaF/K/lPLSgKahImgwNNPq9asaeukzJ0bdjQuaeTlqd5+u830uf/+qm+8Ed/zz5plVV3dutnMokHZscOWloxljeHnnrP93303uLhcuZWWCALrPqqq24FLgUnAQmC8qs4XkZEikgQT08TXOedYo/G2bTYZ54svhh2RSwrp6VZVM2uWzcl0/PFWfRPd06iili618zVqZA3ge1KlVZa0NJuqYuBAq+aZNKnsYx59FA4+2HtSVAYlZYhk3ZK1RFBg+XLVXr3sh9ANN1Ssfc1VUVu2qF53nVXjtGhhS3lW1KpVqm3aqNavr7pwYfxiLMu6dbb8aO3aVhopyfz5sVcluUARRokgVTVubL33zj/fprgZPNgXznIRNWvCHXfYwLP0dPt1ffXVu3dPLcvmzfbG+u47mDjRVoRLlLp1baqIzEwbtLZ4cfH7PfaYTVsR1AR2Lq48EQSgZk3rLDF6tI3p6dkTvv467Khc0ujd2xaH+dOfbLxBt26Qk1O+Y/PzrR5yxgwYOzac9R8aN7aqofx8Gxvwyy+7vr5pk41jGDLEqsNc0vNEEBAR+5y/956tr96jh432dw6A2rXh4YetO+uGDXD44bbec1mzGP7lLzbQa9QoG9EYlrZtrV3ip58Kp7MoMH68FYMvSrllzSstTwQB69/ffuy1amVTUtx5Z2IWgnKVxFFHwZdf2mphI0daQpg/v/h9H3jAShCXXw5XXZXYOItz+OH2pT93Lpx6qvWUAGskbtcO+vYNNz5Xbp4IEuDAA+Gjj2y52BEjbELMTZvCjsoljXr1rEfO//5ns4Z262a/+KPXEX75ZfvyP/nk2Ad1BemEE6we9N13rTfR7NnwySc2r1CyxOjKJFrJfp5mZWVpTnnrU5OMqi0GNWKETfv+yis2mNW5nVassCqVCRPsF/VTT9lcSNnZ0KULTJ5sMx4mm9tvtwWBGjeGtWtt+cv69cOOykURkc9UtdgZnr1EkEAiNlL/jTfg229tXi9fz8DtolEjKxk8/bRVuXTsaL+6mzWzHkLJmATAxkr86U/WZnDGGZ4EKhlPBCE49lhbACoz0ybEfPhhbzdwUUSsZ9CXX1oPo732KuyymaxEbH3oxx6zLrKuUvGqoRBt2GCT1r32ms0ePHp0xWf6dVXYjh22yI5ze8CrhpJUnTpWFXzjjbaA08CBVrJ2bheeBFzAPBGELC0Nbr3V5iaaOxeysqzThXPOJYongiQxZAjMnGmj8vv1s84izjmXCJ4IkkjHjjb47Igj4P/9Pxtj9N13YUflnKvqPBEkmX33tWlcbrrJxhm0bQvXXecT1znnguOJIAmlp8M//gGLFtkKh3fdZdO6jx5d9lQ0zjkXK08ESaxZMxtX9NlntvTtpZdChw42rqiS9fp1ziUxTwSVQNeu8P77lgDApqIfOLD8Mxc751xpPBFUEiLw+9/DvHnwyCOwYIFNUXHWWfD992FH55yrzDwRVDLVq8Mll9jCUCNG2KSUbdrYfW9Qds5VRKCJQESOEZGvRWSxiFxXzOsXi8g8EZkjItNF5NAg46lK6tSB//s/W/nstNNsnQNvUHbOVURgiUBEqgGjgWOBQ4FhxXzRP6+qHVS1M/BP4N6g4qmqmje3qexzcqB9e29Qds7FLsgSQQ9gsaouVdVtwDhgcPQOqroh6mFtwL+6KqhbN5gyZdcG5UGDrMeRc86VJshE0AT4IepxbuS5XYjIn0VkCVYiuDzAeKq86Abl0aNtFuOsLDj7bG9Qds6VLPTGYlUdraoHAX8DbixuHxG5UERyRCRn5cqViQ2wEqpe3dYIWbzYRiW/+KI3KDvnShZkIvgRaBb1uGnkuZKMA04q7gVVHaOqWaqa1bBhw/hFWMXVrWtrhCxaBEOHFjYo/+1vsHBh2NE555JFkIlgFtBaRFqKSA3gDGBi9A4i0jrq4fHANwHGk7KaN4exY2HWLFvw6p574NBD4fDDbUGpdevCjtA5F6bAEoGqbgcuBSYBC4HxqjpfREaKyImR3S4VkfkiMge4Gjg3qHictRe8+irk5sKoUfDrr3Dxxbbe+Jlnwrvv2mJYzrnU4ktVpjBV61X05JPw/PNWMmjWzJbLHT7cqpGcc1WDL1XpiiVipYTRo22JzP/+18Yi3HEHtG4NffvCf/4DGzeGHalzLkieCBwAGRk2Qvmtt6yr6R13wIoV8Mc/wv77w7nnwtSpkJ8fdqTOuXjzROB206SJdTv96iuYMQP+8AeYMMFmPD34YFsrYdmysKN0zsWLJwJXIhHo1QvGjLGqo2efhYMOskTQsqWNXB47FjZtCjtS59ye8ETgyqVWLSsZvPuulQZuvdWqkM45x6qOzj8fPvjAq46cq4w8EbiYNW8ON94I33wDH34IQ4ZYQ/OAAdCihY1gnj8/7Cidc+XlicBVmEhhz6JffrEuqB06wN1329KaXbrAvfdatZJzLnl5InBxUasWDBsGb7wBy5fDgw9CjRpwzTXQtCkcfbRNl+1dUZ1LPp4IXNw1agSXXQaffGIL59xwg02Ad+65sN9+1tbw1luwfXvYkTrnwBOBC1ibNjByJCxZAh99ZCOW334bjjvOuqlecYXNgVTJBrg7V6V4InAJIWIT3j3yiLUZTJgA/frZpHc9ekC7dnDbbfDtt2FH6lzq8UTgEq5GDVtB7cUX4eef4YknbOK7v/8dWrWCI46ARx+F1avDjtS51OCTzrmk8f331vNo7FhYsMAW2BkwwEoORxwBPXvCXnuFHaVzlVNpk855InBJRxXmzrWRzO+8Y0tuqlpi6NbNuqz27Qt9+kCDBmFH61zl4InAVWpr19qcR9OmwfTp1ri8bZu91r69lRb69rXbAw8MN1bnkpUnAlelbN5syWD6dEsOM2bAhg32WrNmhUmhb19biS3NW8KcKzURpCc6GOf21F57WbtBv372eMcOmDevMDFMmWJtDQD161sVUkFi6NYNatYML3bnkpGXCFyVo2rdUAsSw7RpNrANbN2FHj0sOfTubes2Z2aGG69zieBVQy7lrVxpiaEgOXz+eeHI5jZtLCn06mW3Xp3kqiJPBM4VsWmTrdc8Y4ZtM2dasgCoW9e6qvbubVvPnlCnTrjxOrenQksEInIM8ABQDXhCVe8s8vrVwPnAdmAlcJ6qflfaOT0RuCCo2jQY0Ylh3jx7XsRmU40uNRx8sD3vXGURSiIQkWrAIuAoIBeYBQxT1QVR+wwEPlHVTSJyCTBAVU8v7byeCFyibNhgE+fNnFmYHAp6J2VmFiaF3r0hK8tmYHUuWYXVa6gHsFhVl0aCGAcMBnYmAlWdErX/x8BZAcbjXEzq1IGjjrINbPW1hQt3LTW89pq9lp4OnTtbT6YBA6yHUr16IQXuXIyCTARNgB+iHucCPUvZ/4/AW8W9ICIXAhcCNG/ePF7xOReTtDQbwNa+PVxwgT23ahV8/LElhenT4eGHbTEeEUsM/fvb1q+fj4J2ySspxhGIyFlAFtC/uNdVdQwwBqxqKIGhOVeqzEw44QTbALZsseqkqVNtDedHH4X777fE0KGDlRYKEoN3W3XJIshE8CPQLOpx08hzuxCRI4EbgP6qujXAeJwLXEZGYSkAYOtW+PRTSwpTp8Ljj9vqbWAN0NGJoVGjsKJ2qS7IxuJ0rLE4G0sAs4AzVXV+1D5dgJeAY1T1m/Kc1xuLXWW2bZtNj/HBB7ZNn25dWcHGL/TvX5gc9tsv1FBdFRNm99HjgPux7qP/UdXbRWQkkKOqE0XkPaADULC8+feqemJp5/RE4KqSvDwbz1BQlTR9Ovz6q73Wtq0lhd69oXVr67KamendVl3F+IAy5yqJ7dth9uzCqqTp0wu7rIL1ZDr44OK3/ff3JOFK5onAuUpqxw745hsb7LZ48a7bt9/a6wVq1So5STRp4tNmpDqffdS5SqpaNTjkENuKysuzVd2ik8OSJTbW4fXXC9dsAJtxtVWrXZNDmza2VvQBB3hJItV5InCukqpeHQ46yLbf/W7X13bsgB9/3L0UsXgxTJ5c2EANVt3Urt2u26GHQosWlohc1edVQ86lGFX46SebmnvhQlsfeuFC2376qXC/mjWtwbogMRQkidatfU2HysirhpxzO4lYddABB8DAgbu+tm5dYVIo2D79FMaPtwQCVkpo1WrX5NCunVVf7bNPwv8cFweeCJxzO9WrZ5Pp9eq16/ObNsGiRbuXIN5809oqCjRtaiWGVq1sO+igwvsNGnhbRLLyROCcK1OtWjZ3UufOuz6fl1fYQF2wLVlijdW//LLrvnXqFCaFoomieXOoUSNRf40rytsInHOB+O036+K6dKklh6VLC7dvv7XpNwqkpUGzZiUnCi9N7DlvI3DOJVzt2jaf0mGH7f5afr41TBckhuhEUVxpom5dm/W1Y0ebvK/gtm7dxPwtVZ2XCJxzSadoaeKbb+DLL+GLL2D9+sL9mjffNTF07GjjI6pXDy/2ZOUlAudcpVJSaUIVcnMtIcybV3g7aZJNzwHW1tCunSWG6CThA+dK5iUC51ylt20bfPXVrsnhiy9sUF2BBg12Lz0cfLA1YqdCCcLnGnLOpaQ1awqrlAqSw5dfFs7wWiAjw8ZAFGx16pT+uLR9MjKSs+ThVUPOuZTUoIEt+tOvX+Fz+fmwbJklhmXLYOPGwm3DhsL7v/xiU3IUPC6aPEqSng6NG1tpo3XrXbdWrSxRJBtPBM65lJKWVtg9NRb5+ZYMiksaRe/n5loD98svw+rVhecQsW6yBYkhOlm0ahXe1B2eCJxzrhzS0qz6p06d2I5bu9ZKFt98U7gtXmzTdqxZs+v5mzcvviTRsmWwA+48ETjnXIDq14fu3W0ras2aXZNDwf0XXrB5nwqkpcGBB8Ltt8OwYfGP0ROBc86FpEED6NnTtmiqVqVUtCTRqFEwcXgicM65JCNi61NnZsLhhwd/PV+8zjnnUlygiUBEjhGRr0VksYhcV8zr/URktohsF5EhQcbinHOueIElAhGpBowGjgUOBYaJyKFFdvseGA48H1QczjnnShdkG0EPYLGqLgUQkXHAYGBBwQ6quizyWn6AcTjnnCtFkFVDTYAfoh7nRp6LmYhcKCI5IpKzcuXKuATnnHPOVIrGYlUdo6pZqprVsGHDsMNxzrkqJchE8CPQLOpx08hzzjnnkkiQiWAW0FpEWopIDeAMYGKA13POOVcBgU5DLSLHAfcD1YD/qOrtIjISyFHViSLSHXgFqA9sAX5W1fZlnHMl8F0FQ8oEVlXw2DBUpngrU6xQueKtTLFC5Yq3MsUKexbvgapabN16pVuPYE+ISE5J83Eno8oUb2WKFSpXvJUpVqhc8VamWCG4eCtFY7FzzrngeCJwzrkUl2qJYEzYAcSoMsVbmWKFyhVvZYoVKle8lSlWCCjelGojcM45t7tUKxE455wrwhOBc86luJRJBGVNiZ0sRKSZiEwRkQUiMl9Ergg7pvIQkWoi8rmIvB52LKURkXoi8pKIfCUiC0WkV9gxlUZEroq8D74UkRdEJCPsmKKJyH9EZIWIfBn1XAMReVdEvonc1g8zxgIlxHp35L3whYi8IiL1Qgxxp+JijXrtGhFREcmM1/VSIhGUc0rsZLEduEZVDwUOB/6cxLFGuwJYGHYQ5fAA8LaqHgJ0IoljFpEmwOVAlqoehg3MPCPcqHbzFHBMkeeuAyaramtgcuRxMniK3WN9FzhMVTsCi4ARiQ6qBE+xe6yISDPgaGwK/7hJiURA1JTYqroNKJgSO+mo6k+qOjtyfyP2RVWhWVsTRUSaAscDT4QdS2lEpC7QD/g3gKpuU9V1oQZVtnRgLxFJB2oBy0OOZxeq+iGwpsjTg4GnI/efBk5KZEwlKS5WVX1HVbdHHn6MzYkWuhL+XQHuA64F4trLJ1USQdymxE4kEWkBdAE+CTmUstyPvTmTfV2JlsBK4MlINdYTIlI77KBKoqo/AqOwX38/AetV9Z1woyqX/VT1p8j9n4H9wgwmBucBb4UdRElEZDDwo6rOjfe5UyURVDoisjfwMnClqm4IO56SiMgJwApV/SzsWMohHegK/EtVuwC/kTzVFruJ1K0PxhLYAUBtETkr3Khio9Y/Pen7qIvIDVi17HNhx1IcEakFXA/cFMT5UyURVKopsUWkOpYEnlPV/4UdTxn6ACeKyDKsym2QiDwbbkglygVyVbWghPUSlhiS1ZHAt6q6UlXzgP8BvUOOqTx+EZHGAJHbFSHHUyoRGQ6cAPxBk3dg1UHYD4K5kc9aU2C2iOwfj5OnSiKoNFNii4hgddgLVfXesOMpi6qOUNWmqtoC+3d9X1WT8lerqv4M/CAibSNPZRO1dGoS+h44XERqRd4X2SRx43aUicC5kfvnAq+GGEupROQYrFrzRFXdFHY8JVHVearaSFVbRD5ruUDXyHt6j6VEIog0Bl0KTMI+SONVdX64UZWoD3A29st6TmQ7LuygqpDLgOdE5AugM/B/4YZTskjJ5SVgNjAP+7wm1ZQIIvICMBNoKyK5IvJH4E7gKBH5BivV3BlmjAVKiPVhYB/g3chn7dFQg4woIdbgrpe8JSHnnHOJkBIlAueccyXzROCccynOE4FzzqU4TwTOOZfiPBE451yK80TgXBEisiOq6+6ceM5WKyItiptR0rkwpYcdgHNJaLOqdg47COcSxUsEzpWTiCwTkX+KyDwR+VREDo4830JE3o/MaT9ZRJpHnt8vMsf93MhWMD1ENRF5PLLOwDsisldof5RzeCJwrjh7FakaOj3qtfWq2gEbkXp/5LmHgKcjc9o/BzwYef5B4ANV7YTNaVQwmr01MFpV2wPrgFMD/WucK4OPLHauCBH5VVX3Lub5ZcAgVV0amRjwZ1XdV0RWAY1VNS/y/E+qmikiK4Gmqro16hwtgHcji7YgIn8DqqvqbQn405wrlpcInIuNlnA/Fluj7u/A2+pcyDwROBeb06NuZ0buz6BwCck/ANMi9ycDl8DONZ3rJipI52Lhv0Sc291eIjIn6vHbqlrQhbR+ZObSrcCwyHOXYaue/RVbAe3/RZ6/AhgTmTlyB5YUfsK5JONtBM6VU6SNIEtVV4Udi3Px5FVDzjmX4rxE4JxzKc5LBM45l+I8ETjnXIrzROCccynOE4FzzqU4TwTOOZfi/j+Uul4XP4W3JAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(best_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-richards",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
