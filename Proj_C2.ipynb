{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "confident-working",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.9\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: builtins.type size changed, may indicate binary incompatibility. Expected 880, got 864\n"
     ]
    }
   ],
   "source": [
    "#import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics as st\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.python.keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from keras.utils import to_categorical\n",
    "#!{sys.executable} -m pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-purple",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "anonymous-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Based on the training data given, we are able to extract 7 attributes:\n",
    "    1. x accelerometer measurement\n",
    "    2. y accelerometer measurement\n",
    "    3. z accelerometer measurement\n",
    "    4. x gyroscope measurement\n",
    "    5. y gyroscope measurement\n",
    "    6. z gyroscope measurement\n",
    "    7. time stamp for accelerometer and gyroscope measures\n",
    "    \n",
    "    We start by creating a dataframe using the csv files provided for readability.\n",
    "    \n",
    "    @param x_file: contains the xyz accelerometers and xyz gyroscope measures from the lower limb\n",
    "    @param x_time_file: contain the time stamps for the accelerometer and gyroscope measures\n",
    "    @return dataframe of 7 attributes mentioned\n",
    "\"\"\"\n",
    "def create_dataframe_X(x_file, x_time_file):\n",
    "    df1 = pd.read_csv(x_file, sep = ',', names = ['X_acc', 'Y_acc', 'Z_acc', 'X_gyr', 'Y_gyr', 'Z_gyr'])\n",
    "    df1 = scale_data(df1, ['X_acc', 'Y_acc', 'Z_acc', 'X_gyr', 'Y_gyr', 'Z_gyr'])\n",
    "    df2 = pd.read_csv(x_time_file, names = ['Time stamp'])\n",
    "    frames = [df1, df2]\n",
    "    result = pd.concat(frames, axis = 1)\n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "    Scale the values of X to make it robust to outliers.\n",
    "    \n",
    "    @param df: input dataframe\n",
    "    @param columns: columns to scale\n",
    "    @return scaled dataframe\n",
    "\"\"\"\n",
    "def scale_data(df, columns):\n",
    "    scaler = RobustScaler()\n",
    "    scaler = scaler.fit(df[columns])\n",
    "    df.loc[:, columns] = scaler.transform(df[columns])\n",
    "    return df\n",
    "    \n",
    "\"\"\"\n",
    "    We have both the labels and the time stamps for the labels. We create a dataframe from these for\n",
    "    readability.\n",
    "    \n",
    "    @param y_file: contain the labels: \n",
    "        (0) indicates standing or walking in solid ground, \n",
    "        (1) indicates going down the stairs, \n",
    "        (2) indicates going up the stairs, and \n",
    "        (3) indicates walking on grass\n",
    "    @param y_time_file: contain the time stamps for the labels\n",
    "    @return dataframe of labels and time stamps\n",
    "\"\"\" \n",
    "def create_dataframe_Y(y_file, y_time_file):\n",
    "    df1 = pd.read_csv(y_file, names = ['Label'])\n",
    "    df2 = pd.read_csv(y_time_file, names = ['Time stamp'])\n",
    "    frames = [df1, df2]\n",
    "    result = pd.concat(frames, axis = 1)\n",
    "    return result\n",
    "    \n",
    "\"\"\"\n",
    "    We take the outputs of create_dataframe_X and create_dataframe_Y. In order to combine both of these\n",
    "    dataframes, we need look at the time intervals present for when the labels were assigned. We down-sample\n",
    "    the X to the shape of the y.\n",
    "    \n",
    "    @param x_frame: dataframe from create_dataframe_X\n",
    "    @param y_frame: dataframe from create_dataframe_Y\n",
    "    @return dataframe with 9 columns (8 attributes and 1 label)\n",
    "\"\"\"\n",
    "def combine_frames(x_frame, y_frame):\n",
    "    # Change each dataframe column to a list for iterations\n",
    "    time_stamp_y = y_frame['Time stamp'].tolist()\n",
    "    time_stamp_x = x_frame['Time stamp'].tolist()\n",
    "    \n",
    "    x_range = [] # Empty list to append data points to\n",
    "    x_random_row = 0 # Initializing variable to hold randomly selected row instance\n",
    "    refs = []\n",
    "    count = 0\n",
    "    for i in range(0, len(time_stamp_y)):\n",
    "        while (time_stamp_x[count] <= time_stamp_y[i]) and (count <= len(time_stamp_x)):\n",
    "            x_range.append(time_stamp_x.index(time_stamp_x[count]))\n",
    "            count += 1\n",
    "        x_random_row = random.choice(x_range) # Pick a random value\n",
    "        refs.append(x_random_row) # Keep record of selected rows\n",
    "        x_range.clear() # Clear the cache\n",
    "        continue\n",
    "    \n",
    "    # Create a new dataframe based on the refs collected - should be roughly the same length as the y_frame\n",
    "    entries = []\n",
    "    for item in refs:\n",
    "        entry = x_frame.iloc[item]\n",
    "        entries.append(entry)\n",
    "    \n",
    "    found_df = pd.concat(entries, axis = 1)\n",
    "    found_df = found_df.transpose()\n",
    "    \n",
    "    # Combine found_df with y_frame for downsampling\n",
    "    found_df = found_df.reset_index()\n",
    "    found_df = found_df.drop(['index'], axis = 1)\n",
    "    found_df = found_df.drop(['Time stamp'], axis = 1)\n",
    "    combined_frame = pd.concat([found_df, y_frame], axis = 1)\n",
    "    return combined_frame\n",
    "\n",
    "\"\"\"\n",
    "    Takes in the sequential X and y and creates windows of time-series data.\n",
    "    \n",
    "    @param X: input data\n",
    "    @param y: label data\n",
    "    @param time_steps: determines size of window\n",
    "    @param step: incremental value that window will slide over\n",
    "    @return time series of X and y data\n",
    "\"\"\"\n",
    "def mode_labels(X, y, time_steps, step):\n",
    "    X_values = []\n",
    "    y_values = []\n",
    "    for i in range(0, len(X) - time_steps, step):\n",
    "        value = X.iloc[i:(i + time_steps)].values\n",
    "        labels = y.iloc[i: (i + time_steps)]\n",
    "        X_values.append(value)\n",
    "        y_values.append(stats.mode(labels)[0][0])\n",
    "    return np.array(X_values), np.array(y_values).reshape(-1, 1)\n",
    "\n",
    "\"\"\"\n",
    "    Generating data frames from training data.\n",
    "    \n",
    "    @param X_file: list of input X files\n",
    "    @param X_t_file: list of input X_time files\n",
    "    @param y_file: list of input y files\n",
    "    @param y_t file: list of y_time files\n",
    "    @return stacked window of instances across all training files, stack window of labels across all label files\n",
    "\"\"\"\n",
    "def generate_data(X_file, X_t_file, y_file, y_t_file):\n",
    "    all_X = []\n",
    "    all_y = []\n",
    "    for item_X, item_X_t, item_y, item_y_t in zip(X_file, X_t_file, y_file, y_t_file):\n",
    "        df_x = create_dataframe_X(item_X, item_X_t)\n",
    "        df_y = create_dataframe_Y(item_y, item_y_t)\n",
    "        combined_frame = combine_frames(df_x, df_y)\n",
    "        X_temp = combined_frame[['X_acc', 'Y_acc', 'Z_acc', 'X_gyr', 'Y_gyr', 'Z_gyr']]\n",
    "        y_temp = combined_frame['Label']\n",
    "        X, y = mode_labels(X_temp, y_temp, 30, 1)\n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "    return np.concatenate(all_X), np.concatenate(all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opposed-moment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301655, 30, 6) (301655, 1)\n",
      "(33762, 30, 6) (33762, 1)\n"
     ]
    }
   ],
   "source": [
    "# List of training X_files\n",
    "X_files = ['TrainingData/subject_001_01__x.csv', 'TrainingData/subject_001_02__x.csv', \n",
    "           'TrainingData/subject_001_03__x.csv', 'TrainingData/subject_001_04__x.csv',\n",
    "           'TrainingData/subject_001_05__x.csv', 'TrainingData/subject_001_06__x.csv',\n",
    "           'TrainingData/subject_001_07__x.csv', 'TrainingData/subject_001_08__x.csv',\n",
    "           'TrainingData/subject_002_01__x.csv', 'TrainingData/subject_002_02__x.csv',\n",
    "           'TrainingData/subject_002_03__x.csv', 'TrainingData/subject_001_04__x.csv',\n",
    "           'TrainingData/subject_002_05__x.csv', 'TrainingData/subject_003_01__x.csv',\n",
    "           'TrainingData/subject_005_01__x.csv', 'TrainingData/subject_005_02__x.csv',\n",
    "           'TrainingData/subject_005_03__x.csv', 'TrainingData/subject_006_01__x.csv',\n",
    "           'TrainingData/subject_006_02__x.csv', 'TrainingData/subject_006_03__x.csv',\n",
    "           'TrainingData/subject_007_01__x.csv', 'TrainingData/subject_007_02__x.csv',\n",
    "           'TrainingData/subject_007_03__x.csv', 'TrainingData/subject_007_04__x.csv',\n",
    "           'TrainingData/subject_008_01__x.csv']\n",
    "\n",
    "# List of training X_t_files\n",
    "X_t_files = ['TrainingData/subject_001_01__x_time.csv', 'TrainingData/subject_001_02__x_time.csv', \n",
    "             'TrainingData/subject_001_03__x_time.csv', 'TrainingData/subject_001_04__x_time.csv',\n",
    "             'TrainingData/subject_001_05__x_time.csv', 'TrainingData/subject_001_06__x_time.csv',\n",
    "             'TrainingData/subject_001_07__x_time.csv', 'TrainingData/subject_001_08__x_time.csv',\n",
    "             'TrainingData/subject_002_01__x_time.csv', 'TrainingData/subject_002_02__x_time.csv',\n",
    "             'TrainingData/subject_002_03__x_time.csv', 'TrainingData/subject_001_04__x_time.csv',\n",
    "             'TrainingData/subject_002_05__x_time.csv', 'TrainingData/subject_003_01__x_time.csv',\n",
    "             'TrainingData/subject_005_01__x_time.csv', 'TrainingData/subject_005_02__x_time.csv',\n",
    "             'TrainingData/subject_005_03__x_time.csv', 'TrainingData/subject_006_01__x_time.csv',\n",
    "             'TrainingData/subject_006_02__x_time.csv', 'TrainingData/subject_006_03__x_time.csv',\n",
    "             'TrainingData/subject_007_01__x_time.csv', 'TrainingData/subject_007_02__x_time.csv',\n",
    "             'TrainingData/subject_007_03__x_time.csv', 'TrainingData/subject_007_04__x_time.csv',\n",
    "             'TrainingData/subject_008_01__x_time.csv']\n",
    "\n",
    "# List of training y_files\n",
    "y_files = ['TrainingData/subject_001_01__y.csv', 'TrainingData/subject_001_02__y.csv', \n",
    "           'TrainingData/subject_001_03__y.csv', 'TrainingData/subject_001_04__y.csv',\n",
    "           'TrainingData/subject_001_05__y.csv', 'TrainingData/subject_001_06__y.csv',\n",
    "           'TrainingData/subject_001_07__y.csv', 'TrainingData/subject_001_08__y.csv',\n",
    "           'TrainingData/subject_002_01__y.csv', 'TrainingData/subject_002_02__y.csv',\n",
    "           'TrainingData/subject_002_03__y.csv', 'TrainingData/subject_001_04__y.csv',\n",
    "           'TrainingData/subject_002_05__y.csv', 'TrainingData/subject_003_01__y.csv',\n",
    "           'TrainingData/subject_005_01__y.csv', 'TrainingData/subject_005_02__y.csv',\n",
    "           'TrainingData/subject_005_03__y.csv', 'TrainingData/subject_006_01__y.csv',\n",
    "           'TrainingData/subject_006_02__y.csv', 'TrainingData/subject_006_03__y.csv',\n",
    "           'TrainingData/subject_007_01__y.csv', 'TrainingData/subject_007_02__y.csv',\n",
    "           'TrainingData/subject_007_03__y.csv', 'TrainingData/subject_007_04__y.csv',\n",
    "           'TrainingData/subject_008_01__y.csv']\n",
    "\n",
    "# List of training y_t_files\n",
    "y_t_files = ['TrainingData/subject_001_01__y_time.csv', 'TrainingData/subject_001_02__y_time.csv', \n",
    "             'TrainingData/subject_001_03__y_time.csv', 'TrainingData/subject_001_04__y_time.csv',\n",
    "             'TrainingData/subject_001_05__y_time.csv', 'TrainingData/subject_001_06__y_time.csv',\n",
    "             'TrainingData/subject_001_07__y_time.csv', 'TrainingData/subject_001_08__y_time.csv',\n",
    "             'TrainingData/subject_002_01__y_time.csv', 'TrainingData/subject_002_02__y_time.csv',\n",
    "             'TrainingData/subject_002_03__y_time.csv', 'TrainingData/subject_001_04__y_time.csv',\n",
    "             'TrainingData/subject_002_05__y_time.csv', 'TrainingData/subject_003_01__y_time.csv',\n",
    "             'TrainingData/subject_005_01__y_time.csv', 'TrainingData/subject_005_02__y_time.csv',\n",
    "             'TrainingData/subject_005_03__y_time.csv', 'TrainingData/subject_006_01__y_time.csv',\n",
    "             'TrainingData/subject_006_02__y_time.csv', 'TrainingData/subject_006_03__y_time.csv',\n",
    "             'TrainingData/subject_007_01__y_time.csv', 'TrainingData/subject_007_02__y_time.csv',\n",
    "             'TrainingData/subject_007_03__y_time.csv', 'TrainingData/subject_007_04__y_time.csv',\n",
    "             'TrainingData/subject_008_01__y_time.csv']\n",
    "\n",
    "# Use some files to create validation set\n",
    "val_X = ['TrainingData/subject_003_02__x.csv', 'TrainingData/subject_003_03__x.csv',\n",
    "         'TrainingData/subject_004_01__x.csv', 'TrainingData/subject_004_02__x.csv',]\n",
    "val_X_t = ['TrainingData/subject_003_02__x_time.csv', 'TrainingData/subject_003_03__x_time.csv',\n",
    "           'TrainingData/subject_004_01__x_time.csv', 'TrainingData/subject_004_02__x_time.csv',]\n",
    "val_y = ['TrainingData/subject_003_02__y.csv', 'TrainingData/subject_003_03__y.csv',\n",
    "         'TrainingData/subject_004_01__y.csv', 'TrainingData/subject_004_02__y.csv',]\n",
    "val_y_t = ['TrainingData/subject_003_02__y_time.csv', 'TrainingData/subject_003_03__y_time.csv',\n",
    "           'TrainingData/subject_004_01__y_time.csv', 'TrainingData/subject_004_02__y_time.csv',]\n",
    "\n",
    "training_X, training_y = generate_data(X_files, X_t_files, y_files, y_t_files)\n",
    "val_X, val_y = generate_data(val_X, val_X_t, val_y, val_y_t)\n",
    "print(training_X.shape, training_y.shape)\n",
    "print(val_X.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "legislative-combination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33593218 5.81133929 4.44263623 1.59734284]\n",
      "{0: 0.3359321754546953, 1: 5.811339292594591, 2: 4.442636229749632, 3: 1.5973428365669744}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1 2 3], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "label_weights = class_weight.compute_class_weight('balanced', np.unique(training_y), training_y.ravel())\n",
    "print(label_weights)\n",
    "label_weights = {i:label_weights[i] for i in range(len(label_weights))} # Create dictionary\n",
    "print(label_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "relative-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "encoder = encoder.fit(training_y)\n",
    "training_y_encoded = encoder.transform(training_y)\n",
    "val_y_encoded = encoder.transform(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dimensional-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_measure(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_measure(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    precision = precision_measure(y_true, y_pred)\n",
    "    recall = recall_measure(y_true, y_pred)\n",
    "    return 2 * ((precision * recall)/(precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "annual-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps, n_features, n_outputs = training_X.shape[1], training_X.shape[2], training_y_encoded.shape[1]\n",
    "\n",
    "def define_LSTM_model(dropout_rate, l1_value, l2_value):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = 125, kernel_regularizer = regularizers.l1_l2(l1=l1_value, l2=l2_value),\n",
    "                   input_shape = (n_timesteps, n_features)))\n",
    "    model.add(Dropout(rate = dropout_rate))\n",
    "    model.add(Dense(units = 125, activation = 'relu'))\n",
    "    model.add(Dense(units = n_outputs, activation = 'softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', \n",
    "                  metrics = ['accuracy', f1, precision_measure, recall_measure])\n",
    "    return model\n",
    "    \n",
    "def evaluate_model(training_X, training_y_encoded, val_X, val_y_encoded, dropout_rate, l1_value, l2_value):\n",
    "    verbose, epochs, batch_size = 1, 30, 64\n",
    "    model = define_LSTM_model(dropout_rate, l1_value, l2_value)\n",
    "    model.summary()\n",
    "    # Fit network\n",
    "    history = model.fit(training_X, training_y_encoded, epochs = epochs, batch_size = batch_size, \n",
    "              validation_data = (val_X, val_y_encoded), class_weight = label_weights, verbose = verbose)\n",
    "    # Evaluate model\n",
    "    loss, accuracy, f1, precision, recall = model.evaluate(val_X, val_y_encoded, batch_size = batch_size, verbose = verbose)\n",
    "    return model, history, accuracy, f1, precision, recall\n",
    "\n",
    "# Defining a function for plotting training and validation learning curves\n",
    "def plot_history(history):\n",
    "\t# Plot loss\n",
    "    plt.title('Loss')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_loss'], color='red', label='test')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.title('Accuracy')\n",
    "    plt.plot(history.history['acc'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_acc'], color='red', label='test')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot F1\n",
    "    plt.title('F1-Score')\n",
    "    plt.plot(history.history['f1'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_f1'], color='red', label='test')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot precision\n",
    "    plt.title('Precision')\n",
    "    plt.plot(history.history['precision_measure'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_precision_measure'], color='red', label='test')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot recall\n",
    "    plt.title('Recall')\n",
    "    plt.plot(history.history['recall_measure'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_recall_measure'], color='red', label='test')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "optical-chemical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting  1 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 310s 1ms/step - loss: 0.7947 - acc: 0.5508 - f1: 0.4722 - precision_measure: 0.5823 - recall_measure: 0.4294 - val_loss: 0.8487 - val_acc: 0.5053 - val_f1: 0.4855 - val_precision_measure: 0.5074 - val_recall_measure: 0.4686\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 205s 680us/step - loss: 0.4590 - acc: 0.7079 - f1: 0.7024 - precision_measure: 0.7151 - recall_measure: 0.6903 - val_loss: 0.9917 - val_acc: 0.5042 - val_f1: 0.4989 - val_precision_measure: 0.5046 - val_recall_measure: 0.4938\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 203s 674us/step - loss: 0.3812 - acc: 0.7785 - f1: 0.7764 - precision_measure: 0.7840 - recall_measure: 0.7692 - val_loss: 0.7051 - val_acc: 0.7158 - val_f1: 0.7134 - val_precision_measure: 0.7201 - val_recall_measure: 0.7073\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 187s 620us/step - loss: 0.3316 - acc: 0.8185 - f1: 0.8176 - precision_measure: 0.8224 - recall_measure: 0.8128 - val_loss: 0.4614 - val_acc: 0.8180 - val_f1: 0.8177 - val_precision_measure: 0.8190 - val_recall_measure: 0.8164\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 197s 653us/step - loss: 0.2951 - acc: 0.8391 - f1: 0.8386 - precision_measure: 0.8414 - recall_measure: 0.8358 - val_loss: 0.4891 - val_acc: 0.8150 - val_f1: 0.8143 - val_precision_measure: 0.8162 - val_recall_measure: 0.8125\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 196s 649us/step - loss: 0.2744 - acc: 0.8517 - f1: 0.8514 - precision_measure: 0.8537 - recall_measure: 0.8491 - val_loss: 0.7023 - val_acc: 0.7045 - val_f1: 0.7034 - val_precision_measure: 0.7049 - val_recall_measure: 0.7019\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 197s 653us/step - loss: 0.2572 - acc: 0.8631 - f1: 0.8629 - precision_measure: 0.8647 - recall_measure: 0.8612 - val_loss: 0.4104 - val_acc: 0.8564 - val_f1: 0.8557 - val_precision_measure: 0.8567 - val_recall_measure: 0.8547\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.2420 - acc: 0.8719 - f1: 0.8717 - precision_measure: 0.8732 - recall_measure: 0.8703 - val_loss: 0.4160 - val_acc: 0.8549 - val_f1: 0.8548 - val_precision_measure: 0.8556 - val_recall_measure: 0.8540\n",
      "33762/33762 [==============================] - 7s 206us/step\n",
      "Fitting  2 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 225s 746us/step - loss: 0.7072 - acc: 0.5856 - f1: 0.5225 - precision_measure: 0.5997 - recall_measure: 0.4911 - val_loss: 0.6426 - val_acc: 0.6875 - val_f1: 0.6829 - val_precision_measure: 0.6901 - val_recall_measure: 0.6766\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 196s 651us/step - loss: 0.4395 - acc: 0.7176 - f1: 0.7138 - precision_measure: 0.7242 - recall_measure: 0.7038 - val_loss: 0.8535 - val_acc: 0.5804 - val_f1: 0.5677 - val_precision_measure: 0.5816 - val_recall_measure: 0.5560\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 197s 653us/step - loss: 0.3785 - acc: 0.7761 - f1: 0.7743 - precision_measure: 0.7815 - recall_measure: 0.7674 - val_loss: 0.8438 - val_acc: 0.5723 - val_f1: 0.5688 - val_precision_measure: 0.5726 - val_recall_measure: 0.5653\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 201s 666us/step - loss: 0.3338 - acc: 0.8074 - f1: 0.8067 - precision_measure: 0.8112 - recall_measure: 0.8023 - val_loss: 0.4895 - val_acc: 0.8215 - val_f1: 0.8203 - val_precision_measure: 0.8240 - val_recall_measure: 0.8168\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 197s 654us/step - loss: 0.3003 - acc: 0.8346 - f1: 0.8342 - precision_measure: 0.8376 - recall_measure: 0.8308 - val_loss: 0.4553 - val_acc: 0.8432 - val_f1: 0.8415 - val_precision_measure: 0.8446 - val_recall_measure: 0.8385\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 196s 650us/step - loss: 0.2740 - acc: 0.8496 - f1: 0.8494 - precision_measure: 0.8519 - recall_measure: 0.8470 - val_loss: 0.7482 - val_acc: 0.6999 - val_f1: 0.6991 - val_precision_measure: 0.7012 - val_recall_measure: 0.6971\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 234s 777us/step - loss: 0.2572 - acc: 0.8623 - f1: 0.8621 - precision_measure: 0.8641 - recall_measure: 0.8602 - val_loss: 0.4972 - val_acc: 0.8133 - val_f1: 0.8125 - val_precision_measure: 0.8143 - val_recall_measure: 0.8108\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 283s 937us/step - loss: 0.2342 - acc: 0.8759 - f1: 0.8760 - precision_measure: 0.8773 - recall_measure: 0.8747 - val_loss: 0.4609 - val_acc: 0.8369 - val_f1: 0.8364 - val_precision_measure: 0.8382 - val_recall_measure: 0.8348\n",
      "33762/33762 [==============================] - 7s 214us/step\n",
      "Fitting  3 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 231s 766us/step - loss: 0.7348 - acc: 0.5559 - f1: 0.4904 - precision_measure: 0.5817 - recall_measure: 0.4544 - val_loss: 0.8335 - val_acc: 0.5097 - val_f1: 0.5034 - val_precision_measure: 0.5103 - val_recall_measure: 0.4974\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 223s 739us/step - loss: 0.4639 - acc: 0.6493 - f1: 0.6431 - precision_measure: 0.6548 - recall_measure: 0.6320 - val_loss: 0.8544 - val_acc: 0.5386 - val_f1: 0.5305 - val_precision_measure: 0.5404 - val_recall_measure: 0.5219\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 208s 691us/step - loss: 0.4186 - acc: 0.7096 - f1: 0.7058 - precision_measure: 0.7148 - recall_measure: 0.6972 - val_loss: 0.6681 - val_acc: 0.6905 - val_f1: 0.6887 - val_precision_measure: 0.6927 - val_recall_measure: 0.6850\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 207s 686us/step - loss: 0.3662 - acc: 0.7768 - f1: 0.7751 - precision_measure: 0.7810 - recall_measure: 0.7694 - val_loss: 0.5470 - val_acc: 0.7772 - val_f1: 0.7742 - val_precision_measure: 0.7792 - val_recall_measure: 0.7696\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 198s 656us/step - loss: 0.3232 - acc: 0.8165 - f1: 0.8156 - precision_measure: 0.8199 - recall_measure: 0.8115 - val_loss: 0.4814 - val_acc: 0.8286 - val_f1: 0.8276 - val_precision_measure: 0.8312 - val_recall_measure: 0.8242\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 243s 807us/step - loss: 0.2958 - acc: 0.8367 - f1: 0.8361 - precision_measure: 0.8394 - recall_measure: 0.8328 - val_loss: 0.5085 - val_acc: 0.8013 - val_f1: 0.7996 - val_precision_measure: 0.8041 - val_recall_measure: 0.7955\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 204s 675us/step - loss: 0.2756 - acc: 0.8500 - f1: 0.8496 - precision_measure: 0.8519 - recall_measure: 0.8474 - val_loss: 0.4733 - val_acc: 0.8363 - val_f1: 0.8346 - val_precision_measure: 0.8379 - val_recall_measure: 0.8314\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 205s 680us/step - loss: 0.2592 - acc: 0.8596 - f1: 0.8594 - precision_measure: 0.8611 - recall_measure: 0.8578 - val_loss: 0.5783 - val_acc: 0.7806 - val_f1: 0.7799 - val_precision_measure: 0.7815 - val_recall_measure: 0.7782\n",
      "33762/33762 [==============================] - 7s 216us/step\n",
      "Fitting  4 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 203s 674us/step - loss: 0.7483 - acc: 0.5383 - f1: 0.4717 - precision_measure: 0.5620 - recall_measure: 0.4357 - val_loss: 0.9708 - val_acc: 0.3608 - val_f1: 0.3498 - val_precision_measure: 0.3632 - val_recall_measure: 0.3390\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 196s 650us/step - loss: 0.4705 - acc: 0.6510 - f1: 0.6448 - precision_measure: 0.6595 - recall_measure: 0.6311 - val_loss: 0.9347 - val_acc: 0.4164 - val_f1: 0.4151 - val_precision_measure: 0.4181 - val_recall_measure: 0.4124\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 208s 689us/step - loss: 0.3862 - acc: 0.7650 - f1: 0.7629 - precision_measure: 0.7711 - recall_measure: 0.7550 - val_loss: 0.5144 - val_acc: 0.8040 - val_f1: 0.8025 - val_precision_measure: 0.8072 - val_recall_measure: 0.7983\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 185s 614us/step - loss: 0.3354 - acc: 0.8140 - f1: 0.8129 - precision_measure: 0.8188 - recall_measure: 0.8072 - val_loss: 0.5623 - val_acc: 0.7681 - val_f1: 0.7674 - val_precision_measure: 0.7696 - val_recall_measure: 0.7654\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 186s 618us/step - loss: 0.3014 - acc: 0.8364 - f1: 0.8359 - precision_measure: 0.8398 - recall_measure: 0.8320 - val_loss: 0.3944 - val_acc: 0.8846 - val_f1: 0.8833 - val_precision_measure: 0.8864 - val_recall_measure: 0.8804\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 188s 623us/step - loss: 0.2718 - acc: 0.8556 - f1: 0.8552 - precision_measure: 0.8578 - recall_measure: 0.8528 - val_loss: 0.5374 - val_acc: 0.7941 - val_f1: 0.7936 - val_precision_measure: 0.7951 - val_recall_measure: 0.7923\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 191s 633us/step - loss: 0.2488 - acc: 0.8698 - f1: 0.8697 - precision_measure: 0.8715 - recall_measure: 0.8680 - val_loss: 0.4683 - val_acc: 0.8460 - val_f1: 0.8459 - val_precision_measure: 0.8465 - val_recall_measure: 0.8453\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 195s 647us/step - loss: 0.2292 - acc: 0.8833 - f1: 0.8832 - precision_measure: 0.8845 - recall_measure: 0.8820 - val_loss: 0.3601 - val_acc: 0.8934 - val_f1: 0.8930 - val_precision_measure: 0.8947 - val_recall_measure: 0.8914\n",
      "33762/33762 [==============================] - 6s 190us/step\n",
      "Fitting  5 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 199s 659us/step - loss: 0.6567 - acc: 0.5739 - f1: 0.5259 - precision_measure: 0.5943 - recall_measure: 0.4953 - val_loss: 0.7781 - val_acc: 0.6219 - val_f1: 0.6120 - val_precision_measure: 0.6253 - val_recall_measure: 0.6006\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.4089 - acc: 0.7464 - f1: 0.7423 - precision_measure: 0.7531 - recall_measure: 0.7321 - val_loss: 0.6919 - val_acc: 0.7011 - val_f1: 0.6979 - val_precision_measure: 0.7045 - val_recall_measure: 0.6920\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 202s 671us/step - loss: 0.3552 - acc: 0.7945 - f1: 0.7927 - precision_measure: 0.7999 - recall_measure: 0.7857 - val_loss: 0.7686 - val_acc: 0.6386 - val_f1: 0.6337 - val_precision_measure: 0.6412 - val_recall_measure: 0.6271\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 189s 628us/step - loss: 0.3207 - acc: 0.8201 - f1: 0.8191 - precision_measure: 0.8241 - recall_measure: 0.8142 - val_loss: 0.5990 - val_acc: 0.7945 - val_f1: 0.7929 - val_precision_measure: 0.7979 - val_recall_measure: 0.7883\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 190s 630us/step - loss: 0.2891 - acc: 0.8389 - f1: 0.8383 - precision_measure: 0.8420 - recall_measure: 0.8347 - val_loss: 0.4827 - val_acc: 0.8043 - val_f1: 0.8034 - val_precision_measure: 0.8064 - val_recall_measure: 0.8006\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 192s 637us/step - loss: 0.2624 - acc: 0.8556 - f1: 0.8553 - precision_measure: 0.8578 - recall_measure: 0.8529 - val_loss: 0.4191 - val_acc: 0.8654 - val_f1: 0.8634 - val_precision_measure: 0.8666 - val_recall_measure: 0.8605\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 190s 629us/step - loss: 0.2473 - acc: 0.8638 - f1: 0.8637 - precision_measure: 0.8657 - recall_measure: 0.8617 - val_loss: 0.4594 - val_acc: 0.8383 - val_f1: 0.8374 - val_precision_measure: 0.8400 - val_recall_measure: 0.8350\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.2266 - acc: 0.8764 - f1: 0.8763 - precision_measure: 0.8776 - recall_measure: 0.8750 - val_loss: 0.7031 - val_acc: 0.7361 - val_f1: 0.7359 - val_precision_measure: 0.7374 - val_recall_measure: 0.7344\n",
      "33762/33762 [==============================] - 7s 202us/step\n",
      "Fitting  6 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 198s 656us/step - loss: 0.6640 - acc: 0.5976 - f1: 0.5410 - precision_measure: 0.6151 - recall_measure: 0.5098 - val_loss: 0.9544 - val_acc: 0.5076 - val_f1: 0.5011 - val_precision_measure: 0.5080 - val_recall_measure: 0.4951\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 196s 651us/step - loss: 0.4105 - acc: 0.7369 - f1: 0.7332 - precision_measure: 0.7429 - recall_measure: 0.7240 - val_loss: 1.0905 - val_acc: 0.5202 - val_f1: 0.5087 - val_precision_measure: 0.5213 - val_recall_measure: 0.4983\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 197s 652us/step - loss: 0.3491 - acc: 0.7900 - f1: 0.7888 - precision_measure: 0.7947 - recall_measure: 0.7830 - val_loss: 0.6643 - val_acc: 0.7095 - val_f1: 0.7079 - val_precision_measure: 0.7113 - val_recall_measure: 0.7047\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 199s 661us/step - loss: 0.3097 - acc: 0.8224 - f1: 0.8216 - precision_measure: 0.8255 - recall_measure: 0.8179 - val_loss: 0.5005 - val_acc: 0.8136 - val_f1: 0.8114 - val_precision_measure: 0.8175 - val_recall_measure: 0.8058\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 203s 672us/step - loss: 0.2817 - acc: 0.8407 - f1: 0.8403 - precision_measure: 0.8432 - recall_measure: 0.8376 - val_loss: 0.5901 - val_acc: 0.7433 - val_f1: 0.7414 - val_precision_measure: 0.7442 - val_recall_measure: 0.7388\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 199s 659us/step - loss: 0.2596 - acc: 0.8577 - f1: 0.8575 - precision_measure: 0.8597 - recall_measure: 0.8553 - val_loss: 0.6703 - val_acc: 0.7288 - val_f1: 0.7260 - val_precision_measure: 0.7307 - val_recall_measure: 0.7217\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 204s 678us/step - loss: 0.2407 - acc: 0.8687 - f1: 0.8685 - precision_measure: 0.8702 - recall_measure: 0.8669 - val_loss: 0.5445 - val_acc: 0.7821 - val_f1: 0.7817 - val_precision_measure: 0.7828 - val_recall_measure: 0.7806\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 200s 661us/step - loss: 0.2252 - acc: 0.8784 - f1: 0.8783 - precision_measure: 0.8795 - recall_measure: 0.8770 - val_loss: 0.5144 - val_acc: 0.8031 - val_f1: 0.8014 - val_precision_measure: 0.8047 - val_recall_measure: 0.7982\n",
      "33762/33762 [==============================] - 7s 194us/step\n",
      "Fitting  7 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 201s 666us/step - loss: 0.6124 - acc: 0.6075 - f1: 0.5649 - precision_measure: 0.6201 - recall_measure: 0.5388 - val_loss: 0.8679 - val_acc: 0.4882 - val_f1: 0.4757 - val_precision_measure: 0.4886 - val_recall_measure: 0.4650\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 199s 659us/step - loss: 0.3883 - acc: 0.7635 - f1: 0.7607 - precision_measure: 0.7696 - recall_measure: 0.7522 - val_loss: 0.4268 - val_acc: 0.8784 - val_f1: 0.8759 - val_precision_measure: 0.8811 - val_recall_measure: 0.8711\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 210s 696us/step - loss: 0.3299 - acc: 0.8119 - f1: 0.8107 - precision_measure: 0.8160 - recall_measure: 0.8055 - val_loss: 0.6338 - val_acc: 0.7236 - val_f1: 0.7206 - val_precision_measure: 0.7261 - val_recall_measure: 0.7157\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 201s 668us/step - loss: 0.2926 - acc: 0.8364 - f1: 0.8359 - precision_measure: 0.8394 - recall_measure: 0.8325 - val_loss: 0.6078 - val_acc: 0.7676 - val_f1: 0.7669 - val_precision_measure: 0.7689 - val_recall_measure: 0.7651\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 202s 668us/step - loss: 0.2662 - acc: 0.8533 - f1: 0.8530 - precision_measure: 0.8555 - recall_measure: 0.8505 - val_loss: 0.5708 - val_acc: 0.7771 - val_f1: 0.7752 - val_precision_measure: 0.7789 - val_recall_measure: 0.7717\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 203s 674us/step - loss: 0.2411 - acc: 0.8680 - f1: 0.8677 - precision_measure: 0.8695 - recall_measure: 0.8660 - val_loss: 0.2982 - val_acc: 0.9194 - val_f1: 0.9190 - val_precision_measure: 0.9201 - val_recall_measure: 0.9179\n",
      "Epoch 7/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 204s 677us/step - loss: 0.2204 - acc: 0.8794 - f1: 0.8793 - precision_measure: 0.8805 - recall_measure: 0.8780 - val_loss: 0.6791 - val_acc: 0.7359 - val_f1: 0.7352 - val_precision_measure: 0.7368 - val_recall_measure: 0.7337\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.2088 - acc: 0.8876 - f1: 0.8875 - precision_measure: 0.8888 - recall_measure: 0.8864 - val_loss: 0.4178 - val_acc: 0.8638 - val_f1: 0.8636 - val_precision_measure: 0.8642 - val_recall_measure: 0.8630\n",
      "33762/33762 [==============================] - 8s 243us/step\n",
      "Fitting  8 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 193s 641us/step - loss: 0.6156 - acc: 0.6066 - f1: 0.5579 - precision_measure: 0.6166 - recall_measure: 0.5311 - val_loss: 0.6634 - val_acc: 0.6733 - val_f1: 0.6656 - val_precision_measure: 0.6779 - val_recall_measure: 0.6552\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 194s 643us/step - loss: 0.3720 - acc: 0.7790 - f1: 0.7768 - precision_measure: 0.7852 - recall_measure: 0.7687 - val_loss: 0.4802 - val_acc: 0.8307 - val_f1: 0.8282 - val_precision_measure: 0.8333 - val_recall_measure: 0.8234\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 201s 668us/step - loss: 0.3195 - acc: 0.8212 - f1: 0.8204 - precision_measure: 0.8258 - recall_measure: 0.8153 - val_loss: 0.4169 - val_acc: 0.8621 - val_f1: 0.8612 - val_precision_measure: 0.8651 - val_recall_measure: 0.8577\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 211s 701us/step - loss: 0.2858 - acc: 0.8429 - f1: 0.8426 - precision_measure: 0.8462 - recall_measure: 0.8391 - val_loss: 0.4996 - val_acc: 0.8132 - val_f1: 0.8122 - val_precision_measure: 0.8143 - val_recall_measure: 0.8102\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 197s 652us/step - loss: 0.2613 - acc: 0.8583 - f1: 0.8582 - precision_measure: 0.8604 - recall_measure: 0.8561 - val_loss: 0.3570 - val_acc: 0.8887 - val_f1: 0.8883 - val_precision_measure: 0.8894 - val_recall_measure: 0.8873\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 202s 669us/step - loss: 0.2375 - acc: 0.8710 - f1: 0.8709 - precision_measure: 0.8724 - recall_measure: 0.8693 - val_loss: 0.3688 - val_acc: 0.8711 - val_f1: 0.8711 - val_precision_measure: 0.8720 - val_recall_measure: 0.8703\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 199s 659us/step - loss: 0.2216 - acc: 0.8820 - f1: 0.8820 - precision_measure: 0.8832 - recall_measure: 0.8808 - val_loss: 0.3639 - val_acc: 0.8880 - val_f1: 0.8878 - val_precision_measure: 0.8890 - val_recall_measure: 0.8866\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 194s 645us/step - loss: 0.2050 - acc: 0.8919 - f1: 0.8918 - precision_measure: 0.8927 - recall_measure: 0.8910 - val_loss: 0.4478 - val_acc: 0.8375 - val_f1: 0.8372 - val_precision_measure: 0.8384 - val_recall_measure: 0.8361\n",
      "33762/33762 [==============================] - 8s 225us/step\n",
      "Fitting  9 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 209s 693us/step - loss: 0.5876 - acc: 0.5971 - f1: 0.5583 - precision_measure: 0.6092 - recall_measure: 0.5318 - val_loss: 0.8561 - val_acc: 0.5654 - val_f1: 0.5595 - val_precision_measure: 0.5673 - val_recall_measure: 0.5526\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 200s 664us/step - loss: 0.3808 - acc: 0.7603 - f1: 0.7572 - precision_measure: 0.7665 - recall_measure: 0.7482 - val_loss: 0.6005 - val_acc: 0.7420 - val_f1: 0.7369 - val_precision_measure: 0.7446 - val_recall_measure: 0.7300\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 263s 873us/step - loss: 0.3180 - acc: 0.8152 - f1: 0.8140 - precision_measure: 0.8201 - recall_measure: 0.8081 - val_loss: 0.3482 - val_acc: 0.8918 - val_f1: 0.8913 - val_precision_measure: 0.8942 - val_recall_measure: 0.8886\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 242s 804us/step - loss: 0.2816 - acc: 0.8394 - f1: 0.8388 - precision_measure: 0.8430 - recall_measure: 0.8348 - val_loss: 0.3774 - val_acc: 0.8708 - val_f1: 0.8696 - val_precision_measure: 0.8729 - val_recall_measure: 0.8666\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 261s 866us/step - loss: 0.2529 - acc: 0.8582 - f1: 0.8579 - precision_measure: 0.8606 - recall_measure: 0.8552 - val_loss: 0.3456 - val_acc: 0.8859 - val_f1: 0.8853 - val_precision_measure: 0.8882 - val_recall_measure: 0.8826\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 206s 682us/step - loss: 0.2315 - acc: 0.8714 - f1: 0.8712 - precision_measure: 0.8731 - recall_measure: 0.8693 - val_loss: 0.4907 - val_acc: 0.8061 - val_f1: 0.8049 - val_precision_measure: 0.8070 - val_recall_measure: 0.8031\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 202s 669us/step - loss: 0.2084 - acc: 0.8830 - f1: 0.8828 - precision_measure: 0.8841 - recall_measure: 0.8816 - val_loss: 0.4044 - val_acc: 0.8473 - val_f1: 0.8468 - val_precision_measure: 0.8477 - val_recall_measure: 0.8460\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 260s 863us/step - loss: 0.1935 - acc: 0.8935 - f1: 0.8934 - precision_measure: 0.8942 - recall_measure: 0.8926 - val_loss: 0.5411 - val_acc: 0.7989 - val_f1: 0.7988 - val_precision_measure: 0.7996 - val_recall_measure: 0.7981\n",
      "33762/33762 [==============================] - 8s 237us/step\n",
      "Fitting  10 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 210s 696us/step - loss: 0.5775 - acc: 0.5974 - f1: 0.5649 - precision_measure: 0.6093 - recall_measure: 0.5401 - val_loss: 0.7697 - val_acc: 0.5897 - val_f1: 0.5819 - val_precision_measure: 0.5912 - val_recall_measure: 0.5735\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 198s 658us/step - loss: 0.3572 - acc: 0.7914 - f1: 0.7891 - precision_measure: 0.7969 - recall_measure: 0.7816 - val_loss: 0.8890 - val_acc: 0.5718 - val_f1: 0.5663 - val_precision_measure: 0.5741 - val_recall_measure: 0.5597\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 218s 722us/step - loss: 0.3051 - acc: 0.8272 - f1: 0.8265 - precision_measure: 0.8314 - recall_measure: 0.8218 - val_loss: 0.5575 - val_acc: 0.7766 - val_f1: 0.7750 - val_precision_measure: 0.7786 - val_recall_measure: 0.7716\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 203s 674us/step - loss: 0.2758 - acc: 0.8475 - f1: 0.8471 - precision_measure: 0.8504 - recall_measure: 0.8438 - val_loss: 0.4938 - val_acc: 0.8078 - val_f1: 0.8043 - val_precision_measure: 0.8093 - val_recall_measure: 0.7997\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 204s 676us/step - loss: 0.2507 - acc: 0.8609 - f1: 0.8607 - precision_measure: 0.8632 - recall_measure: 0.8582 - val_loss: 0.4179 - val_acc: 0.8308 - val_f1: 0.8301 - val_precision_measure: 0.8327 - val_recall_measure: 0.8276\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 308s 1ms/step - loss: 0.2268 - acc: 0.8734 - f1: 0.8733 - precision_measure: 0.8749 - recall_measure: 0.8717 - val_loss: 0.4346 - val_acc: 0.8364 - val_f1: 0.8362 - val_precision_measure: 0.8369 - val_recall_measure: 0.8355\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 228s 757us/step - loss: 0.2109 - acc: 0.8835 - f1: 0.8834 - precision_measure: 0.8846 - recall_measure: 0.8821 - val_loss: 0.5181 - val_acc: 0.8087 - val_f1: 0.8083 - val_precision_measure: 0.8096 - val_recall_measure: 0.8071\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 206s 684us/step - loss: 0.1956 - acc: 0.8921 - f1: 0.8921 - precision_measure: 0.8930 - recall_measure: 0.8912 - val_loss: 0.4487 - val_acc: 0.8298 - val_f1: 0.8295 - val_precision_measure: 0.8299 - val_recall_measure: 0.8290\n",
      "33762/33762 [==============================] - 8s 243us/step\n",
      "Fitting  11 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 205s 681us/step - loss: 0.5675 - acc: 0.6496 - f1: 0.6233 - precision_measure: 0.6669 - recall_measure: 0.5983 - val_loss: 0.8392 - val_acc: 0.5906 - val_f1: 0.5802 - val_precision_measure: 0.5929 - val_recall_measure: 0.5693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 194s 644us/step - loss: 0.3569 - acc: 0.8004 - f1: 0.7987 - precision_measure: 0.8072 - recall_measure: 0.7905 - val_loss: 0.7583 - val_acc: 0.6407 - val_f1: 0.6378 - val_precision_measure: 0.6426 - val_recall_measure: 0.6334\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 188s 622us/step - loss: 0.3059 - acc: 0.8308 - f1: 0.8302 - precision_measure: 0.8357 - recall_measure: 0.8249 - val_loss: 0.5916 - val_acc: 0.7559 - val_f1: 0.7519 - val_precision_measure: 0.7592 - val_recall_measure: 0.7454\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 189s 627us/step - loss: 0.2744 - acc: 0.8487 - f1: 0.8483 - precision_measure: 0.8521 - recall_measure: 0.8446 - val_loss: 0.5372 - val_acc: 0.7806 - val_f1: 0.7791 - val_precision_measure: 0.7840 - val_recall_measure: 0.7746\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 186s 617us/step - loss: 0.2481 - acc: 0.8639 - f1: 0.8637 - precision_measure: 0.8662 - recall_measure: 0.8612 - val_loss: 0.5915 - val_acc: 0.7558 - val_f1: 0.7549 - val_precision_measure: 0.7579 - val_recall_measure: 0.7522\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 226s 749us/step - loss: 0.2288 - acc: 0.8743 - f1: 0.8742 - precision_measure: 0.8759 - recall_measure: 0.8726 - val_loss: 0.5354 - val_acc: 0.7885 - val_f1: 0.7881 - val_precision_measure: 0.7903 - val_recall_measure: 0.7860\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 245s 811us/step - loss: 0.2125 - acc: 0.8853 - f1: 0.8852 - precision_measure: 0.8865 - recall_measure: 0.8840 - val_loss: 0.5223 - val_acc: 0.7889 - val_f1: 0.7884 - val_precision_measure: 0.7901 - val_recall_measure: 0.7867\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 223s 741us/step - loss: 0.1931 - acc: 0.8957 - f1: 0.8957 - precision_measure: 0.8966 - recall_measure: 0.8949 - val_loss: 0.4704 - val_acc: 0.8200 - val_f1: 0.8196 - val_precision_measure: 0.8206 - val_recall_measure: 0.8186\n",
      "33762/33762 [==============================] - 8s 248us/step\n",
      "Fitting  12 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 211s 701us/step - loss: 0.5597 - acc: 0.6233 - f1: 0.5959 - precision_measure: 0.6405 - recall_measure: 0.5723 - val_loss: 0.8829 - val_acc: 0.5631 - val_f1: 0.5525 - val_precision_measure: 0.5649 - val_recall_measure: 0.5421\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 206s 683us/step - loss: 0.3440 - acc: 0.7967 - f1: 0.7952 - precision_measure: 0.8021 - recall_measure: 0.7885 - val_loss: 0.8648 - val_acc: 0.6014 - val_f1: 0.5996 - val_precision_measure: 0.6045 - val_recall_measure: 0.5951\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 203s 675us/step - loss: 0.2930 - acc: 0.8372 - f1: 0.8367 - precision_measure: 0.8405 - recall_measure: 0.8330 - val_loss: 0.4614 - val_acc: 0.8218 - val_f1: 0.8213 - val_precision_measure: 0.8232 - val_recall_measure: 0.8195\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 228s 755us/step - loss: 0.2582 - acc: 0.8570 - f1: 0.8567 - precision_measure: 0.8591 - recall_measure: 0.8543 - val_loss: 0.5768 - val_acc: 0.7778 - val_f1: 0.7776 - val_precision_measure: 0.7792 - val_recall_measure: 0.7762\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 245s 813us/step - loss: 0.2333 - acc: 0.8722 - f1: 0.8720 - precision_measure: 0.8735 - recall_measure: 0.8705 - val_loss: 0.5171 - val_acc: 0.8085 - val_f1: 0.8076 - val_precision_measure: 0.8094 - val_recall_measure: 0.8059\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 290s 963us/step - loss: 0.2135 - acc: 0.8845 - f1: 0.8844 - precision_measure: 0.8856 - recall_measure: 0.8833 - val_loss: 0.4898 - val_acc: 0.7971 - val_f1: 0.7967 - val_precision_measure: 0.7983 - val_recall_measure: 0.7952\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 283s 939us/step - loss: 0.1912 - acc: 0.8980 - f1: 0.8979 - precision_measure: 0.8986 - recall_measure: 0.8971 - val_loss: 0.7845 - val_acc: 0.7172 - val_f1: 0.7166 - val_precision_measure: 0.7180 - val_recall_measure: 0.7153\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 260s 861us/step - loss: 0.1776 - acc: 0.9087 - f1: 0.9087 - precision_measure: 0.9093 - recall_measure: 0.9081 - val_loss: 0.4200 - val_acc: 0.8510 - val_f1: 0.8504 - val_precision_measure: 0.8521 - val_recall_measure: 0.8489\n",
      "33762/33762 [==============================] - 9s 253us/step\n",
      "Fitting  13 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 235s 780us/step - loss: 0.5459 - acc: 0.6204 - f1: 0.5965 - precision_measure: 0.6355 - recall_measure: 0.5727 - val_loss: 0.5466 - val_acc: 0.7915 - val_f1: 0.7881 - val_precision_measure: 0.7966 - val_recall_measure: 0.7805\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 195s 645us/step - loss: 0.3516 - acc: 0.7872 - f1: 0.7853 - precision_measure: 0.7934 - recall_measure: 0.7776 - val_loss: 0.9239 - val_acc: 0.6096 - val_f1: 0.6064 - val_precision_measure: 0.6115 - val_recall_measure: 0.6018\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 197s 653us/step - loss: 0.2931 - acc: 0.8309 - f1: 0.8302 - precision_measure: 0.8352 - recall_measure: 0.8253 - val_loss: 0.5350 - val_acc: 0.7808 - val_f1: 0.7796 - val_precision_measure: 0.7830 - val_recall_measure: 0.7765\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 203s 673us/step - loss: 0.2666 - acc: 0.8526 - f1: 0.8521 - precision_measure: 0.8558 - recall_measure: 0.8486 - val_loss: 0.2646 - val_acc: 0.9209 - val_f1: 0.9209 - val_precision_measure: 0.9222 - val_recall_measure: 0.9198\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 200s 662us/step - loss: 0.2355 - acc: 0.8672 - f1: 0.8670 - precision_measure: 0.8691 - recall_measure: 0.8649 - val_loss: 0.4202 - val_acc: 0.8445 - val_f1: 0.8438 - val_precision_measure: 0.8453 - val_recall_measure: 0.8425\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 195s 645us/step - loss: 0.2180 - acc: 0.8769 - f1: 0.8768 - precision_measure: 0.8785 - recall_measure: 0.8752 - val_loss: 0.5042 - val_acc: 0.8080 - val_f1: 0.8076 - val_precision_measure: 0.8089 - val_recall_measure: 0.8064\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 198s 655us/step - loss: 0.2027 - acc: 0.8865 - f1: 0.8864 - precision_measure: 0.8877 - recall_measure: 0.8852 - val_loss: 0.4735 - val_acc: 0.8266 - val_f1: 0.8265 - val_precision_measure: 0.8278 - val_recall_measure: 0.8252\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 196s 651us/step - loss: 0.1852 - acc: 0.8977 - f1: 0.8977 - precision_measure: 0.8986 - recall_measure: 0.8968 - val_loss: 0.4668 - val_acc: 0.8314 - val_f1: 0.8310 - val_precision_measure: 0.8324 - val_recall_measure: 0.8297\n",
      "33762/33762 [==============================] - 7s 222us/step\n",
      "Fitting  14 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 209s 693us/step - loss: 0.5358 - acc: 0.6591 - f1: 0.6346 - precision_measure: 0.6741 - recall_measure: 0.6111 - val_loss: 0.7107 - val_acc: 0.6656 - val_f1: 0.6548 - val_precision_measure: 0.6706 - val_recall_measure: 0.6418\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 194s 645us/step - loss: 0.3372 - acc: 0.8087 - f1: 0.8073 - precision_measure: 0.8150 - recall_measure: 0.7999 - val_loss: 0.5695 - val_acc: 0.7745 - val_f1: 0.7708 - val_precision_measure: 0.7788 - val_recall_measure: 0.7637\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 202s 671us/step - loss: 0.2819 - acc: 0.8415 - f1: 0.8411 - precision_measure: 0.8452 - recall_measure: 0.8370 - val_loss: 0.6197 - val_acc: 0.7261 - val_f1: 0.7244 - val_precision_measure: 0.7272 - val_recall_measure: 0.7219\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 200s 664us/step - loss: 0.2509 - acc: 0.8587 - f1: 0.8586 - precision_measure: 0.8613 - recall_measure: 0.8559 - val_loss: 0.5930 - val_acc: 0.7636 - val_f1: 0.7620 - val_precision_measure: 0.7660 - val_recall_measure: 0.7582\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 180s 597us/step - loss: 0.2268 - acc: 0.8715 - f1: 0.8713 - precision_measure: 0.8734 - recall_measure: 0.8692 - val_loss: 0.5144 - val_acc: 0.7965 - val_f1: 0.7962 - val_precision_measure: 0.7974 - val_recall_measure: 0.7951\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 180s 595us/step - loss: 0.2074 - acc: 0.8822 - f1: 0.8821 - precision_measure: 0.8837 - recall_measure: 0.8807 - val_loss: 0.2834 - val_acc: 0.9091 - val_f1: 0.9091 - val_precision_measure: 0.9104 - val_recall_measure: 0.9080\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 176s 583us/step - loss: 0.1898 - acc: 0.8935 - f1: 0.8935 - precision_measure: 0.8946 - recall_measure: 0.8924 - val_loss: 0.4796 - val_acc: 0.8296 - val_f1: 0.8296 - val_precision_measure: 0.8308 - val_recall_measure: 0.8284\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 176s 585us/step - loss: 0.1756 - acc: 0.9037 - f1: 0.9036 - precision_measure: 0.9046 - recall_measure: 0.9027 - val_loss: 0.4251 - val_acc: 0.8306 - val_f1: 0.8304 - val_precision_measure: 0.8311 - val_recall_measure: 0.8297\n",
      "33762/33762 [==============================] - 6s 179us/step\n",
      "Fitting  15 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 179s 593us/step - loss: 0.5136 - acc: 0.6699 - f1: 0.6498 - precision_measure: 0.6827 - recall_measure: 0.6291 - val_loss: 0.6726 - val_acc: 0.6708 - val_f1: 0.6679 - val_precision_measure: 0.6733 - val_recall_measure: 0.6629\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 178s 590us/step - loss: 0.3187 - acc: 0.8200 - f1: 0.8188 - precision_measure: 0.8249 - recall_measure: 0.8129 - val_loss: 0.5814 - val_acc: 0.7780 - val_f1: 0.7743 - val_precision_measure: 0.7821 - val_recall_measure: 0.7674\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.2697 - acc: 0.8502 - f1: 0.8499 - precision_measure: 0.8536 - recall_measure: 0.8462 - val_loss: 0.4770 - val_acc: 0.8122 - val_f1: 0.8116 - val_precision_measure: 0.8144 - val_recall_measure: 0.8089\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 180s 595us/step - loss: 0.2383 - acc: 0.8678 - f1: 0.8677 - precision_measure: 0.8701 - recall_measure: 0.8653 - val_loss: 0.4011 - val_acc: 0.8490 - val_f1: 0.8488 - val_precision_measure: 0.8507 - val_recall_measure: 0.8471\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 180s 595us/step - loss: 0.2189 - acc: 0.8787 - f1: 0.8785 - precision_measure: 0.8803 - recall_measure: 0.8768 - val_loss: 0.4553 - val_acc: 0.8321 - val_f1: 0.8312 - val_precision_measure: 0.8343 - val_recall_measure: 0.8283\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 181s 599us/step - loss: 0.1963 - acc: 0.8916 - f1: 0.8915 - precision_measure: 0.8927 - recall_measure: 0.8904 - val_loss: 0.6102 - val_acc: 0.7473 - val_f1: 0.7466 - val_precision_measure: 0.7483 - val_recall_measure: 0.7450\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 180s 597us/step - loss: 0.1840 - acc: 0.9011 - f1: 0.9011 - precision_measure: 0.9021 - recall_measure: 0.9001 - val_loss: 0.4496 - val_acc: 0.8373 - val_f1: 0.8373 - val_precision_measure: 0.8379 - val_recall_measure: 0.8368\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.1644 - acc: 0.9122 - f1: 0.9122 - precision_measure: 0.9128 - recall_measure: 0.9116 - val_loss: 0.5442 - val_acc: 0.7955 - val_f1: 0.7952 - val_precision_measure: 0.7958 - val_recall_measure: 0.7947\n",
      "33762/33762 [==============================] - 6s 183us/step\n",
      "Fitting  16 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 180s 595us/step - loss: 0.4939 - acc: 0.7017 - f1: 0.6815 - precision_measure: 0.7122 - recall_measure: 0.6635 - val_loss: 0.6638 - val_acc: 0.7065 - val_f1: 0.7034 - val_precision_measure: 0.7097 - val_recall_measure: 0.6978\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 176s 582us/step - loss: 0.3085 - acc: 0.8257 - f1: 0.8247 - precision_measure: 0.8305 - recall_measure: 0.8191 - val_loss: 0.4450 - val_acc: 0.8321 - val_f1: 0.8308 - val_precision_measure: 0.8361 - val_recall_measure: 0.8261\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 177s 586us/step - loss: 0.2618 - acc: 0.8553 - f1: 0.8549 - precision_measure: 0.8585 - recall_measure: 0.8514 - val_loss: 0.3317 - val_acc: 0.8879 - val_f1: 0.8872 - val_precision_measure: 0.8893 - val_recall_measure: 0.8851\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 179s 595us/step - loss: 0.2327 - acc: 0.8716 - f1: 0.8715 - precision_measure: 0.8737 - recall_measure: 0.8693 - val_loss: 0.5395 - val_acc: 0.7742 - val_f1: 0.7730 - val_precision_measure: 0.7764 - val_recall_measure: 0.7699\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.2101 - acc: 0.8839 - f1: 0.8838 - precision_measure: 0.8852 - recall_measure: 0.8824 - val_loss: 0.6449 - val_acc: 0.7515 - val_f1: 0.7508 - val_precision_measure: 0.7541 - val_recall_measure: 0.7478\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 592us/step - loss: 0.1965 - acc: 0.8937 - f1: 0.8936 - precision_measure: 0.8947 - recall_measure: 0.8926 - val_loss: 0.5408 - val_acc: 0.7835 - val_f1: 0.7830 - val_precision_measure: 0.7840 - val_recall_measure: 0.7820\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 178s 591us/step - loss: 0.1771 - acc: 0.9056 - f1: 0.9055 - precision_measure: 0.9063 - recall_measure: 0.9047 - val_loss: 0.3975 - val_acc: 0.8629 - val_f1: 0.8623 - val_precision_measure: 0.8643 - val_recall_measure: 0.8605\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 177s 585us/step - loss: 0.1619 - acc: 0.9167 - f1: 0.9166 - precision_measure: 0.9173 - recall_measure: 0.9160 - val_loss: 0.4442 - val_acc: 0.8465 - val_f1: 0.8462 - val_precision_measure: 0.8471 - val_recall_measure: 0.8454\n",
      "33762/33762 [==============================] - 7s 197us/step\n",
      "Fitting  17 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.7837 - acc: 0.5449 - f1: 0.4638 - precision_measure: 0.5724 - recall_measure: 0.4227 - val_loss: 1.0414 - val_acc: 0.4199 - val_f1: 0.4076 - val_precision_measure: 0.4211 - val_recall_measure: 0.3969\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 180s 598us/step - loss: 0.4968 - acc: 0.6169 - f1: 0.6068 - precision_measure: 0.6231 - recall_measure: 0.5917 - val_loss: 0.8440 - val_acc: 0.4979 - val_f1: 0.4869 - val_precision_measure: 0.4988 - val_recall_measure: 0.4768\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.4500 - acc: 0.6775 - f1: 0.6713 - precision_measure: 0.6837 - recall_measure: 0.6595 - val_loss: 0.9658 - val_acc: 0.4972 - val_f1: 0.4922 - val_precision_measure: 0.4966 - val_recall_measure: 0.4883\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 180s 596us/step - loss: 0.4069 - acc: 0.7370 - f1: 0.7338 - precision_measure: 0.7425 - recall_measure: 0.7255 - val_loss: 0.7307 - val_acc: 0.6281 - val_f1: 0.6265 - val_precision_measure: 0.6301 - val_recall_measure: 0.6232\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.3689 - acc: 0.7804 - f1: 0.7786 - precision_measure: 0.7852 - recall_measure: 0.7723 - val_loss: 0.5568 - val_acc: 0.7643 - val_f1: 0.7623 - val_precision_measure: 0.7657 - val_recall_measure: 0.7591\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 593us/step - loss: 0.3333 - acc: 0.8120 - f1: 0.8109 - precision_measure: 0.8159 - recall_measure: 0.8061 - val_loss: 0.5538 - val_acc: 0.7893 - val_f1: 0.7861 - val_precision_measure: 0.7917 - val_recall_measure: 0.7811\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.3081 - acc: 0.8300 - f1: 0.8294 - precision_measure: 0.8332 - recall_measure: 0.8257 - val_loss: 0.4843 - val_acc: 0.8194 - val_f1: 0.8181 - val_precision_measure: 0.8202 - val_recall_measure: 0.8161\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 174s 578us/step - loss: 0.2854 - acc: 0.8443 - f1: 0.8440 - precision_measure: 0.8469 - recall_measure: 0.8413 - val_loss: 0.4702 - val_acc: 0.8320 - val_f1: 0.8313 - val_precision_measure: 0.8336 - val_recall_measure: 0.8291\n",
      "33762/33762 [==============================] - 7s 193us/step\n",
      "Fitting  18 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 187s 621us/step - loss: 0.7903 - acc: 0.5577 - f1: 0.4745 - precision_measure: 0.5876 - recall_measure: 0.4338 - val_loss: 1.0269 - val_acc: 0.4622 - val_f1: 0.4279 - val_precision_measure: 0.4649 - val_recall_measure: 0.4027\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 181s 601us/step - loss: 0.4708 - acc: 0.6968 - f1: 0.6898 - precision_measure: 0.7038 - recall_measure: 0.6766 - val_loss: 0.9185 - val_acc: 0.5635 - val_f1: 0.5574 - val_precision_measure: 0.5637 - val_recall_measure: 0.5517\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 184s 609us/step - loss: 0.4047 - acc: 0.7644 - f1: 0.7620 - precision_measure: 0.7704 - recall_measure: 0.7540 - val_loss: 0.8262 - val_acc: 0.5416 - val_f1: 0.5353 - val_precision_measure: 0.5428 - val_recall_measure: 0.5288\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 185s 613us/step - loss: 0.3640 - acc: 0.7947 - f1: 0.7930 - precision_measure: 0.7994 - recall_measure: 0.7867 - val_loss: 0.5444 - val_acc: 0.7996 - val_f1: 0.7968 - val_precision_measure: 0.8020 - val_recall_measure: 0.7920\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 182s 605us/step - loss: 0.3389 - acc: 0.8093 - f1: 0.8081 - precision_measure: 0.8130 - recall_measure: 0.8034 - val_loss: 0.4961 - val_acc: 0.8255 - val_f1: 0.8244 - val_precision_measure: 0.8276 - val_recall_measure: 0.8214\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 184s 609us/step - loss: 0.3142 - acc: 0.8254 - f1: 0.8249 - precision_measure: 0.8288 - recall_measure: 0.8211 - val_loss: 0.5991 - val_acc: 0.7753 - val_f1: 0.7727 - val_precision_measure: 0.7775 - val_recall_measure: 0.7684\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 182s 602us/step - loss: 0.2911 - acc: 0.8390 - f1: 0.8386 - precision_measure: 0.8416 - recall_measure: 0.8356 - val_loss: 0.4867 - val_acc: 0.8230 - val_f1: 0.8226 - val_precision_measure: 0.8238 - val_recall_measure: 0.8215\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 186s 617us/step - loss: 0.2781 - acc: 0.8474 - f1: 0.8470 - precision_measure: 0.8496 - recall_measure: 0.8445 - val_loss: 0.5059 - val_acc: 0.8219 - val_f1: 0.8217 - val_precision_measure: 0.8230 - val_recall_measure: 0.8205\n",
      "33762/33762 [==============================] - 7s 198us/step\n",
      "Fitting  19 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 191s 634us/step - loss: 0.8023 - acc: 0.5478 - f1: 0.4647 - precision_measure: 0.5767 - recall_measure: 0.4232 - val_loss: 0.9870 - val_acc: 0.4657 - val_f1: 0.4447 - val_precision_measure: 0.4675 - val_recall_measure: 0.4282\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 185s 615us/step - loss: 0.4881 - acc: 0.6665 - f1: 0.6584 - precision_measure: 0.6750 - recall_measure: 0.6430 - val_loss: 0.7444 - val_acc: 0.6118 - val_f1: 0.6079 - val_precision_measure: 0.6134 - val_recall_measure: 0.6030\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 190s 630us/step - loss: 0.4393 - acc: 0.7144 - f1: 0.7098 - precision_measure: 0.7214 - recall_measure: 0.6988 - val_loss: 0.8256 - val_acc: 0.5355 - val_f1: 0.5330 - val_precision_measure: 0.5366 - val_recall_measure: 0.5297\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 186s 616us/step - loss: 0.4042 - acc: 0.7445 - f1: 0.7419 - precision_measure: 0.7513 - recall_measure: 0.7330 - val_loss: 0.7147 - val_acc: 0.6439 - val_f1: 0.6402 - val_precision_measure: 0.6459 - val_recall_measure: 0.6349\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 188s 622us/step - loss: 0.3862 - acc: 0.7613 - f1: 0.7595 - precision_measure: 0.7672 - recall_measure: 0.7521 - val_loss: 0.4863 - val_acc: 0.8195 - val_f1: 0.8172 - val_precision_measure: 0.8214 - val_recall_measure: 0.8132\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 190s 628us/step - loss: 0.3569 - acc: 0.7794 - f1: 0.7779 - precision_measure: 0.7840 - recall_measure: 0.7720 - val_loss: 0.7626 - val_acc: 0.6556 - val_f1: 0.6515 - val_precision_measure: 0.6572 - val_recall_measure: 0.6462\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 186s 616us/step - loss: 0.3381 - acc: 0.7986 - f1: 0.7975 - precision_measure: 0.8022 - recall_measure: 0.7930 - val_loss: 0.5507 - val_acc: 0.7781 - val_f1: 0.7761 - val_precision_measure: 0.7804 - val_recall_measure: 0.7721\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 188s 625us/step - loss: 0.3132 - acc: 0.8218 - f1: 0.8212 - precision_measure: 0.8248 - recall_measure: 0.8176 - val_loss: 0.4646 - val_acc: 0.8249 - val_f1: 0.8241 - val_precision_measure: 0.8260 - val_recall_measure: 0.8224\n",
      "33762/33762 [==============================] - 7s 204us/step\n",
      "Fitting  20 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.7759 - acc: 0.5468 - f1: 0.4717 - precision_measure: 0.5724 - recall_measure: 0.4315 - val_loss: 0.9906 - val_acc: 0.4225 - val_f1: 0.4090 - val_precision_measure: 0.4220 - val_recall_measure: 0.3983\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 184s 609us/step - loss: 0.4860 - acc: 0.6564 - f1: 0.6484 - precision_measure: 0.6640 - recall_measure: 0.6338 - val_loss: 0.7642 - val_acc: 0.6062 - val_f1: 0.6018 - val_precision_measure: 0.6090 - val_recall_measure: 0.5956\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 191s 632us/step - loss: 0.4355 - acc: 0.7136 - f1: 0.7089 - precision_measure: 0.7206 - recall_measure: 0.6978 - val_loss: 0.7630 - val_acc: 0.6380 - val_f1: 0.6344 - val_precision_measure: 0.6401 - val_recall_measure: 0.6293\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 185s 613us/step - loss: 0.4059 - acc: 0.7417 - f1: 0.7388 - precision_measure: 0.7480 - recall_measure: 0.7299 - val_loss: 0.6699 - val_acc: 0.6960 - val_f1: 0.6877 - val_precision_measure: 0.6989 - val_recall_measure: 0.6782\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 187s 621us/step - loss: 0.3803 - acc: 0.7630 - f1: 0.7608 - precision_measure: 0.7683 - recall_measure: 0.7536 - val_loss: 1.2118 - val_acc: 0.4847 - val_f1: 0.4817 - val_precision_measure: 0.4861 - val_recall_measure: 0.4776\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 187s 619us/step - loss: 0.3606 - acc: 0.7793 - f1: 0.7776 - precision_measure: 0.7837 - recall_measure: 0.7717 - val_loss: 0.7039 - val_acc: 0.7006 - val_f1: 0.6964 - val_precision_measure: 0.7029 - val_recall_measure: 0.6906\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 186s 618us/step - loss: 0.3428 - acc: 0.7924 - f1: 0.7913 - precision_measure: 0.7963 - recall_measure: 0.7864 - val_loss: 0.5333 - val_acc: 0.8001 - val_f1: 0.7989 - val_precision_measure: 0.8021 - val_recall_measure: 0.7959\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 188s 623us/step - loss: 0.3304 - acc: 0.8047 - f1: 0.8037 - precision_measure: 0.8077 - recall_measure: 0.7998 - val_loss: 0.4762 - val_acc: 0.8239 - val_f1: 0.8217 - val_precision_measure: 0.8252 - val_recall_measure: 0.8184\n",
      "33762/33762 [==============================] - 8s 224us/step\n",
      "Fitting  21 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 200s 663us/step - loss: 0.6804 - acc: 0.5395 - f1: 0.4826 - precision_measure: 0.5567 - recall_measure: 0.4491 - val_loss: 0.9091 - val_acc: 0.5368 - val_f1: 0.5272 - val_precision_measure: 0.5406 - val_recall_measure: 0.5159\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 188s 624us/step - loss: 0.4270 - acc: 0.7190 - f1: 0.7137 - precision_measure: 0.7273 - recall_measure: 0.7010 - val_loss: 0.7066 - val_acc: 0.6727 - val_f1: 0.6699 - val_precision_measure: 0.6747 - val_recall_measure: 0.6654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 177s 587us/step - loss: 0.3653 - acc: 0.7888 - f1: 0.7870 - precision_measure: 0.7952 - recall_measure: 0.7792 - val_loss: 0.5355 - val_acc: 0.7941 - val_f1: 0.7924 - val_precision_measure: 0.7961 - val_recall_measure: 0.7891\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 179s 595us/step - loss: 0.3287 - acc: 0.8149 - f1: 0.8139 - precision_measure: 0.8200 - recall_measure: 0.8079 - val_loss: 0.4719 - val_acc: 0.7974 - val_f1: 0.7960 - val_precision_measure: 0.7989 - val_recall_measure: 0.7934\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.3038 - acc: 0.8307 - f1: 0.8300 - precision_measure: 0.8349 - recall_measure: 0.8252 - val_loss: 0.5042 - val_acc: 0.8066 - val_f1: 0.8058 - val_precision_measure: 0.8085 - val_recall_measure: 0.8032\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 594us/step - loss: 0.2834 - acc: 0.8428 - f1: 0.8424 - precision_measure: 0.8463 - recall_measure: 0.8386 - val_loss: 0.4006 - val_acc: 0.8726 - val_f1: 0.8715 - val_precision_measure: 0.8740 - val_recall_measure: 0.8693\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 180s 595us/step - loss: 0.2691 - acc: 0.8523 - f1: 0.8521 - precision_measure: 0.8553 - recall_measure: 0.8489 - val_loss: 0.4008 - val_acc: 0.8665 - val_f1: 0.8656 - val_precision_measure: 0.8681 - val_recall_measure: 0.8632\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.2517 - acc: 0.8627 - f1: 0.8624 - precision_measure: 0.8648 - recall_measure: 0.8600 - val_loss: 0.6173 - val_acc: 0.7269 - val_f1: 0.7264 - val_precision_measure: 0.7281 - val_recall_measure: 0.7249\n",
      "33762/33762 [==============================] - 7s 195us/step\n",
      "Fitting  22 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 183s 606us/step - loss: 0.6705 - acc: 0.5790 - f1: 0.5210 - precision_measure: 0.5972 - recall_measure: 0.4898 - val_loss: 0.9155 - val_acc: 0.5448 - val_f1: 0.5346 - val_precision_measure: 0.5482 - val_recall_measure: 0.5236\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 178s 588us/step - loss: 0.4272 - acc: 0.7181 - f1: 0.7133 - precision_measure: 0.7248 - recall_measure: 0.7023 - val_loss: 0.8372 - val_acc: 0.5915 - val_f1: 0.5618 - val_precision_measure: 0.5968 - val_recall_measure: 0.5360\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 180s 598us/step - loss: 0.3752 - acc: 0.7709 - f1: 0.7687 - precision_measure: 0.7765 - recall_measure: 0.7612 - val_loss: 0.7135 - val_acc: 0.6637 - val_f1: 0.6579 - val_precision_measure: 0.6654 - val_recall_measure: 0.6514\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 178s 591us/step - loss: 0.3364 - acc: 0.8052 - f1: 0.8038 - precision_measure: 0.8092 - recall_measure: 0.7986 - val_loss: 0.6320 - val_acc: 0.7395 - val_f1: 0.7373 - val_precision_measure: 0.7410 - val_recall_measure: 0.7339\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 180s 597us/step - loss: 0.3081 - acc: 0.8272 - f1: 0.8267 - precision_measure: 0.8305 - recall_measure: 0.8229 - val_loss: 0.8680 - val_acc: 0.6272 - val_f1: 0.6249 - val_precision_measure: 0.6284 - val_recall_measure: 0.6216\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 178s 591us/step - loss: 0.2826 - acc: 0.8441 - f1: 0.8438 - precision_measure: 0.8468 - recall_measure: 0.8408 - val_loss: 0.4305 - val_acc: 0.8442 - val_f1: 0.8437 - val_precision_measure: 0.8456 - val_recall_measure: 0.8419\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 176s 585us/step - loss: 0.2689 - acc: 0.8554 - f1: 0.8551 - precision_measure: 0.8577 - recall_measure: 0.8525 - val_loss: 0.5948 - val_acc: 0.7632 - val_f1: 0.7623 - val_precision_measure: 0.7649 - val_recall_measure: 0.7599\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.2516 - acc: 0.8642 - f1: 0.8640 - precision_measure: 0.8661 - recall_measure: 0.8620 - val_loss: 0.5289 - val_acc: 0.7867 - val_f1: 0.7862 - val_precision_measure: 0.7873 - val_recall_measure: 0.7852\n",
      "33762/33762 [==============================] - 7s 203us/step\n",
      "Fitting  23 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 182s 602us/step - loss: 0.6625 - acc: 0.5361 - f1: 0.4859 - precision_measure: 0.5499 - recall_measure: 0.4543 - val_loss: 0.8049 - val_acc: 0.5615 - val_f1: 0.5502 - val_precision_measure: 0.5654 - val_recall_measure: 0.5377\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 181s 599us/step - loss: 0.4346 - acc: 0.7126 - f1: 0.7064 - precision_measure: 0.7200 - recall_measure: 0.6936 - val_loss: 0.9335 - val_acc: 0.5120 - val_f1: 0.5016 - val_precision_measure: 0.5125 - val_recall_measure: 0.4922\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 180s 597us/step - loss: 0.3623 - acc: 0.7916 - f1: 0.7897 - precision_measure: 0.7968 - recall_measure: 0.7829 - val_loss: 1.0249 - val_acc: 0.5014 - val_f1: 0.4998 - val_precision_measure: 0.5019 - val_recall_measure: 0.4978\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 178s 590us/step - loss: 0.3267 - acc: 0.8188 - f1: 0.8179 - precision_measure: 0.8230 - recall_measure: 0.8129 - val_loss: 0.6229 - val_acc: 0.7267 - val_f1: 0.7250 - val_precision_measure: 0.7278 - val_recall_measure: 0.7224\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 178s 590us/step - loss: 0.3030 - acc: 0.8363 - f1: 0.8356 - precision_measure: 0.8395 - recall_measure: 0.8318 - val_loss: 0.3935 - val_acc: 0.8645 - val_f1: 0.8635 - val_precision_measure: 0.8664 - val_recall_measure: 0.8608\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 594us/step - loss: 0.2844 - acc: 0.8469 - f1: 0.8464 - precision_measure: 0.8496 - recall_measure: 0.8433 - val_loss: 0.4723 - val_acc: 0.8210 - val_f1: 0.8200 - val_precision_measure: 0.8221 - val_recall_measure: 0.8180\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 180s 596us/step - loss: 0.2676 - acc: 0.8563 - f1: 0.8560 - precision_measure: 0.8586 - recall_measure: 0.8534 - val_loss: 0.5911 - val_acc: 0.7549 - val_f1: 0.7545 - val_precision_measure: 0.7559 - val_recall_measure: 0.7531\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 185s 614us/step - loss: 0.2572 - acc: 0.8630 - f1: 0.8627 - precision_measure: 0.8649 - recall_measure: 0.8606 - val_loss: 0.3764 - val_acc: 0.8736 - val_f1: 0.8733 - val_precision_measure: 0.8750 - val_recall_measure: 0.8717\n",
      "33762/33762 [==============================] - 8s 226us/step\n",
      "Fitting  24 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 182s 603us/step - loss: 0.6711 - acc: 0.5274 - f1: 0.4705 - precision_measure: 0.5438 - recall_measure: 0.4360 - val_loss: 0.9554 - val_acc: 0.4598 - val_f1: 0.4411 - val_precision_measure: 0.4589 - val_recall_measure: 0.4272\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 182s 602us/step - loss: 0.4230 - acc: 0.7142 - f1: 0.7081 - precision_measure: 0.7218 - recall_measure: 0.6953 - val_loss: 0.7582 - val_acc: 0.6226 - val_f1: 0.6123 - val_precision_measure: 0.6231 - val_recall_measure: 0.6032\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 180s 596us/step - loss: 0.3533 - acc: 0.7959 - f1: 0.7941 - precision_measure: 0.8017 - recall_measure: 0.7867 - val_loss: 0.9119 - val_acc: 0.5592 - val_f1: 0.5546 - val_precision_measure: 0.5597 - val_recall_measure: 0.5500\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 180s 596us/step - loss: 0.3174 - acc: 0.8208 - f1: 0.8199 - precision_measure: 0.8248 - recall_measure: 0.8150 - val_loss: 0.4341 - val_acc: 0.8485 - val_f1: 0.8466 - val_precision_measure: 0.8510 - val_recall_measure: 0.8427\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 180s 597us/step - loss: 0.2999 - acc: 0.8342 - f1: 0.8334 - precision_measure: 0.8375 - recall_measure: 0.8294 - val_loss: 0.5851 - val_acc: 0.7540 - val_f1: 0.7504 - val_precision_measure: 0.7559 - val_recall_measure: 0.7453\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 175s 581us/step - loss: 0.2743 - acc: 0.8472 - f1: 0.8467 - precision_measure: 0.8499 - recall_measure: 0.8437 - val_loss: 0.5825 - val_acc: 0.7407 - val_f1: 0.7397 - val_precision_measure: 0.7419 - val_recall_measure: 0.7376\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 175s 581us/step - loss: 0.2557 - acc: 0.8580 - f1: 0.8578 - precision_measure: 0.8602 - recall_measure: 0.8555 - val_loss: 0.5077 - val_acc: 0.7938 - val_f1: 0.7930 - val_precision_measure: 0.7952 - val_recall_measure: 0.7909\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 174s 578us/step - loss: 0.2413 - acc: 0.8687 - f1: 0.8684 - precision_measure: 0.8704 - recall_measure: 0.8665 - val_loss: 0.6346 - val_acc: 0.7440 - val_f1: 0.7426 - val_precision_measure: 0.7456 - val_recall_measure: 0.7398\n",
      "33762/33762 [==============================] - 7s 205us/step\n",
      "Fitting  25 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 184s 609us/step - loss: 0.6121 - acc: 0.5817 - f1: 0.5408 - precision_measure: 0.5979 - recall_measure: 0.5109 - val_loss: 0.7903 - val_acc: 0.6215 - val_f1: 0.6170 - val_precision_measure: 0.6254 - val_recall_measure: 0.6097\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 176s 582us/step - loss: 0.3902 - acc: 0.7616 - f1: 0.7584 - precision_measure: 0.7684 - recall_measure: 0.7489 - val_loss: 0.5906 - val_acc: 0.7623 - val_f1: 0.7593 - val_precision_measure: 0.7655 - val_recall_measure: 0.7536\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.3348 - acc: 0.8116 - f1: 0.8103 - precision_measure: 0.8169 - recall_measure: 0.8039 - val_loss: 0.6886 - val_acc: 0.7042 - val_f1: 0.6974 - val_precision_measure: 0.7071 - val_recall_measure: 0.6889\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 176s 583us/step - loss: 0.3018 - acc: 0.8294 - f1: 0.8288 - precision_measure: 0.8340 - recall_measure: 0.8237 - val_loss: 0.3581 - val_acc: 0.8877 - val_f1: 0.8870 - val_precision_measure: 0.8906 - val_recall_measure: 0.8837\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 175s 581us/step - loss: 0.2802 - acc: 0.8429 - f1: 0.8423 - precision_measure: 0.8460 - recall_measure: 0.8386 - val_loss: 0.3761 - val_acc: 0.8775 - val_f1: 0.8764 - val_precision_measure: 0.8795 - val_recall_measure: 0.8735\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 176s 584us/step - loss: 0.2636 - acc: 0.8527 - f1: 0.8524 - precision_measure: 0.8553 - recall_measure: 0.8495 - val_loss: 0.4296 - val_acc: 0.8362 - val_f1: 0.8353 - val_precision_measure: 0.8369 - val_recall_measure: 0.8338\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.2519 - acc: 0.8600 - f1: 0.8597 - precision_measure: 0.8624 - recall_measure: 0.8571 - val_loss: 0.3649 - val_acc: 0.8644 - val_f1: 0.8642 - val_precision_measure: 0.8650 - val_recall_measure: 0.8635\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 177s 585us/step - loss: 0.2381 - acc: 0.8692 - f1: 0.8690 - precision_measure: 0.8711 - recall_measure: 0.8670 - val_loss: 0.3839 - val_acc: 0.8748 - val_f1: 0.8745 - val_precision_measure: 0.8764 - val_recall_measure: 0.8728\n",
      "33762/33762 [==============================] - 7s 213us/step\n",
      "Fitting  26 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 184s 610us/step - loss: 0.6092 - acc: 0.5963 - f1: 0.5588 - precision_measure: 0.6161 - recall_measure: 0.5285 - val_loss: 0.8745 - val_acc: 0.5699 - val_f1: 0.5566 - val_precision_measure: 0.5717 - val_recall_measure: 0.5443\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.3996 - acc: 0.7500 - f1: 0.7460 - precision_measure: 0.7567 - recall_measure: 0.7358 - val_loss: 0.6999 - val_acc: 0.6070 - val_f1: 0.6041 - val_precision_measure: 0.6097 - val_recall_measure: 0.5990\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 179s 593us/step - loss: 0.3479 - acc: 0.7933 - f1: 0.7916 - precision_measure: 0.7989 - recall_measure: 0.7846 - val_loss: 0.6356 - val_acc: 0.7232 - val_f1: 0.7222 - val_precision_measure: 0.7248 - val_recall_measure: 0.7197\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 179s 592us/step - loss: 0.3088 - acc: 0.8258 - f1: 0.8249 - precision_measure: 0.8300 - recall_measure: 0.8200 - val_loss: 0.5691 - val_acc: 0.7630 - val_f1: 0.7627 - val_precision_measure: 0.7652 - val_recall_measure: 0.7603\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 178s 590us/step - loss: 0.2837 - acc: 0.8411 - f1: 0.8404 - precision_measure: 0.8446 - recall_measure: 0.8364 - val_loss: 0.5740 - val_acc: 0.7628 - val_f1: 0.7619 - val_precision_measure: 0.7645 - val_recall_measure: 0.7594\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 187s 621us/step - loss: 0.2644 - acc: 0.8519 - f1: 0.8515 - precision_measure: 0.8545 - recall_measure: 0.8487 - val_loss: 0.4908 - val_acc: 0.8255 - val_f1: 0.8228 - val_precision_measure: 0.8285 - val_recall_measure: 0.8177\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 178s 591us/step - loss: 0.2469 - acc: 0.8618 - f1: 0.8614 - precision_measure: 0.8638 - recall_measure: 0.8591 - val_loss: 0.4928 - val_acc: 0.8136 - val_f1: 0.8131 - val_precision_measure: 0.8148 - val_recall_measure: 0.8114\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 179s 595us/step - loss: 0.2305 - acc: 0.8706 - f1: 0.8705 - precision_measure: 0.8721 - recall_measure: 0.8688 - val_loss: 0.5964 - val_acc: 0.7742 - val_f1: 0.7736 - val_precision_measure: 0.7750 - val_recall_measure: 0.7723\n",
      "33762/33762 [==============================] - 7s 206us/step\n",
      "Fitting  27 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 182s 603us/step - loss: 0.5886 - acc: 0.6073 - f1: 0.5752 - precision_measure: 0.6245 - recall_measure: 0.5483 - val_loss: 0.8812 - val_acc: 0.6098 - val_f1: 0.6007 - val_precision_measure: 0.6167 - val_recall_measure: 0.5874\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 177s 586us/step - loss: 0.3746 - acc: 0.7851 - f1: 0.7828 - precision_measure: 0.7917 - recall_measure: 0.7742 - val_loss: 0.5240 - val_acc: 0.8080 - val_f1: 0.8050 - val_precision_measure: 0.8113 - val_recall_measure: 0.7992\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.3252 - acc: 0.8187 - f1: 0.8176 - precision_measure: 0.8239 - recall_measure: 0.8114 - val_loss: 0.6868 - val_acc: 0.6911 - val_f1: 0.6896 - val_precision_measure: 0.6935 - val_recall_measure: 0.6861\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 177s 585us/step - loss: 0.2938 - acc: 0.8383 - f1: 0.8374 - precision_measure: 0.8423 - recall_measure: 0.8326 - val_loss: 0.4754 - val_acc: 0.8213 - val_f1: 0.8202 - val_precision_measure: 0.8227 - val_recall_measure: 0.8178\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 180s 596us/step - loss: 0.2699 - acc: 0.8521 - f1: 0.8516 - precision_measure: 0.8552 - recall_measure: 0.8480 - val_loss: 0.6873 - val_acc: 0.7506 - val_f1: 0.7502 - val_precision_measure: 0.7519 - val_recall_measure: 0.7487\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 594us/step - loss: 0.2505 - acc: 0.8625 - f1: 0.8623 - precision_measure: 0.8649 - recall_measure: 0.8596 - val_loss: 0.4776 - val_acc: 0.8122 - val_f1: 0.8118 - val_precision_measure: 0.8146 - val_recall_measure: 0.8092\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.2326 - acc: 0.8716 - f1: 0.8713 - precision_measure: 0.8733 - recall_measure: 0.8694 - val_loss: 0.4425 - val_acc: 0.8346 - val_f1: 0.8344 - val_precision_measure: 0.8363 - val_recall_measure: 0.8327\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 188s 622us/step - loss: 0.2200 - acc: 0.8806 - f1: 0.8804 - precision_measure: 0.8820 - recall_measure: 0.8788 - val_loss: 0.6309 - val_acc: 0.7580 - val_f1: 0.7575 - val_precision_measure: 0.7584 - val_recall_measure: 0.7566\n",
      "33762/33762 [==============================] - 7s 208us/step\n",
      "Fitting  28 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 181s 601us/step - loss: 0.5797 - acc: 0.6095 - f1: 0.5784 - precision_measure: 0.6261 - recall_measure: 0.5517 - val_loss: 0.8433 - val_acc: 0.5708 - val_f1: 0.5503 - val_precision_measure: 0.5727 - val_recall_measure: 0.5326\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 182s 603us/step - loss: 0.3772 - acc: 0.7672 - f1: 0.7641 - precision_measure: 0.7733 - recall_measure: 0.7552 - val_loss: 0.8040 - val_acc: 0.6046 - val_f1: 0.6029 - val_precision_measure: 0.6064 - val_recall_measure: 0.5997\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 179s 592us/step - loss: 0.3234 - acc: 0.8167 - f1: 0.8157 - precision_measure: 0.8210 - recall_measure: 0.8104 - val_loss: 0.4420 - val_acc: 0.8572 - val_f1: 0.8560 - val_precision_measure: 0.8602 - val_recall_measure: 0.8523\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 179s 593us/step - loss: 0.2867 - acc: 0.8402 - f1: 0.8395 - precision_measure: 0.8434 - recall_measure: 0.8358 - val_loss: 0.2966 - val_acc: 0.9071 - val_f1: 0.9068 - val_precision_measure: 0.9082 - val_recall_measure: 0.9054\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 181s 602us/step - loss: 0.2658 - acc: 0.8522 - f1: 0.8518 - precision_measure: 0.8549 - recall_measure: 0.8488 - val_loss: 0.4301 - val_acc: 0.8459 - val_f1: 0.8455 - val_precision_measure: 0.8467 - val_recall_measure: 0.8444\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 594us/step - loss: 0.2499 - acc: 0.8633 - f1: 0.8631 - precision_measure: 0.8654 - recall_measure: 0.8608 - val_loss: 0.4817 - val_acc: 0.8267 - val_f1: 0.8253 - val_precision_measure: 0.8327 - val_recall_measure: 0.8186\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 180s 596us/step - loss: 0.2278 - acc: 0.8749 - f1: 0.8748 - precision_measure: 0.8765 - recall_measure: 0.8731 - val_loss: 0.3865 - val_acc: 0.8678 - val_f1: 0.8675 - val_precision_measure: 0.8688 - val_recall_measure: 0.8663\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 183s 606us/step - loss: 0.2181 - acc: 0.8827 - f1: 0.8827 - precision_measure: 0.8841 - recall_measure: 0.8813 - val_loss: 0.4185 - val_acc: 0.8510 - val_f1: 0.8508 - val_precision_measure: 0.8517 - val_recall_measure: 0.8500\n",
      "33762/33762 [==============================] - 7s 221us/step\n",
      "Fitting  29 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 179s 594us/step - loss: 0.5772 - acc: 0.6085 - f1: 0.5768 - precision_measure: 0.6249 - recall_measure: 0.5487 - val_loss: 0.8395 - val_acc: 0.6016 - val_f1: 0.5947 - val_precision_measure: 0.6028 - val_recall_measure: 0.5876\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 178s 590us/step - loss: 0.3867 - acc: 0.7468 - f1: 0.7437 - precision_measure: 0.7535 - recall_measure: 0.7343 - val_loss: 0.7293 - val_acc: 0.6166 - val_f1: 0.6114 - val_precision_measure: 0.6185 - val_recall_measure: 0.6051\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 177s 586us/step - loss: 0.3346 - acc: 0.8009 - f1: 0.7997 - precision_measure: 0.8066 - recall_measure: 0.7931 - val_loss: 0.5619 - val_acc: 0.7627 - val_f1: 0.7574 - val_precision_measure: 0.7673 - val_recall_measure: 0.7487\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 177s 587us/step - loss: 0.2985 - acc: 0.8260 - f1: 0.8251 - precision_measure: 0.8301 - recall_measure: 0.8202 - val_loss: 0.4674 - val_acc: 0.8166 - val_f1: 0.8157 - val_precision_measure: 0.8181 - val_recall_measure: 0.8135\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 178s 591us/step - loss: 0.2703 - acc: 0.8426 - f1: 0.8421 - precision_measure: 0.8454 - recall_measure: 0.8390 - val_loss: 0.7005 - val_acc: 0.7038 - val_f1: 0.7023 - val_precision_measure: 0.7060 - val_recall_measure: 0.6988\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 177s 587us/step - loss: 0.2517 - acc: 0.8554 - f1: 0.8550 - precision_measure: 0.8577 - recall_measure: 0.8523 - val_loss: 0.5449 - val_acc: 0.7725 - val_f1: 0.7718 - val_precision_measure: 0.7745 - val_recall_measure: 0.7692\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 182s 604us/step - loss: 0.2388 - acc: 0.8623 - f1: 0.8621 - precision_measure: 0.8642 - recall_measure: 0.8601 - val_loss: 0.4038 - val_acc: 0.8394 - val_f1: 0.8390 - val_precision_measure: 0.8409 - val_recall_measure: 0.8372\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.2200 - acc: 0.8719 - f1: 0.8718 - precision_measure: 0.8734 - recall_measure: 0.8701 - val_loss: 0.3738 - val_acc: 0.8605 - val_f1: 0.8604 - val_precision_measure: 0.8615 - val_recall_measure: 0.8593\n",
      "33762/33762 [==============================] - 7s 218us/step\n",
      "Fitting  30 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 187s 621us/step - loss: 0.5512 - acc: 0.6553 - f1: 0.6315 - precision_measure: 0.6732 - recall_measure: 0.6058 - val_loss: 1.1003 - val_acc: 0.4542 - val_f1: 0.4509 - val_precision_measure: 0.4550 - val_recall_measure: 0.4472\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.3681 - acc: 0.7842 - f1: 0.7817 - precision_measure: 0.7900 - recall_measure: 0.7737 - val_loss: 0.7119 - val_acc: 0.6624 - val_f1: 0.6591 - val_precision_measure: 0.6635 - val_recall_measure: 0.6551\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 190s 631us/step - loss: 0.3216 - acc: 0.8137 - f1: 0.8123 - precision_measure: 0.8181 - recall_measure: 0.8066 - val_loss: 0.7276 - val_acc: 0.6614 - val_f1: 0.6593 - val_precision_measure: 0.6634 - val_recall_measure: 0.6556\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 194s 644us/step - loss: 0.2924 - acc: 0.8324 - f1: 0.8318 - precision_measure: 0.8364 - recall_measure: 0.8273 - val_loss: 0.4356 - val_acc: 0.8348 - val_f1: 0.8340 - val_precision_measure: 0.8364 - val_recall_measure: 0.8317\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 197s 653us/step - loss: 0.2720 - acc: 0.8439 - f1: 0.8435 - precision_measure: 0.8470 - recall_measure: 0.8400 - val_loss: 0.3413 - val_acc: 0.8977 - val_f1: 0.8966 - val_precision_measure: 0.8987 - val_recall_measure: 0.8946\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 194s 642us/step - loss: 0.2533 - acc: 0.8544 - f1: 0.8541 - precision_measure: 0.8568 - recall_measure: 0.8516 - val_loss: 0.6720 - val_acc: 0.7168 - val_f1: 0.7160 - val_precision_measure: 0.7174 - val_recall_measure: 0.7147\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 196s 651us/step - loss: 0.2357 - acc: 0.8657 - f1: 0.8654 - precision_measure: 0.8676 - recall_measure: 0.8633 - val_loss: 0.3749 - val_acc: 0.8609 - val_f1: 0.8605 - val_precision_measure: 0.8620 - val_recall_measure: 0.8591\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 198s 656us/step - loss: 0.2246 - acc: 0.8744 - f1: 0.8742 - precision_measure: 0.8761 - recall_measure: 0.8723 - val_loss: 0.4791 - val_acc: 0.8179 - val_f1: 0.8168 - val_precision_measure: 0.8193 - val_recall_measure: 0.8143\n",
      "33762/33762 [==============================] - 9s 272us/step\n",
      "Fitting  31 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 202s 670us/step - loss: 0.5285 - acc: 0.6741 - f1: 0.6480 - precision_measure: 0.6889 - recall_measure: 0.6246 - val_loss: 0.6498 - val_acc: 0.6960 - val_f1: 0.6915 - val_precision_measure: 0.6981 - val_recall_measure: 0.6857\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 201s 666us/step - loss: 0.3449 - acc: 0.7990 - f1: 0.7970 - precision_measure: 0.8044 - recall_measure: 0.7898 - val_loss: 0.4029 - val_acc: 0.8497 - val_f1: 0.8482 - val_precision_measure: 0.8510 - val_recall_measure: 0.8456\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 200s 664us/step - loss: 0.2894 - acc: 0.8375 - f1: 0.8369 - precision_measure: 0.8412 - recall_measure: 0.8328 - val_loss: 0.4079 - val_acc: 0.8549 - val_f1: 0.8545 - val_precision_measure: 0.8571 - val_recall_measure: 0.8521\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 180s 595us/step - loss: 0.2679 - acc: 0.8514 - f1: 0.8509 - precision_measure: 0.8543 - recall_measure: 0.8477 - val_loss: 0.5444 - val_acc: 0.7842 - val_f1: 0.7840 - val_precision_measure: 0.7858 - val_recall_measure: 0.7822\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 183s 605us/step - loss: 0.2489 - acc: 0.8633 - f1: 0.8631 - precision_measure: 0.8656 - recall_measure: 0.8606 - val_loss: 0.4242 - val_acc: 0.8474 - val_f1: 0.8474 - val_precision_measure: 0.8482 - val_recall_measure: 0.8467\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 594us/step - loss: 0.2347 - acc: 0.8705 - f1: 0.8704 - precision_measure: 0.8725 - recall_measure: 0.8683 - val_loss: 0.3644 - val_acc: 0.8691 - val_f1: 0.8684 - val_precision_measure: 0.8704 - val_recall_measure: 0.8666\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 182s 603us/step - loss: 0.2181 - acc: 0.8798 - f1: 0.8796 - precision_measure: 0.8811 - recall_measure: 0.8782 - val_loss: 0.4183 - val_acc: 0.8468 - val_f1: 0.8465 - val_precision_measure: 0.8476 - val_recall_measure: 0.8455\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 200s 663us/step - loss: 0.2071 - acc: 0.8862 - f1: 0.8861 - precision_measure: 0.8873 - recall_measure: 0.8850 - val_loss: 0.4743 - val_acc: 0.8182 - val_f1: 0.8178 - val_precision_measure: 0.8190 - val_recall_measure: 0.8166\n",
      "33762/33762 [==============================] - 8s 235us/step\n",
      "Fitting  32 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 199s 659us/step - loss: 0.5174 - acc: 0.6854 - f1: 0.6639 - precision_measure: 0.7004 - recall_measure: 0.6421 - val_loss: 0.6151 - val_acc: 0.7089 - val_f1: 0.7020 - val_precision_measure: 0.7131 - val_recall_measure: 0.6923\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 194s 642us/step - loss: 0.3387 - acc: 0.8035 - f1: 0.8021 - precision_measure: 0.8095 - recall_measure: 0.7949 - val_loss: 0.4648 - val_acc: 0.8399 - val_f1: 0.8377 - val_precision_measure: 0.8464 - val_recall_measure: 0.8300\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 192s 637us/step - loss: 0.2957 - acc: 0.8309 - f1: 0.8303 - precision_measure: 0.8353 - recall_measure: 0.8254 - val_loss: 0.6795 - val_acc: 0.6997 - val_f1: 0.6973 - val_precision_measure: 0.7012 - val_recall_measure: 0.6936\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.2668 - acc: 0.8483 - f1: 0.8480 - precision_measure: 0.8512 - recall_measure: 0.8447 - val_loss: 0.4502 - val_acc: 0.8179 - val_f1: 0.8170 - val_precision_measure: 0.8203 - val_recall_measure: 0.8140\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 202s 669us/step - loss: 0.2420 - acc: 0.8614 - f1: 0.8610 - precision_measure: 0.8635 - recall_measure: 0.8585 - val_loss: 0.8288 - val_acc: 0.6585 - val_f1: 0.6561 - val_precision_measure: 0.6612 - val_recall_measure: 0.6515\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 206s 683us/step - loss: 0.2267 - acc: 0.8704 - f1: 0.8703 - precision_measure: 0.8723 - recall_measure: 0.8684 - val_loss: 0.5035 - val_acc: 0.7962 - val_f1: 0.7958 - val_precision_measure: 0.7971 - val_recall_measure: 0.7946\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 194s 643us/step - loss: 0.2069 - acc: 0.8840 - f1: 0.8839 - precision_measure: 0.8854 - recall_measure: 0.8825 - val_loss: 0.4885 - val_acc: 0.8315 - val_f1: 0.8298 - val_precision_measure: 0.8350 - val_recall_measure: 0.8250\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 200s 661us/step - loss: 0.1950 - acc: 0.8916 - f1: 0.8915 - precision_measure: 0.8927 - recall_measure: 0.8903 - val_loss: 0.4311 - val_acc: 0.8303 - val_f1: 0.8293 - val_precision_measure: 0.8321 - val_recall_measure: 0.8266\n",
      "33762/33762 [==============================] - 8s 232us/step\n",
      "Fitting  33 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 203s 673us/step - loss: 1.0381 - acc: 0.4908 - f1: 0.3265 - precision_measure: 0.5547 - recall_measure: 0.2579 - val_loss: 0.8786 - val_acc: 0.3037 - val_f1: 0.2721 - val_precision_measure: 0.3007 - val_recall_measure: 0.2567\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 194s 642us/step - loss: 0.6043 - acc: 0.5334 - f1: 0.4986 - precision_measure: 0.5360 - recall_measure: 0.4673 - val_loss: 0.8909 - val_acc: 0.4783 - val_f1: 0.4518 - val_precision_measure: 0.4789 - val_recall_measure: 0.4327\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 200s 663us/step - loss: 0.5485 - acc: 0.6154 - f1: 0.5961 - precision_measure: 0.6205 - recall_measure: 0.5742 - val_loss: 0.9470 - val_acc: 0.4166 - val_f1: 0.3972 - val_precision_measure: 0.4149 - val_recall_measure: 0.3835\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 206s 684us/step - loss: 0.5154 - acc: 0.6488 - f1: 0.6354 - precision_measure: 0.6550 - recall_measure: 0.6174 - val_loss: 0.8960 - val_acc: 0.4232 - val_f1: 0.4161 - val_precision_measure: 0.4225 - val_recall_measure: 0.4106\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 191s 632us/step - loss: 0.4866 - acc: 0.6827 - f1: 0.6732 - precision_measure: 0.6897 - recall_measure: 0.6577 - val_loss: 0.9758 - val_acc: 0.4480 - val_f1: 0.4384 - val_precision_measure: 0.4483 - val_recall_measure: 0.4300\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 196s 650us/step - loss: 0.4711 - acc: 0.6982 - f1: 0.6903 - precision_measure: 0.7060 - recall_measure: 0.6757 - val_loss: 0.9371 - val_acc: 0.4664 - val_f1: 0.4518 - val_precision_measure: 0.4680 - val_recall_measure: 0.4392\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 195s 646us/step - loss: 0.4499 - acc: 0.7174 - f1: 0.7114 - precision_measure: 0.7252 - recall_measure: 0.6985 - val_loss: 0.7840 - val_acc: 0.5283 - val_f1: 0.5191 - val_precision_measure: 0.5284 - val_recall_measure: 0.5111\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 194s 642us/step - loss: 0.4252 - acc: 0.7382 - f1: 0.7336 - precision_measure: 0.7456 - recall_measure: 0.7222 - val_loss: 0.6995 - val_acc: 0.5836 - val_f1: 0.5776 - val_precision_measure: 0.5843 - val_recall_measure: 0.5716\n",
      "33762/33762 [==============================] - 9s 257us/step\n",
      "Fitting  34 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 207s 688us/step - loss: 0.9607 - acc: 0.4707 - f1: 0.3210 - precision_measure: 0.5196 - recall_measure: 0.2604 - val_loss: 0.9451 - val_acc: 0.2857 - val_f1: 0.2261 - val_precision_measure: 0.2797 - val_recall_measure: 0.2052\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 195s 647us/step - loss: 0.6091 - acc: 0.4658 - f1: 0.4230 - precision_measure: 0.4632 - recall_measure: 0.3910 - val_loss: 0.8222 - val_acc: 0.3690 - val_f1: 0.3450 - val_precision_measure: 0.3667 - val_recall_measure: 0.3304\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 198s 655us/step - loss: 0.5633 - acc: 0.5563 - f1: 0.5303 - precision_measure: 0.5581 - recall_measure: 0.5060 - val_loss: 0.7376 - val_acc: 0.4858 - val_f1: 0.4774 - val_precision_measure: 0.4867 - val_recall_measure: 0.4694\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 206s 682us/step - loss: 0.5260 - acc: 0.5990 - f1: 0.5831 - precision_measure: 0.6037 - recall_measure: 0.5643 - val_loss: 0.7990 - val_acc: 0.4891 - val_f1: 0.4709 - val_precision_measure: 0.4864 - val_recall_measure: 0.4579\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 214s 709us/step - loss: 0.5035 - acc: 0.6398 - f1: 0.6293 - precision_measure: 0.6463 - recall_measure: 0.6136 - val_loss: 0.7632 - val_acc: 0.5088 - val_f1: 0.4998 - val_precision_measure: 0.5087 - val_recall_measure: 0.4921\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 196s 651us/step - loss: 0.4989 - acc: 0.6197 - f1: 0.6078 - precision_measure: 0.6261 - recall_measure: 0.5911 - val_loss: 0.9073 - val_acc: 0.4395 - val_f1: 0.4325 - val_precision_measure: 0.4407 - val_recall_measure: 0.4257\n",
      "Epoch 7/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 195s 647us/step - loss: 0.4646 - acc: 0.6795 - f1: 0.6726 - precision_measure: 0.6863 - recall_measure: 0.6598 - val_loss: 0.8543 - val_acc: 0.4523 - val_f1: 0.4455 - val_precision_measure: 0.4531 - val_recall_measure: 0.4390\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 206s 684us/step - loss: 0.4502 - acc: 0.6905 - f1: 0.6839 - precision_measure: 0.6966 - recall_measure: 0.6720 - val_loss: 0.8500 - val_acc: 0.4607 - val_f1: 0.4561 - val_precision_measure: 0.4602 - val_recall_measure: 0.4524\n",
      "33762/33762 [==============================] - 10s 303us/step\n",
      "Fitting  35 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 236s 784us/step - loss: 0.9664 - acc: 0.4667 - f1: 0.3206 - precision_measure: 0.5116 - recall_measure: 0.2666 - val_loss: 0.8225 - val_acc: 0.3130 - val_f1: 0.2689 - val_precision_measure: 0.3215 - val_recall_measure: 0.2482\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 198s 656us/step - loss: 0.5963 - acc: 0.4664 - f1: 0.4308 - precision_measure: 0.4648 - recall_measure: 0.4027 - val_loss: 0.7680 - val_acc: 0.4685 - val_f1: 0.4581 - val_precision_measure: 0.4695 - val_recall_measure: 0.4484\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 193s 640us/step - loss: 0.5499 - acc: 0.5825 - f1: 0.5596 - precision_measure: 0.5847 - recall_measure: 0.5373 - val_loss: 0.8198 - val_acc: 0.4938 - val_f1: 0.4630 - val_precision_measure: 0.4905 - val_recall_measure: 0.4420\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 195s 645us/step - loss: 0.5281 - acc: 0.6190 - f1: 0.6016 - precision_measure: 0.6232 - recall_measure: 0.5821 - val_loss: 0.8320 - val_acc: 0.5092 - val_f1: 0.4864 - val_precision_measure: 0.5070 - val_recall_measure: 0.4709\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 193s 641us/step - loss: 0.4964 - acc: 0.6603 - f1: 0.6486 - precision_measure: 0.6669 - recall_measure: 0.6317 - val_loss: 0.8145 - val_acc: 0.5690 - val_f1: 0.5575 - val_precision_measure: 0.5711 - val_recall_measure: 0.5460\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 193s 640us/step - loss: 0.4730 - acc: 0.6925 - f1: 0.6841 - precision_measure: 0.7006 - recall_measure: 0.6689 - val_loss: 0.8687 - val_acc: 0.5082 - val_f1: 0.4861 - val_precision_measure: 0.5096 - val_recall_measure: 0.4678\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 194s 645us/step - loss: 0.4511 - acc: 0.7078 - f1: 0.7019 - precision_measure: 0.7157 - recall_measure: 0.6888 - val_loss: 0.7977 - val_acc: 0.5799 - val_f1: 0.5749 - val_precision_measure: 0.5802 - val_recall_measure: 0.5702\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 201s 665us/step - loss: 0.4384 - acc: 0.7179 - f1: 0.7123 - precision_measure: 0.7248 - recall_measure: 0.7004 - val_loss: 0.8568 - val_acc: 0.5081 - val_f1: 0.4959 - val_precision_measure: 0.5059 - val_recall_measure: 0.4873\n",
      "33762/33762 [==============================] - 10s 300us/step\n",
      "Fitting  36 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 196s 650us/step - loss: 1.0028 - acc: 0.4969 - f1: 0.3566 - precision_measure: 0.5657 - recall_measure: 0.2936 - val_loss: 1.0169 - val_acc: 0.2809 - val_f1: 0.2697 - val_precision_measure: 0.2818 - val_recall_measure: 0.2612\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 195s 645us/step - loss: 0.6122 - acc: 0.4626 - f1: 0.4382 - precision_measure: 0.4756 - recall_measure: 0.4075 - val_loss: 0.8219 - val_acc: 0.3022 - val_f1: 0.2914 - val_precision_measure: 0.2990 - val_recall_measure: 0.2851\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 195s 647us/step - loss: 0.5529 - acc: 0.5076 - f1: 0.4738 - precision_measure: 0.5033 - recall_measure: 0.4484 - val_loss: 0.7825 - val_acc: 0.4571 - val_f1: 0.4237 - val_precision_measure: 0.4499 - val_recall_measure: 0.4049\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 193s 639us/step - loss: 0.5199 - acc: 0.5996 - f1: 0.5828 - precision_measure: 0.6020 - recall_measure: 0.5654 - val_loss: 0.7960 - val_acc: 0.7929 - val_f1: 0.7590 - val_precision_measure: 0.8019 - val_recall_measure: 0.7257\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 194s 642us/step - loss: 0.4873 - acc: 0.6715 - f1: 0.6612 - precision_measure: 0.6771 - recall_measure: 0.6463 - val_loss: 0.7686 - val_acc: 0.5733 - val_f1: 0.5671 - val_precision_measure: 0.5754 - val_recall_measure: 0.5597\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 192s 637us/step - loss: 0.4563 - acc: 0.7173 - f1: 0.7112 - precision_measure: 0.7241 - recall_measure: 0.6991 - val_loss: 0.7678 - val_acc: 0.5563 - val_f1: 0.5542 - val_precision_measure: 0.5590 - val_recall_measure: 0.5498\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 195s 645us/step - loss: 0.4468 - acc: 0.7253 - f1: 0.7194 - precision_measure: 0.7330 - recall_measure: 0.7067 - val_loss: 0.6618 - val_acc: 0.5863 - val_f1: 0.5835 - val_precision_measure: 0.5871 - val_recall_measure: 0.5803\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 191s 635us/step - loss: 0.4249 - acc: 0.7552 - f1: 0.7508 - precision_measure: 0.7615 - recall_measure: 0.7406 - val_loss: 0.8127 - val_acc: 0.5165 - val_f1: 0.5132 - val_precision_measure: 0.5167 - val_recall_measure: 0.5098\n",
      "33762/33762 [==============================] - 9s 264us/step\n",
      "Fitting  37 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 256s 847us/step - loss: 0.8585 - acc: 0.4734 - f1: 0.3646 - precision_measure: 0.5061 - recall_measure: 0.3143 - val_loss: 0.8464 - val_acc: 0.3324 - val_f1: 0.2937 - val_precision_measure: 0.3383 - val_recall_measure: 0.2738\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 197s 655us/step - loss: 0.5631 - acc: 0.5172 - f1: 0.4847 - precision_measure: 0.5206 - recall_measure: 0.4549 - val_loss: 0.7856 - val_acc: 0.5611 - val_f1: 0.5416 - val_precision_measure: 0.5629 - val_recall_measure: 0.5249\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 241s 799us/step - loss: 0.5121 - acc: 0.6272 - f1: 0.6108 - precision_measure: 0.6348 - recall_measure: 0.5891 - val_loss: 0.9142 - val_acc: 0.5419 - val_f1: 0.5120 - val_precision_measure: 0.5425 - val_recall_measure: 0.4896\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 382s 1ms/step - loss: 0.4810 - acc: 0.6608 - f1: 0.6495 - precision_measure: 0.6678 - recall_measure: 0.6325 - val_loss: 0.8342 - val_acc: 0.5417 - val_f1: 0.5299 - val_precision_measure: 0.5411 - val_recall_measure: 0.5204\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 380s 1ms/step - loss: 0.4541 - acc: 0.6884 - f1: 0.6802 - precision_measure: 0.6956 - recall_measure: 0.6658 - val_loss: 0.7301 - val_acc: 0.5242 - val_f1: 0.5132 - val_precision_measure: 0.5228 - val_recall_measure: 0.5055\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 299s 990us/step - loss: 0.4468 - acc: 0.6822 - f1: 0.6740 - precision_measure: 0.6874 - recall_measure: 0.6615 - val_loss: 0.7209 - val_acc: 0.6374 - val_f1: 0.6284 - val_precision_measure: 0.6416 - val_recall_measure: 0.6170\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 272s 902us/step - loss: 0.4206 - acc: 0.7263 - f1: 0.7210 - precision_measure: 0.7324 - recall_measure: 0.7101 - val_loss: 0.5980 - val_acc: 0.6988 - val_f1: 0.6954 - val_precision_measure: 0.7008 - val_recall_measure: 0.6903\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 256s 847us/step - loss: 0.3985 - acc: 0.7545 - f1: 0.7502 - precision_measure: 0.7603 - recall_measure: 0.7404 - val_loss: 0.6897 - val_acc: 0.6683 - val_f1: 0.6590 - val_precision_measure: 0.6698 - val_recall_measure: 0.6494\n",
      "33762/33762 [==============================] - 29s 868us/step\n",
      "Fitting  38 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 317s 1ms/step - loss: 0.8568 - acc: 0.4755 - f1: 0.3420 - precision_measure: 0.4979 - recall_measure: 0.2927 - val_loss: 0.8089 - val_acc: 0.4082 - val_f1: 0.2909 - val_precision_measure: 0.3752 - val_recall_measure: 0.2600\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 190s 630us/step - loss: 0.5365 - acc: 0.5880 - f1: 0.5643 - precision_measure: 0.5937 - recall_measure: 0.5388 - val_loss: 0.9324 - val_acc: 0.5062 - val_f1: 0.4801 - val_precision_measure: 0.4998 - val_recall_measure: 0.4646\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.4832 - acc: 0.6912 - f1: 0.6819 - precision_measure: 0.6993 - recall_measure: 0.6657 - val_loss: 0.7317 - val_acc: 0.6092 - val_f1: 0.6010 - val_precision_measure: 0.6084 - val_recall_measure: 0.5945\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 182s 604us/step - loss: 0.4399 - acc: 0.7358 - f1: 0.7306 - precision_measure: 0.7445 - recall_measure: 0.7175 - val_loss: 0.7159 - val_acc: 0.5933 - val_f1: 0.5871 - val_precision_measure: 0.5934 - val_recall_measure: 0.5816\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 205s 681us/step - loss: 0.4169 - acc: 0.7623 - f1: 0.7583 - precision_measure: 0.7707 - recall_measure: 0.7465 - val_loss: 0.6946 - val_acc: 0.6384 - val_f1: 0.6347 - val_precision_measure: 0.6396 - val_recall_measure: 0.6303\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 384s 1ms/step - loss: 0.3930 - acc: 0.7829 - f1: 0.7793 - precision_measure: 0.7895 - recall_measure: 0.7696 - val_loss: 0.6212 - val_acc: 0.7097 - val_f1: 0.7049 - val_precision_measure: 0.7107 - val_recall_measure: 0.6996\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 253s 839us/step - loss: 0.3881 - acc: 0.7936 - f1: 0.7910 - precision_measure: 0.7996 - recall_measure: 0.7829 - val_loss: 0.6087 - val_acc: 0.7618 - val_f1: 0.7482 - val_precision_measure: 0.7665 - val_recall_measure: 0.7322\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 192s 637us/step - loss: 0.3582 - acc: 0.8064 - f1: 0.8041 - precision_measure: 0.8119 - recall_measure: 0.7967 - val_loss: 0.5338 - val_acc: 0.7690 - val_f1: 0.7664 - val_precision_measure: 0.7700 - val_recall_measure: 0.7629\n",
      "33762/33762 [==============================] - 12s 367us/step\n",
      "Fitting  39 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 211s 701us/step - loss: 0.7900 - acc: 0.4866 - f1: 0.3839 - precision_measure: 0.5156 - recall_measure: 0.3361 - val_loss: 0.6578 - val_acc: 0.8443 - val_f1: 0.8280 - val_precision_measure: 0.8545 - val_recall_measure: 0.8072\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 191s 633us/step - loss: 0.5350 - acc: 0.5409 - f1: 0.5126 - precision_measure: 0.5438 - recall_measure: 0.4859 - val_loss: 0.6992 - val_acc: 0.5189 - val_f1: 0.5095 - val_precision_measure: 0.5212 - val_recall_measure: 0.4996\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 193s 639us/step - loss: 0.4922 - acc: 0.6284 - f1: 0.6142 - precision_measure: 0.6352 - recall_measure: 0.5950 - val_loss: 0.7931 - val_acc: 0.5241 - val_f1: 0.5200 - val_precision_measure: 0.5244 - val_recall_measure: 0.5161\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 189s 627us/step - loss: 0.4575 - acc: 0.6917 - f1: 0.6842 - precision_measure: 0.6995 - recall_measure: 0.6698 - val_loss: 0.7219 - val_acc: 0.5798 - val_f1: 0.5762 - val_precision_measure: 0.5800 - val_recall_measure: 0.5727\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 193s 641us/step - loss: 0.4305 - acc: 0.7302 - f1: 0.7253 - precision_measure: 0.7383 - recall_measure: 0.7130 - val_loss: 0.7658 - val_acc: 0.5535 - val_f1: 0.5486 - val_precision_measure: 0.5537 - val_recall_measure: 0.5440\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 301s 999us/step - loss: 0.4017 - acc: 0.7574 - f1: 0.7536 - precision_measure: 0.7650 - recall_measure: 0.7426 - val_loss: 0.8943 - val_acc: 0.5130 - val_f1: 0.5082 - val_precision_measure: 0.5150 - val_recall_measure: 0.5022\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 416s 1ms/step - loss: 0.3833 - acc: 0.7783 - f1: 0.7754 - precision_measure: 0.7854 - recall_measure: 0.7658 - val_loss: 0.6824 - val_acc: 0.6373 - val_f1: 0.6349 - val_precision_measure: 0.6384 - val_recall_measure: 0.6317\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 291s 964us/step - loss: 0.3687 - acc: 0.7935 - f1: 0.7911 - precision_measure: 0.7994 - recall_measure: 0.7831 - val_loss: 0.6722 - val_acc: 0.6742 - val_f1: 0.6700 - val_precision_measure: 0.6750 - val_recall_measure: 0.6655\n",
      "33762/33762 [==============================] - 13s 376us/step\n",
      "Fitting  40 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 288s 956us/step - loss: 0.8784 - acc: 0.4756 - f1: 0.3612 - precision_measure: 0.5244 - recall_measure: 0.3061 - val_loss: 0.8145 - val_acc: 0.3049 - val_f1: 0.2906 - val_precision_measure: 0.3038 - val_recall_measure: 0.2805\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 181s 600us/step - loss: 0.5416 - acc: 0.5482 - f1: 0.5219 - precision_measure: 0.5510 - recall_measure: 0.4966 - val_loss: 0.7919 - val_acc: 0.5186 - val_f1: 0.5096 - val_precision_measure: 0.5189 - val_recall_measure: 0.5018\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 246s 814us/step - loss: 0.4812 - acc: 0.6657 - f1: 0.6558 - precision_measure: 0.6726 - recall_measure: 0.6403 - val_loss: 0.7203 - val_acc: 0.5695 - val_f1: 0.5646 - val_precision_measure: 0.5709 - val_recall_measure: 0.5591\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 182s 604us/step - loss: 0.4410 - acc: 0.7147 - f1: 0.7091 - precision_measure: 0.7222 - recall_measure: 0.6968 - val_loss: 0.6557 - val_acc: 0.6716 - val_f1: 0.6578 - val_precision_measure: 0.6713 - val_recall_measure: 0.6465\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 186s 617us/step - loss: 0.4152 - acc: 0.7487 - f1: 0.7445 - precision_measure: 0.7563 - recall_measure: 0.7334 - val_loss: 0.6789 - val_acc: 0.6389 - val_f1: 0.6320 - val_precision_measure: 0.6403 - val_recall_measure: 0.6248\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 226s 750us/step - loss: 0.3879 - acc: 0.7781 - f1: 0.7749 - precision_measure: 0.7846 - recall_measure: 0.7656 - val_loss: 0.7846 - val_acc: 0.6134 - val_f1: 0.6069 - val_precision_measure: 0.6152 - val_recall_measure: 0.5995\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 227s 752us/step - loss: 0.3662 - acc: 0.7927 - f1: 0.7906 - precision_measure: 0.7987 - recall_measure: 0.7829 - val_loss: 0.8076 - val_acc: 0.5796 - val_f1: 0.5745 - val_precision_measure: 0.5824 - val_recall_measure: 0.5679\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 224s 742us/step - loss: 0.3624 - acc: 0.8003 - f1: 0.7980 - precision_measure: 0.8054 - recall_measure: 0.7909 - val_loss: 0.4417 - val_acc: 0.8361 - val_f1: 0.8352 - val_precision_measure: 0.8380 - val_recall_measure: 0.8325\n",
      "33762/33762 [==============================] - 13s 398us/step\n",
      "Fitting  41 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 242s 802us/step - loss: 0.7515 - acc: 0.4734 - f1: 0.4080 - precision_measure: 0.5112 - recall_measure: 0.3636 - val_loss: 0.8810 - val_acc: 0.2823 - val_f1: 0.2740 - val_precision_measure: 0.2827 - val_recall_measure: 0.2675\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 209s 692us/step - loss: 0.5452 - acc: 0.4580 - f1: 0.4346 - precision_measure: 0.4653 - recall_measure: 0.4087 - val_loss: 0.8436 - val_acc: 0.2976 - val_f1: 0.2865 - val_precision_measure: 0.2942 - val_recall_measure: 0.2806\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 207s 688us/step - loss: 0.5177 - acc: 0.5048 - f1: 0.4746 - precision_measure: 0.5037 - recall_measure: 0.4496 - val_loss: 0.9269 - val_acc: 0.3111 - val_f1: 0.2949 - val_precision_measure: 0.3065 - val_recall_measure: 0.2865\n",
      "Epoch 4/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 273s 906us/step - loss: 0.4753 - acc: 0.6369 - f1: 0.6214 - precision_measure: 0.6409 - recall_measure: 0.6036 - val_loss: 0.7970 - val_acc: 0.5633 - val_f1: 0.5493 - val_precision_measure: 0.5611 - val_recall_measure: 0.5397\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 223s 741us/step - loss: 0.4388 - acc: 0.6903 - f1: 0.6828 - precision_measure: 0.6966 - recall_measure: 0.6698 - val_loss: 0.7217 - val_acc: 0.5997 - val_f1: 0.5930 - val_precision_measure: 0.5992 - val_recall_measure: 0.5877\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 238s 789us/step - loss: 0.4161 - acc: 0.7208 - f1: 0.7160 - precision_measure: 0.7275 - recall_measure: 0.7050 - val_loss: 0.7697 - val_acc: 0.5393 - val_f1: 0.5305 - val_precision_measure: 0.5384 - val_recall_measure: 0.5237\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 193s 641us/step - loss: 0.4013 - acc: 0.7342 - f1: 0.7285 - precision_measure: 0.7398 - recall_measure: 0.7178 - val_loss: 0.6100 - val_acc: 0.6772 - val_f1: 0.6741 - val_precision_measure: 0.6777 - val_recall_measure: 0.6708\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 222s 735us/step - loss: 0.3652 - acc: 0.7890 - f1: 0.7864 - precision_measure: 0.7949 - recall_measure: 0.7782 - val_loss: 0.8681 - val_acc: 0.7903 - val_f1: 0.7888 - val_precision_measure: 0.7949 - val_recall_measure: 0.7832\n",
      "33762/33762 [==============================] - 15s 437us/step\n",
      "Fitting  42 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 249s 826us/step - loss: 0.7475 - acc: 0.4709 - f1: 0.3903 - precision_measure: 0.5001 - recall_measure: 0.3472 - val_loss: 0.8065 - val_acc: 0.2955 - val_f1: 0.2769 - val_precision_measure: 0.2926 - val_recall_measure: 0.2656\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 266s 881us/step - loss: 0.5139 - acc: 0.5595 - f1: 0.5345 - precision_measure: 0.5613 - recall_measure: 0.5112 - val_loss: 0.7832 - val_acc: 0.5719 - val_f1: 0.5652 - val_precision_measure: 0.5730 - val_recall_measure: 0.5589\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 306s 1ms/step - loss: 0.4543 - acc: 0.7048 - f1: 0.6970 - precision_measure: 0.7127 - recall_measure: 0.6823 - val_loss: 0.7425 - val_acc: 0.6384 - val_f1: 0.6318 - val_precision_measure: 0.6386 - val_recall_measure: 0.6260\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 396s 1ms/step - loss: 0.4103 - acc: 0.7604 - f1: 0.7565 - precision_measure: 0.7675 - recall_measure: 0.7460 - val_loss: 0.7767 - val_acc: 0.6342 - val_f1: 0.6292 - val_precision_measure: 0.6357 - val_recall_measure: 0.6233\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 349s 1ms/step - loss: 0.3969 - acc: 0.7724 - f1: 0.7694 - precision_measure: 0.7803 - recall_measure: 0.7591 - val_loss: 0.5308 - val_acc: 0.8406 - val_f1: 0.8345 - val_precision_measure: 0.8460 - val_recall_measure: 0.8242\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 356s 1ms/step - loss: 0.3686 - acc: 0.7988 - f1: 0.7961 - precision_measure: 0.8055 - recall_measure: 0.7871 - val_loss: 0.8140 - val_acc: 0.5985 - val_f1: 0.5952 - val_precision_measure: 0.5997 - val_recall_measure: 0.5911\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 326s 1ms/step - loss: 0.3489 - acc: 0.8097 - f1: 0.8076 - precision_measure: 0.8155 - recall_measure: 0.8001 - val_loss: 0.6636 - val_acc: 0.6834 - val_f1: 0.6825 - val_precision_measure: 0.6850 - val_recall_measure: 0.6802\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 341s 1ms/step - loss: 0.3387 - acc: 0.8179 - f1: 0.8162 - precision_measure: 0.8230 - recall_measure: 0.8098 - val_loss: 0.5648 - val_acc: 0.7152 - val_f1: 0.7141 - val_precision_measure: 0.7166 - val_recall_measure: 0.7117\n",
      "33762/33762 [==============================] - 17s 509us/step\n",
      "Fitting  43 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 304s 1ms/step - loss: 0.7161 - acc: 0.4838 - f1: 0.4162 - precision_measure: 0.5084 - recall_measure: 0.3744 - val_loss: 0.7590 - val_acc: 0.3348 - val_f1: 0.3208 - val_precision_measure: 0.3344 - val_recall_measure: 0.3107\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 327s 1ms/step - loss: 0.5110 - acc: 0.5582 - f1: 0.5384 - precision_measure: 0.5645 - recall_measure: 0.5158 - val_loss: 0.8085 - val_acc: 0.4429 - val_f1: 0.4337 - val_precision_measure: 0.4414 - val_recall_measure: 0.4273\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 207s 685us/step - loss: 0.4427 - acc: 0.6983 - f1: 0.6905 - precision_measure: 0.7051 - recall_measure: 0.6768 - val_loss: 0.8769 - val_acc: 0.5199 - val_f1: 0.5139 - val_precision_measure: 0.5200 - val_recall_measure: 0.5085\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 201s 667us/step - loss: 0.4020 - acc: 0.7539 - f1: 0.7495 - precision_measure: 0.7599 - recall_measure: 0.7396 - val_loss: 0.5854 - val_acc: 0.7625 - val_f1: 0.7584 - val_precision_measure: 0.7666 - val_recall_measure: 0.7511\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 199s 659us/step - loss: 0.3741 - acc: 0.7861 - f1: 0.7835 - precision_measure: 0.7920 - recall_measure: 0.7754 - val_loss: 0.5960 - val_acc: 0.7232 - val_f1: 0.7185 - val_precision_measure: 0.7257 - val_recall_measure: 0.7119\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 200s 663us/step - loss: 0.3572 - acc: 0.8014 - f1: 0.7996 - precision_measure: 0.8073 - recall_measure: 0.7921 - val_loss: 0.6634 - val_acc: 0.6524 - val_f1: 0.6502 - val_precision_measure: 0.6532 - val_recall_measure: 0.6474\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 202s 670us/step - loss: 0.3408 - acc: 0.8136 - f1: 0.8118 - precision_measure: 0.8185 - recall_measure: 0.8054 - val_loss: 0.4554 - val_acc: 0.8277 - val_f1: 0.8264 - val_precision_measure: 0.8289 - val_recall_measure: 0.8241\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 197s 652us/step - loss: 0.3254 - acc: 0.8242 - f1: 0.8229 - precision_measure: 0.8289 - recall_measure: 0.8170 - val_loss: 0.6155 - val_acc: 0.7537 - val_f1: 0.7446 - val_precision_measure: 0.7589 - val_recall_measure: 0.7321\n",
      "33762/33762 [==============================] - 14s 422us/step\n",
      "Fitting  44 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 221s 732us/step - loss: 0.7498 - acc: 0.4812 - f1: 0.4058 - precision_measure: 0.5153 - recall_measure: 0.3595 - val_loss: 0.8322 - val_acc: 0.2828 - val_f1: 0.2663 - val_precision_measure: 0.2759 - val_recall_measure: 0.2590\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 204s 676us/step - loss: 0.5198 - acc: 0.5213 - f1: 0.4992 - precision_measure: 0.5258 - recall_measure: 0.4761 - val_loss: 0.7532 - val_acc: 0.5077 - val_f1: 0.4965 - val_precision_measure: 0.5083 - val_recall_measure: 0.4865\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 207s 685us/step - loss: 0.4575 - acc: 0.6789 - f1: 0.6689 - precision_measure: 0.6866 - recall_measure: 0.6527 - val_loss: 0.7045 - val_acc: 0.6246 - val_f1: 0.6133 - val_precision_measure: 0.6236 - val_recall_measure: 0.6047\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 209s 694us/step - loss: 0.4032 - acc: 0.7588 - f1: 0.7539 - precision_measure: 0.7663 - recall_measure: 0.7422 - val_loss: 0.6887 - val_acc: 0.6563 - val_f1: 0.6533 - val_precision_measure: 0.6568 - val_recall_measure: 0.6503\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 208s 689us/step - loss: 0.3712 - acc: 0.7957 - f1: 0.7928 - precision_measure: 0.8019 - recall_measure: 0.7840 - val_loss: 0.5944 - val_acc: 0.7138 - val_f1: 0.7097 - val_precision_measure: 0.7157 - val_recall_measure: 0.7043\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 209s 694us/step - loss: 0.3545 - acc: 0.8081 - f1: 0.8060 - precision_measure: 0.8142 - recall_measure: 0.7981 - val_loss: 0.4519 - val_acc: 0.8361 - val_f1: 0.8336 - val_precision_measure: 0.8383 - val_recall_measure: 0.8294\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 187s 618us/step - loss: 0.3357 - acc: 0.8178 - f1: 0.8161 - precision_measure: 0.8236 - recall_measure: 0.8089 - val_loss: 0.6734 - val_acc: 0.6873 - val_f1: 0.6848 - val_precision_measure: 0.6880 - val_recall_measure: 0.6817\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 183s 607us/step - loss: 0.3240 - acc: 0.8279 - f1: 0.8263 - precision_measure: 0.8330 - recall_measure: 0.8199 - val_loss: 0.4845 - val_acc: 0.8076 - val_f1: 0.8070 - val_precision_measure: 0.8085 - val_recall_measure: 0.8055\n",
      "33762/33762 [==============================] - 10s 293us/step\n",
      "Fitting  45 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 329s 1ms/step - loss: 0.7061 - acc: 0.4596 - f1: 0.3899 - precision_measure: 0.4773 - recall_measure: 0.3477 - val_loss: 0.8388 - val_acc: 0.2599 - val_f1: 0.2444 - val_precision_measure: 0.2595 - val_recall_measure: 0.2351\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 226s 748us/step - loss: 0.5195 - acc: 0.4695 - f1: 0.4333 - precision_measure: 0.4648 - recall_measure: 0.4073 - val_loss: 0.7992 - val_acc: 0.4536 - val_f1: 0.4319 - val_precision_measure: 0.4500 - val_recall_measure: 0.4174\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 195s 647us/step - loss: 0.4598 - acc: 0.6578 - f1: 0.6460 - precision_measure: 0.6630 - recall_measure: 0.6303 - val_loss: 0.7079 - val_acc: 0.5889 - val_f1: 0.5787 - val_precision_measure: 0.5879 - val_recall_measure: 0.5708\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 199s 661us/step - loss: 0.4170 - acc: 0.7416 - f1: 0.7360 - precision_measure: 0.7493 - recall_measure: 0.7235 - val_loss: 0.6811 - val_acc: 0.6342 - val_f1: 0.6299 - val_precision_measure: 0.6344 - val_recall_measure: 0.6258\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 196s 649us/step - loss: 0.3926 - acc: 0.7658 - f1: 0.7613 - precision_measure: 0.7727 - recall_measure: 0.7506 - val_loss: 0.5097 - val_acc: 0.7833 - val_f1: 0.7785 - val_precision_measure: 0.7891 - val_recall_measure: 0.7693\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 194s 642us/step - loss: 0.3675 - acc: 0.7929 - f1: 0.7899 - precision_measure: 0.7995 - recall_measure: 0.7806 - val_loss: 0.6179 - val_acc: 0.7197 - val_f1: 0.7176 - val_precision_measure: 0.7234 - val_recall_measure: 0.7125\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 196s 651us/step - loss: 0.3378 - acc: 0.8120 - f1: 0.8102 - precision_measure: 0.8181 - recall_measure: 0.8026 - val_loss: 0.3806 - val_acc: 0.8782 - val_f1: 0.8757 - val_precision_measure: 0.8804 - val_recall_measure: 0.8713\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 195s 646us/step - loss: 0.3342 - acc: 0.8162 - f1: 0.8144 - precision_measure: 0.8222 - recall_measure: 0.8069 - val_loss: 0.3367 - val_acc: 0.8727 - val_f1: 0.8717 - val_precision_measure: 0.8737 - val_recall_measure: 0.8698\n",
      "33762/33762 [==============================] - 12s 362us/step\n",
      "Fitting  46 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 211s 700us/step - loss: 0.6885 - acc: 0.4697 - f1: 0.4062 - precision_measure: 0.4826 - recall_measure: 0.3636 - val_loss: 0.8556 - val_acc: 0.3492 - val_f1: 0.2629 - val_precision_measure: 0.3182 - val_recall_measure: 0.2429\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 207s 688us/step - loss: 0.5039 - acc: 0.5965 - f1: 0.5708 - precision_measure: 0.5981 - recall_measure: 0.5470 - val_loss: 0.8066 - val_acc: 0.6125 - val_f1: 0.5885 - val_precision_measure: 0.6174 - val_recall_measure: 0.5666\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 213s 707us/step - loss: 0.4318 - acc: 0.7216 - f1: 0.7154 - precision_measure: 0.7280 - recall_measure: 0.7036 - val_loss: 0.6567 - val_acc: 0.6385 - val_f1: 0.6326 - val_precision_measure: 0.6392 - val_recall_measure: 0.6267\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 421s 1ms/step - loss: 0.3818 - acc: 0.7784 - f1: 0.7754 - precision_measure: 0.7844 - recall_measure: 0.7667 - val_loss: 0.5035 - val_acc: 0.7548 - val_f1: 0.7535 - val_precision_measure: 0.7573 - val_recall_measure: 0.7500\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 520s 2ms/step - loss: 0.3595 - acc: 0.8004 - f1: 0.7985 - precision_measure: 0.8059 - recall_measure: 0.7915 - val_loss: 0.4254 - val_acc: 0.8452 - val_f1: 0.8444 - val_precision_measure: 0.8474 - val_recall_measure: 0.8416\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 371s 1ms/step - loss: 0.3372 - acc: 0.8151 - f1: 0.8138 - precision_measure: 0.8206 - recall_measure: 0.8072 - val_loss: 0.6077 - val_acc: 0.6614 - val_f1: 0.6584 - val_precision_measure: 0.6626 - val_recall_measure: 0.6546\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 408s 1ms/step - loss: 0.3276 - acc: 0.8191 - f1: 0.8176 - precision_measure: 0.8239 - recall_measure: 0.8115 - val_loss: 0.4494 - val_acc: 0.8074 - val_f1: 0.8055 - val_precision_measure: 0.8090 - val_recall_measure: 0.8022\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 293s 971us/step - loss: 0.3291 - acc: 0.8166 - f1: 0.8149 - precision_measure: 0.8214 - recall_measure: 0.8088 - val_loss: 0.4124 - val_acc: 0.8494 - val_f1: 0.8482 - val_precision_measure: 0.8520 - val_recall_measure: 0.8447\n",
      "33762/33762 [==============================] - 30s 895us/step\n",
      "Fitting  47 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 285s 944us/step - loss: 0.6535 - acc: 0.4993 - f1: 0.4480 - precision_measure: 0.5162 - recall_measure: 0.4089 - val_loss: 0.7920 - val_acc: 0.6711 - val_f1: 0.6410 - val_precision_measure: 0.6889 - val_recall_measure: 0.6090\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 241s 799us/step - loss: 0.4785 - acc: 0.6390 - f1: 0.6241 - precision_measure: 0.6487 - recall_measure: 0.6023 - val_loss: 0.9096 - val_acc: 0.5392 - val_f1: 0.5261 - val_precision_measure: 0.5374 - val_recall_measure: 0.5169\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 242s 802us/step - loss: 0.4038 - acc: 0.7634 - f1: 0.7584 - precision_measure: 0.7720 - recall_measure: 0.7455 - val_loss: 0.7842 - val_acc: 0.5655 - val_f1: 0.5575 - val_precision_measure: 0.5638 - val_recall_measure: 0.5520\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 395s 1ms/step - loss: 0.3654 - acc: 0.7953 - f1: 0.7925 - precision_measure: 0.8022 - recall_measure: 0.7832 - val_loss: 0.5164 - val_acc: 0.7838 - val_f1: 0.7820 - val_precision_measure: 0.7854 - val_recall_measure: 0.7787\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 219s 728us/step - loss: 0.3376 - acc: 0.8156 - f1: 0.8139 - precision_measure: 0.8212 - recall_measure: 0.8069 - val_loss: 0.4749 - val_acc: 0.7840 - val_f1: 0.7831 - val_precision_measure: 0.7855 - val_recall_measure: 0.7808\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 214s 711us/step - loss: 0.3281 - acc: 0.8239 - f1: 0.8224 - precision_measure: 0.8296 - recall_measure: 0.8155 - val_loss: 0.4784 - val_acc: 0.7995 - val_f1: 0.7984 - val_precision_measure: 0.8021 - val_recall_measure: 0.7950\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 207s 686us/step - loss: 0.3159 - acc: 0.8284 - f1: 0.8272 - precision_measure: 0.8336 - recall_measure: 0.8210 - val_loss: 0.4950 - val_acc: 0.8021 - val_f1: 0.8008 - val_precision_measure: 0.8056 - val_recall_measure: 0.7964\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 222s 735us/step - loss: 0.2973 - acc: 0.8380 - f1: 0.8371 - precision_measure: 0.8418 - recall_measure: 0.8325 - val_loss: 0.3739 - val_acc: 0.8564 - val_f1: 0.8558 - val_precision_measure: 0.8578 - val_recall_measure: 0.8540\n",
      "33762/33762 [==============================] - 16s 466us/step\n",
      "Fitting  48 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 302s 1ms/step - loss: 0.6530 - acc: 0.5406 - f1: 0.4850 - precision_measure: 0.5525 - recall_measure: 0.4463 - val_loss: 0.7665 - val_acc: 0.6180 - val_f1: 0.5966 - val_precision_measure: 0.6188 - val_recall_measure: 0.5787\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 275s 911us/step - loss: 0.4464 - acc: 0.7241 - f1: 0.7151 - precision_measure: 0.7324 - recall_measure: 0.6991 - val_loss: 0.5692 - val_acc: 0.7431 - val_f1: 0.7377 - val_precision_measure: 0.7444 - val_recall_measure: 0.7315\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 280s 929us/step - loss: 0.3809 - acc: 0.7920 - f1: 0.7889 - precision_measure: 0.7993 - recall_measure: 0.7789 - val_loss: 0.5787 - val_acc: 0.7232 - val_f1: 0.7181 - val_precision_measure: 0.7235 - val_recall_measure: 0.7132\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 307s 1ms/step - loss: 0.3489 - acc: 0.8112 - f1: 0.8095 - precision_measure: 0.8178 - recall_measure: 0.8015 - val_loss: 0.4751 - val_acc: 0.8083 - val_f1: 0.8064 - val_precision_measure: 0.8107 - val_recall_measure: 0.8023\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 225s 745us/step - loss: 0.3271 - acc: 0.8265 - f1: 0.8254 - precision_measure: 0.8322 - recall_measure: 0.8189 - val_loss: 0.4894 - val_acc: 0.8030 - val_f1: 0.8013 - val_precision_measure: 0.8069 - val_recall_measure: 0.7962\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 211s 701us/step - loss: 0.3154 - acc: 0.8336 - f1: 0.8327 - precision_measure: 0.8385 - recall_measure: 0.8271 - val_loss: 0.6348 - val_acc: 0.6877 - val_f1: 0.6867 - val_precision_measure: 0.6881 - val_recall_measure: 0.6852\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 208s 691us/step - loss: 0.2989 - acc: 0.8424 - f1: 0.8417 - precision_measure: 0.8465 - recall_measure: 0.8370 - val_loss: 0.4491 - val_acc: 0.8125 - val_f1: 0.8107 - val_precision_measure: 0.8152 - val_recall_measure: 0.8065\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 204s 675us/step - loss: 0.2930 - acc: 0.8421 - f1: 0.8411 - precision_measure: 0.8462 - recall_measure: 0.8361 - val_loss: 0.5924 - val_acc: 0.7920 - val_f1: 0.7873 - val_precision_measure: 0.7972 - val_recall_measure: 0.7783\n",
      "33762/33762 [==============================] - 15s 445us/step\n",
      "7\n",
      "0.8655490393539087\n",
      "<keras.callbacks.History object at 0x1307a0d90>\n"
     ]
    }
   ],
   "source": [
    "# Define the dropout grid\n",
    "dropout_grid = [0.1, 0.5, 0.9]\n",
    "l1_grid = [2**-5, 2**-6, 2**-7, 2**-8]\n",
    "l2_grid = [2**-5, 2**-6, 2**-7, 2**-8]\n",
    "tot = len(dropout_grid) * len(l1_grid) * len(l2_grid)\n",
    "\n",
    "# Variables for the best result\n",
    "scores = []\n",
    "best_history = [] # place holder\n",
    "best_ind = 0\n",
    "best_acc = 0\n",
    "\n",
    "# Loop through each combination\n",
    "pos = 0\n",
    "for ii in dropout_grid:\n",
    "    for jj in l1_grid:\n",
    "        for kk in l2_grid:\n",
    "            pos = pos + 1\n",
    "            print(\"Fitting \", pos, \"/\", tot , \" model\")\n",
    "            # define the model\n",
    "            curr_model = define_LSTM_model(ii, jj, kk)\n",
    "            #curr_model.summary()\n",
    "            \n",
    "            # train the model\n",
    "            curr_history = curr_model.fit(training_X, training_y_encoded, epochs = 8, batch_size = 64, \n",
    "                                     validation_data = (val_X, val_y_encoded), class_weight = label_weights, \n",
    "                                     verbose = 1)\n",
    "            curr_acc = st.mean(curr_history.history['val_acc'][5:10])\n",
    "                        \n",
    "            # get prediction report\n",
    "            y_pred = curr_model.predict(val_X, batch_size=64, verbose=1)\n",
    "            y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "            scores.append(classification_report(val_y, y_pred_bool))\n",
    "            \n",
    "            # save the best result\n",
    "            if best_acc < curr_acc:\n",
    "                best_acc = curr_acc\n",
    "                best_ind = pos - 1\n",
    "                best_history = curr_history\n",
    "\n",
    "# Display best best_ind, best_acc, and best_history\n",
    "print(best_ind)\n",
    "print(best_acc)\n",
    "print(best_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-renaissance",
   "metadata": {},
   "source": [
    "The above hyperparamter search for this LSTM returns that index 7 is the best index combination of hyperparameters, returning an accuracy of 0.8655490393539087. The hyperparamters that correspond to this index are found in 'Fitting Model 8 / 48' (results are in log file). They are `dropout_rate` = 0.1, `l1` = 2e-6, `l2` = 2e-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-louisville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 125)               66000     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 125)               15750     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 504       \n",
      "=================================================================\n",
      "Total params: 82,254\n",
      "Trainable params: 82,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/30\n",
      "301655/301655 [==============================] - 397s 1ms/step - loss: 0.6167 - acc: 0.5919 - f1: 0.5563 - precision_measure: 0.6098 - recall_measure: 0.5277 - val_loss: 0.9235 - val_acc: 0.4953 - val_f1: 0.4830 - val_precision_measure: 0.4994 - val_recall_measure: 0.4699\n",
      "Epoch 2/30\n",
      "301655/301655 [==============================] - 232s 770us/step - loss: 0.3959 - acc: 0.7542 - f1: 0.7504 - precision_measure: 0.7625 - recall_measure: 0.7389 - val_loss: 0.6783 - val_acc: 0.6706 - val_f1: 0.6626 - val_precision_measure: 0.6772 - val_recall_measure: 0.6503\n",
      "Epoch 3/30\n",
      "301655/301655 [==============================] - 250s 830us/step - loss: 0.3304 - acc: 0.8086 - f1: 0.8071 - precision_measure: 0.8139 - recall_measure: 0.8006 - val_loss: 0.5139 - val_acc: 0.7897 - val_f1: 0.7888 - val_precision_measure: 0.7923 - val_recall_measure: 0.7856\n",
      "Epoch 4/30\n",
      "301655/301655 [==============================] - 201s 666us/step - loss: 0.2889 - acc: 0.8363 - f1: 0.8356 - precision_measure: 0.8400 - recall_measure: 0.8314 - val_loss: 0.3796 - val_acc: 0.8644 - val_f1: 0.8639 - val_precision_measure: 0.8664 - val_recall_measure: 0.8617\n",
      "Epoch 5/30\n",
      "301655/301655 [==============================] - 201s 668us/step - loss: 0.2593 - acc: 0.8526 - f1: 0.8523 - precision_measure: 0.8550 - recall_measure: 0.8498 - val_loss: 0.4263 - val_acc: 0.8374 - val_f1: 0.8365 - val_precision_measure: 0.8393 - val_recall_measure: 0.8340\n",
      "Epoch 6/30\n",
      "301655/301655 [==============================] - 193s 641us/step - loss: 0.2379 - acc: 0.8647 - f1: 0.8645 - precision_measure: 0.8664 - recall_measure: 0.8627 - val_loss: 0.4288 - val_acc: 0.8376 - val_f1: 0.8372 - val_precision_measure: 0.8385 - val_recall_measure: 0.8359\n",
      "Epoch 7/30\n",
      "301655/301655 [==============================] - 194s 645us/step - loss: 0.2167 - acc: 0.8767 - f1: 0.8765 - precision_measure: 0.8777 - recall_measure: 0.8752 - val_loss: 0.4887 - val_acc: 0.7997 - val_f1: 0.7993 - val_precision_measure: 0.8003 - val_recall_measure: 0.7982\n",
      "Epoch 8/30\n",
      "301655/301655 [==============================] - 205s 680us/step - loss: 0.2031 - acc: 0.8875 - f1: 0.8874 - precision_measure: 0.8884 - recall_measure: 0.8865 - val_loss: 0.4215 - val_acc: 0.8501 - val_f1: 0.8494 - val_precision_measure: 0.8513 - val_recall_measure: 0.8475\n",
      "Epoch 9/30\n",
      "301655/301655 [==============================] - 197s 653us/step - loss: 0.1876 - acc: 0.8984 - f1: 0.8983 - precision_measure: 0.8990 - recall_measure: 0.8976 - val_loss: 0.3595 - val_acc: 0.8752 - val_f1: 0.8748 - val_precision_measure: 0.8762 - val_recall_measure: 0.8735\n",
      "Epoch 10/30\n",
      "301655/301655 [==============================] - 192s 637us/step - loss: 0.1679 - acc: 0.9099 - f1: 0.9099 - precision_measure: 0.9104 - recall_measure: 0.9094 - val_loss: 0.4597 - val_acc: 0.8526 - val_f1: 0.8525 - val_precision_measure: 0.8532 - val_recall_measure: 0.8519\n",
      "Epoch 11/30\n",
      "301655/301655 [==============================] - 200s 662us/step - loss: 0.1612 - acc: 0.9173 - f1: 0.9173 - precision_measure: 0.9177 - recall_measure: 0.9169 - val_loss: 0.3905 - val_acc: 0.8653 - val_f1: 0.8652 - val_precision_measure: 0.8657 - val_recall_measure: 0.8647\n",
      "Epoch 12/30\n",
      "301655/301655 [==============================] - 193s 641us/step - loss: 0.1493 - acc: 0.9268 - f1: 0.9268 - precision_measure: 0.9271 - recall_measure: 0.9265 - val_loss: 0.5124 - val_acc: 0.8364 - val_f1: 0.8362 - val_precision_measure: 0.8365 - val_recall_measure: 0.8359\n",
      "Epoch 13/30\n",
      "219776/301655 [====================>.........] - ETA: 1:18 - loss: 0.1371 - acc: 0.9356 - f1: 0.9356 - precision_measure: 0.9358 - recall_measure: 0.9354"
     ]
    }
   ],
   "source": [
    "# Optimal parameters: dropout_rate = 0.1, l1 = 2e-6, l2 = 2e-8\n",
    "best_model, best_history, best_accuracy, best_f1, best_precision, best_recall = evaluate_model(training_X, \n",
    "                                                                                   training_y_encoded, \n",
    "                                                                                   val_X, val_y_encoded, \n",
    "                                                                                   0.1, 2**-6, 2**-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "legitimate-license",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(best_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fancy-federation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8508263728452106\n"
     ]
    }
   ],
   "source": [
    "curr_acc = st.mean(best_history.history['val_acc'][10:15])\n",
    "print(curr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ordered-dividend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33762/33762 [==============================] - 8s 247us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90     26856\n",
      "           1       0.80      1.00      0.89      1446\n",
      "           2       0.87      1.00      0.93      1602\n",
      "           3       0.48      0.89      0.62      3858\n",
      "\n",
      "    accuracy                           0.86     33762\n",
      "   macro avg       0.78      0.93      0.83     33762\n",
      "weighted avg       0.91      0.86      0.87     33762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get prediction report\n",
    "y_pred = best_model.predict(val_X, batch_size = 64, verbose = 1)\n",
    "y_pred_bool = np.argmax(y_pred, axis = 1)\n",
    "print(classification_report(val_y, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fresh-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = pd.DataFrame({'Y':val_y.flatten(), 'Prediction':y_pred_bool})\n",
    "validation = pd.DataFrame(list(zip(val_y.flatten(), y_pred_bool)), columns = ['Y', 'Prediction'])\n",
    "validation.to_csv('validation_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "comparative-guarantee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9497, 1)\n",
      "37988/37988 [==============================] - 7s 177us/step\n",
      "(9497,)\n",
      "(12269, 1)\n",
      "49076/49076 [==============================] - 9s 184us/step\n",
      "(12269,)\n",
      "(12939, 1)\n",
      "51756/51756 [==============================] - 10s 188us/step\n",
      "(12939,)\n",
      "(11329, 1)\n",
      "45316/45316 [==============================] - 9s 194us/step\n",
      "(11329,)\n"
     ]
    }
   ],
   "source": [
    "# Get predictions using test data\n",
    "test_files = ['TestData/subject_009_01__x.csv', 'TestData/subject_010_01__x.csv', \n",
    "             'TestData/subject_011_01__x.csv', 'TestData/subject_012_01__x.csv']\n",
    "\n",
    "y_files = ['TestData/subject_009_01__y_time.csv', 'TestData/subject_010_01__y_time.csv',\n",
    "          'TestData/subject_011_01__y_time.csv', 'TestData/subject_012_01__y_time.csv']\n",
    "\n",
    "prediction_files = ['subject_009_01__y_prediction.csv', 'subject_010_01__y_prediction.csv',\n",
    "                   'subject_011_01__y_prediction.csv', 'subject_012_01__y_prediction.csv']\n",
    "\n",
    "def generate_test_data(X, time_steps, step):\n",
    "    X_values = []\n",
    "    for i in range(0, len(X) - time_steps, step):\n",
    "        value = X.iloc[i:(i + time_steps)].values\n",
    "        X_values.append(value)\n",
    "    return np.array(X_values)\n",
    "\n",
    "def reduce(y):\n",
    "    y_output = []\n",
    "    for i in range(0, y.shape[0], 4):\n",
    "        item = list(y[i:i + 4])\n",
    "        y_output.append(max(item, key = item.count))\n",
    "    return np.array(y_output)\n",
    "\n",
    "for i in range(len(test_files)):\n",
    "    test_input = pd.read_csv(test_files[i])\n",
    "    test_input = scale_data(test_input, list(test_input.columns.values))\n",
    "    y_frame = pd.read_csv(y_files[i])\n",
    "    print(y_frame.shape)\n",
    "\n",
    "    add_to_frame = y_frame.shape[0] * 4 - test_input.shape[0] + 30\n",
    "    adding_dataframe = pd.DataFrame(test_input.iloc[-add_to_frame:])\n",
    "    test_input = test_input.append(adding_dataframe)\n",
    "    \n",
    "    # Apply window technique\n",
    "    X_test = generate_test_data(test_input, 30, 1)\n",
    "\n",
    "    y_hat_encoded = best_model.predict(X_test, batch_size = 64, verbose = 1)\n",
    "    \n",
    "    y_hat = np.argmax(y_hat_encoded, axis = 1)\n",
    "    \n",
    "    y_actual = reduce(y_hat)\n",
    "    #y_actual = y_actual[np.arange(y_actual.size - 1)]\n",
    "    \n",
    "    print(y_actual.shape)\n",
    "    \n",
    "    y_series = pd.Series(y_actual)\n",
    "    y_series.to_csv(\"C2_predictions/\" + prediction_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "lasting-metro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9497\n"
     ]
    }
   ],
   "source": [
    "x = pd.read_csv('TestData/subject_009_01__y_time.csv')\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fiscal-quantum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12269\n"
     ]
    }
   ],
   "source": [
    "x = pd.read_csv('TestData/subject_010_01__y_time.csv')\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cordless-scene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12939\n"
     ]
    }
   ],
   "source": [
    "x = pd.read_csv('TestData/subject_011_01__y_time.csv')\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "refined-donor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11329\n"
     ]
    }
   ],
   "source": [
    "x = pd.read_csv('TestData/subject_012_01__y_time.csv')\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-loading",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
