{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "confident-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics as st\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, LSTM\n",
    "from tensorflow.python.keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from keras.utils import to_categorical\n",
    "#!{sys.executable} -m pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-purple",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "anonymous-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Based on the training data given, we are able to extract 7 attributes:\n",
    "    1. x accelerometer measurement\n",
    "    2. y accelerometer measurement\n",
    "    3. z accelerometer measurement\n",
    "    4. x gyroscope measurement\n",
    "    5. y gyroscope measurement\n",
    "    6. z gyroscope measurement\n",
    "    7. time stamp for accelerometer and gyroscope measures\n",
    "    \n",
    "    We start by creating a dataframe using the csv files provided for readability.\n",
    "    \n",
    "    @param x_file: contains the xyz accelerometers and xyz gyroscope measures from the lower limb\n",
    "    @param x_time_file: contain the time stamps for the accelerometer and gyroscope measures\n",
    "    @return dataframe of 7 attributes mentioned\n",
    "\"\"\"\n",
    "def create_dataframe_X(x_file, x_time_file):\n",
    "    df1 = pd.read_csv(x_file, sep = ',', names = ['X_acc', 'Y_acc', 'Z_acc', 'X_gyr', 'Y_gyr', 'Z_gyr'])\n",
    "    df1 = scale_data(df1, ['X_acc', 'Y_acc', 'Z_acc', 'X_gyr', 'Y_gyr', 'Z_gyr'])\n",
    "    df2 = pd.read_csv(x_time_file, names = ['Time stamp'])\n",
    "    frames = [df1, df2]\n",
    "    result = pd.concat(frames, axis = 1)\n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "    Scale the values of X to make it robust to outliers.\n",
    "    \n",
    "    @param df: input dataframe\n",
    "    @param columns: columns to scale\n",
    "    @return scaled dataframe\n",
    "\"\"\"\n",
    "def scale_data(df, columns):\n",
    "    scaler = RobustScaler()\n",
    "    scaler = scaler.fit(df[columns])\n",
    "    df.loc[:, columns] = scaler.transform(df[columns])\n",
    "    return df\n",
    "    \n",
    "\"\"\"\n",
    "    We have both the labels and the time stamps for the labels. We create a dataframe from these for\n",
    "    readability.\n",
    "    \n",
    "    @param y_file: contain the labels: \n",
    "        (0) indicates standing or walking in solid ground, \n",
    "        (1) indicates going down the stairs, \n",
    "        (2) indicates going up the stairs, and \n",
    "        (3) indicates walking on grass\n",
    "    @param y_time_file: contain the time stamps for the labels\n",
    "    @return dataframe of labels and time stamps\n",
    "\"\"\" \n",
    "def create_dataframe_Y(y_file, y_time_file):\n",
    "    df1 = pd.read_csv(y_file, names = ['Label'])\n",
    "    df2 = pd.read_csv(y_time_file, names = ['Time stamp'])\n",
    "    frames = [df1, df2]\n",
    "    result = pd.concat(frames, axis = 1)\n",
    "    return result\n",
    "    \n",
    "\"\"\"\n",
    "    We take the outputs of create_dataframe_X and create_dataframe_Y. In order to combine both of these\n",
    "    dataframes, we need look at the time intervals present for when the labels were assigned. We down-sample\n",
    "    the X to the shape of the y.\n",
    "    \n",
    "    @param x_frame: dataframe from create_dataframe_X\n",
    "    @param y_frame: dataframe from create_dataframe_Y\n",
    "    @return dataframe with 9 columns (8 attributes and 1 label)\n",
    "\"\"\"\n",
    "def combine_frames(x_frame, y_frame):\n",
    "    # Change each dataframe column to a list for iterations\n",
    "    time_stamp_y = y_frame['Time stamp'].tolist()\n",
    "    time_stamp_x = x_frame['Time stamp'].tolist()\n",
    "    \n",
    "    x_range = [] # Empty list to append data points to\n",
    "    x_random_row = 0 # Initializing variable to hold randomly selected row instance\n",
    "    refs = []\n",
    "    count = 0\n",
    "    for i in range(0, len(time_stamp_y)):\n",
    "        while (time_stamp_x[count] <= time_stamp_y[i]) and (count <= len(time_stamp_x)):\n",
    "            x_range.append(time_stamp_x.index(time_stamp_x[count]))\n",
    "            count += 1\n",
    "        x_random_row = random.choice(x_range) # Pick a random value\n",
    "        refs.append(x_random_row) # Keep record of selected rows\n",
    "        x_range.clear() # Clear the cache\n",
    "        continue\n",
    "    \n",
    "    # Create a new dataframe based on the refs collected - should be roughly the same length as the y_frame\n",
    "    entries = []\n",
    "    for item in refs:\n",
    "        entry = x_frame.iloc[item]\n",
    "        entries.append(entry)\n",
    "    \n",
    "    found_df = pd.concat(entries, axis = 1)\n",
    "    found_df = found_df.transpose()\n",
    "    \n",
    "    # Combine found_df with y_frame for downsampling\n",
    "    found_df = found_df.reset_index()\n",
    "    found_df = found_df.drop(['index'], axis = 1)\n",
    "    found_df = found_df.drop(['Time stamp'], axis = 1)\n",
    "    combined_frame = pd.concat([found_df, y_frame], axis = 1)\n",
    "    return combined_frame\n",
    "\n",
    "\"\"\"\n",
    "    Takes in the sequential X and y and creates windows of time-series data.\n",
    "    \n",
    "    @param X: input data\n",
    "    @param y: label data\n",
    "    @param time_steps: determines size of window\n",
    "    @param step: incremental value that window will slide over\n",
    "    @return time series of X and y data\n",
    "\"\"\"\n",
    "def mode_labels(X, y, time_steps, step):\n",
    "    X_values = []\n",
    "    y_values = []\n",
    "    for i in range(0, len(X) - time_steps, step):\n",
    "        value = X.iloc[i:(i + time_steps)].values\n",
    "        labels = y.iloc[i: (i + time_steps)]\n",
    "        X_values.append(value)\n",
    "        y_values.append(stats.mode(labels)[0][0])\n",
    "    return np.array(X_values), np.array(y_values).reshape(-1, 1)\n",
    "\n",
    "\"\"\"\n",
    "    Generating data frames from training data.\n",
    "    \n",
    "    @param X_file: list of input X files\n",
    "    @param X_t_file: list of input X_time files\n",
    "    @param y_file: list of input y files\n",
    "    @param y_t file: list of y_time files\n",
    "    @return stacked window of instances across all training files, stack window of labels across all label files\n",
    "\"\"\"\n",
    "def generate_data(X_file, X_t_file, y_file, y_t_file):\n",
    "    all_X = []\n",
    "    all_y = []\n",
    "    for item_X, item_X_t, item_y, item_y_t in zip(X_file, X_t_file, y_file, y_t_file):\n",
    "        df_x = create_dataframe_X(item_X, item_X_t)\n",
    "        df_y = create_dataframe_Y(item_y, item_y_t)\n",
    "        combined_frame = combine_frames(df_x, df_y)\n",
    "        X_temp = combined_frame[['X_acc', 'Y_acc', 'Z_acc', 'X_gyr', 'Y_gyr', 'Z_gyr']]\n",
    "        y_temp = combined_frame['Label']\n",
    "        X, y = mode_labels(X_temp, y_temp, 30, 1)\n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "    return np.concatenate(all_X), np.concatenate(all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opposed-moment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301655, 30, 6) (301655, 1)\n",
      "(33762, 30, 6) (33762, 1)\n"
     ]
    }
   ],
   "source": [
    "# List of training X_files\n",
    "X_files = ['TrainingData/subject_001_01__x.csv', 'TrainingData/subject_001_02__x.csv', \n",
    "           'TrainingData/subject_001_03__x.csv', 'TrainingData/subject_001_04__x.csv',\n",
    "           'TrainingData/subject_001_05__x.csv', 'TrainingData/subject_001_06__x.csv',\n",
    "           'TrainingData/subject_001_07__x.csv', 'TrainingData/subject_001_08__x.csv',\n",
    "           'TrainingData/subject_002_01__x.csv', 'TrainingData/subject_002_02__x.csv',\n",
    "           'TrainingData/subject_002_03__x.csv', 'TrainingData/subject_001_04__x.csv',\n",
    "           'TrainingData/subject_002_05__x.csv', 'TrainingData/subject_003_01__x.csv',\n",
    "           'TrainingData/subject_005_01__x.csv', 'TrainingData/subject_005_02__x.csv',\n",
    "           'TrainingData/subject_005_03__x.csv', 'TrainingData/subject_006_01__x.csv',\n",
    "           'TrainingData/subject_006_02__x.csv', 'TrainingData/subject_006_03__x.csv',\n",
    "           'TrainingData/subject_007_01__x.csv', 'TrainingData/subject_007_02__x.csv',\n",
    "           'TrainingData/subject_007_03__x.csv', 'TrainingData/subject_007_04__x.csv',\n",
    "           'TrainingData/subject_008_01__x.csv']\n",
    "\n",
    "# List of training X_t_files\n",
    "X_t_files = ['TrainingData/subject_001_01__x_time.csv', 'TrainingData/subject_001_02__x_time.csv', \n",
    "             'TrainingData/subject_001_03__x_time.csv', 'TrainingData/subject_001_04__x_time.csv',\n",
    "             'TrainingData/subject_001_05__x_time.csv', 'TrainingData/subject_001_06__x_time.csv',\n",
    "             'TrainingData/subject_001_07__x_time.csv', 'TrainingData/subject_001_08__x_time.csv',\n",
    "             'TrainingData/subject_002_01__x_time.csv', 'TrainingData/subject_002_02__x_time.csv',\n",
    "             'TrainingData/subject_002_03__x_time.csv', 'TrainingData/subject_001_04__x_time.csv',\n",
    "             'TrainingData/subject_002_05__x_time.csv', 'TrainingData/subject_003_01__x_time.csv',\n",
    "             'TrainingData/subject_005_01__x_time.csv', 'TrainingData/subject_005_02__x_time.csv',\n",
    "             'TrainingData/subject_005_03__x_time.csv', 'TrainingData/subject_006_01__x_time.csv',\n",
    "             'TrainingData/subject_006_02__x_time.csv', 'TrainingData/subject_006_03__x_time.csv',\n",
    "             'TrainingData/subject_007_01__x_time.csv', 'TrainingData/subject_007_02__x_time.csv',\n",
    "             'TrainingData/subject_007_03__x_time.csv', 'TrainingData/subject_007_04__x_time.csv',\n",
    "             'TrainingData/subject_008_01__x_time.csv']\n",
    "\n",
    "# List of training y_files\n",
    "y_files = ['TrainingData/subject_001_01__y.csv', 'TrainingData/subject_001_02__y.csv', \n",
    "           'TrainingData/subject_001_03__y.csv', 'TrainingData/subject_001_04__y.csv',\n",
    "           'TrainingData/subject_001_05__y.csv', 'TrainingData/subject_001_06__y.csv',\n",
    "           'TrainingData/subject_001_07__y.csv', 'TrainingData/subject_001_08__y.csv',\n",
    "           'TrainingData/subject_002_01__y.csv', 'TrainingData/subject_002_02__y.csv',\n",
    "           'TrainingData/subject_002_03__y.csv', 'TrainingData/subject_001_04__y.csv',\n",
    "           'TrainingData/subject_002_05__y.csv', 'TrainingData/subject_003_01__y.csv',\n",
    "           'TrainingData/subject_005_01__y.csv', 'TrainingData/subject_005_02__y.csv',\n",
    "           'TrainingData/subject_005_03__y.csv', 'TrainingData/subject_006_01__y.csv',\n",
    "           'TrainingData/subject_006_02__y.csv', 'TrainingData/subject_006_03__y.csv',\n",
    "           'TrainingData/subject_007_01__y.csv', 'TrainingData/subject_007_02__y.csv',\n",
    "           'TrainingData/subject_007_03__y.csv', 'TrainingData/subject_007_04__y.csv',\n",
    "           'TrainingData/subject_008_01__y.csv']\n",
    "\n",
    "# List of training y_t_files\n",
    "y_t_files = ['TrainingData/subject_001_01__y_time.csv', 'TrainingData/subject_001_02__y_time.csv', \n",
    "             'TrainingData/subject_001_03__y_time.csv', 'TrainingData/subject_001_04__y_time.csv',\n",
    "             'TrainingData/subject_001_05__y_time.csv', 'TrainingData/subject_001_06__y_time.csv',\n",
    "             'TrainingData/subject_001_07__y_time.csv', 'TrainingData/subject_001_08__y_time.csv',\n",
    "             'TrainingData/subject_002_01__y_time.csv', 'TrainingData/subject_002_02__y_time.csv',\n",
    "             'TrainingData/subject_002_03__y_time.csv', 'TrainingData/subject_001_04__y_time.csv',\n",
    "             'TrainingData/subject_002_05__y_time.csv', 'TrainingData/subject_003_01__y_time.csv',\n",
    "             'TrainingData/subject_005_01__y_time.csv', 'TrainingData/subject_005_02__y_time.csv',\n",
    "             'TrainingData/subject_005_03__y_time.csv', 'TrainingData/subject_006_01__y_time.csv',\n",
    "             'TrainingData/subject_006_02__y_time.csv', 'TrainingData/subject_006_03__y_time.csv',\n",
    "             'TrainingData/subject_007_01__y_time.csv', 'TrainingData/subject_007_02__y_time.csv',\n",
    "             'TrainingData/subject_007_03__y_time.csv', 'TrainingData/subject_007_04__y_time.csv',\n",
    "             'TrainingData/subject_008_01__y_time.csv']\n",
    "\n",
    "# Use some files to create validation set\n",
    "val_X = ['TrainingData/subject_003_02__x.csv', 'TrainingData/subject_003_03__x.csv',\n",
    "         'TrainingData/subject_004_01__x.csv', 'TrainingData/subject_004_02__x.csv',]\n",
    "val_X_t = ['TrainingData/subject_003_02__x_time.csv', 'TrainingData/subject_003_03__x_time.csv',\n",
    "           'TrainingData/subject_004_01__x_time.csv', 'TrainingData/subject_004_02__x_time.csv',]\n",
    "val_y = ['TrainingData/subject_003_02__y.csv', 'TrainingData/subject_003_03__y.csv',\n",
    "         'TrainingData/subject_004_01__y.csv', 'TrainingData/subject_004_02__y.csv',]\n",
    "val_y_t = ['TrainingData/subject_003_02__y_time.csv', 'TrainingData/subject_003_03__y_time.csv',\n",
    "           'TrainingData/subject_004_01__y_time.csv', 'TrainingData/subject_004_02__y_time.csv',]\n",
    "\n",
    "# TODO: Create the test set\n",
    "#test_X = ['TestData/subject_009_01__x.csv', 'TestData/subject_010_01__x.csv',\n",
    "#          'TestData/subject_011_01__x.csv', 'TestData/subject_012_01__x.csv']\n",
    "#test_X_t = ['TestData/subject_009_01__x_time.csv', 'TestData/subject_010_01__x_time.csv',\n",
    "#           'TestData/subject_011_01__x_time.csv', 'TestData/subject_012_01__x_time.csv']\n",
    "\n",
    "training_X, training_y = generate_data(X_files, X_t_files, y_files, y_t_files)\n",
    "val_X, val_y = generate_data(val_X, val_X_t, val_y, val_y_t)\n",
    "print(training_X.shape, training_y.shape)\n",
    "print(val_X.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "legislative-combination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33593218 5.81133929 4.44263623 1.59734284]\n",
      "{0: 0.3359321754546953, 1: 5.811339292594591, 2: 4.442636229749632, 3: 1.5973428365669744}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1 2 3], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "label_weights = class_weight.compute_class_weight('balanced', np.unique(training_y), training_y.ravel())\n",
    "print(label_weights)\n",
    "label_weights = {i:label_weights[i] for i in range(len(label_weights))} # Create dictionary\n",
    "print(label_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "relative-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
    "encoder = encoder.fit(training_y)\n",
    "training_y_encoded = encoder.transform(training_y)\n",
    "val_y_encoded = encoder.transform(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mobile-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_measure(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_measure(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    precision = precision_measure(y_true, y_pred)\n",
    "    recall = recall_measure(y_true, y_pred)\n",
    "    return 2 * ((precision * recall)/(precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "annual-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps, n_features, n_outputs = training_X.shape[1], training_X.shape[2], training_y_encoded.shape[1]\n",
    "\n",
    "def define_LSTM_model(dropout_rate, l1_value, l2_value):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = 125, kernel_regularizer = regularizers.l1_l2(l1=l1_value, l2=l2_value),\n",
    "                   input_shape = (n_timesteps, n_features)))\n",
    "    model.add(Dropout(rate = dropout_rate))\n",
    "    model.add(Dense(units = 125, activation = 'relu'))\n",
    "    model.add(Dense(units = n_outputs, activation = 'softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', \n",
    "                  metrics = ['accuracy', f1, precision_measure, recall_measure])\n",
    "    return model\n",
    "    \n",
    "def evaluate_model(training_X, training_y_encoded, val_X, val_y_encoded, dropout_rate, l1_value, l2_value):\n",
    "    verbose, epochs, batch_size = 1, 15, 64\n",
    "    model = define_LSTM_model(dropout_rate, l1_value, l2_value)\n",
    "    model.summary()\n",
    "    # Fit network\n",
    "    history = model.fit(training_X, training_y_encoded, epochs = epochs, batch_size = batch_size, \n",
    "              validation_data = (val_X, val_y_encoded), class_weight = label_weights, verbose = verbose)\n",
    "    # Evaluate model\n",
    "    loss, accuracy, f1, precision, recall = model.evaluate(val_X, val_y_encoded, batch_size = batch_size, verbose = verbose)\n",
    "    return history, accuracy, f1, precision, recall\n",
    "\n",
    "# Defining a function for plotting training and validation learning curves\n",
    "def plot_history(history):\n",
    "\t# Plot loss\n",
    "    plt.title('Loss')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_loss'], color='red', label='test')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.title('Accuracy')\n",
    "    plt.plot(history.history['acc'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_acc'], color='red', label='test')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot F1\n",
    "    plt.title('F1-Score')\n",
    "    plt.plot(history.history['f1'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_f1'], color='red', label='test')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot precision\n",
    "    plt.title('Precision')\n",
    "    plt.plot(history.history['precision_measure'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_precision_measure'], color='red', label='test')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot recall\n",
    "    plt.title('Recall')\n",
    "    plt.plot(history.history['recall_measure'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_recall_measure'], color='red', label='test')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "optical-chemical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting  1 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 310s 1ms/step - loss: 0.7947 - acc: 0.5508 - f1: 0.4722 - precision_measure: 0.5823 - recall_measure: 0.4294 - val_loss: 0.8487 - val_acc: 0.5053 - val_f1: 0.4855 - val_precision_measure: 0.5074 - val_recall_measure: 0.4686\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 205s 680us/step - loss: 0.4590 - acc: 0.7079 - f1: 0.7024 - precision_measure: 0.7151 - recall_measure: 0.6903 - val_loss: 0.9917 - val_acc: 0.5042 - val_f1: 0.4989 - val_precision_measure: 0.5046 - val_recall_measure: 0.4938\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 203s 674us/step - loss: 0.3812 - acc: 0.7785 - f1: 0.7764 - precision_measure: 0.7840 - recall_measure: 0.7692 - val_loss: 0.7051 - val_acc: 0.7158 - val_f1: 0.7134 - val_precision_measure: 0.7201 - val_recall_measure: 0.7073\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 187s 620us/step - loss: 0.3316 - acc: 0.8185 - f1: 0.8176 - precision_measure: 0.8224 - recall_measure: 0.8128 - val_loss: 0.4614 - val_acc: 0.8180 - val_f1: 0.8177 - val_precision_measure: 0.8190 - val_recall_measure: 0.8164\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 197s 653us/step - loss: 0.2951 - acc: 0.8391 - f1: 0.8386 - precision_measure: 0.8414 - recall_measure: 0.8358 - val_loss: 0.4891 - val_acc: 0.8150 - val_f1: 0.8143 - val_precision_measure: 0.8162 - val_recall_measure: 0.8125\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 196s 649us/step - loss: 0.2744 - acc: 0.8517 - f1: 0.8514 - precision_measure: 0.8537 - recall_measure: 0.8491 - val_loss: 0.7023 - val_acc: 0.7045 - val_f1: 0.7034 - val_precision_measure: 0.7049 - val_recall_measure: 0.7019\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 197s 653us/step - loss: 0.2572 - acc: 0.8631 - f1: 0.8629 - precision_measure: 0.8647 - recall_measure: 0.8612 - val_loss: 0.4104 - val_acc: 0.8564 - val_f1: 0.8557 - val_precision_measure: 0.8567 - val_recall_measure: 0.8547\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.2420 - acc: 0.8719 - f1: 0.8717 - precision_measure: 0.8732 - recall_measure: 0.8703 - val_loss: 0.4160 - val_acc: 0.8549 - val_f1: 0.8548 - val_precision_measure: 0.8556 - val_recall_measure: 0.8540\n",
      "33762/33762 [==============================] - 7s 206us/step\n",
      "Fitting  2 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 225s 746us/step - loss: 0.7072 - acc: 0.5856 - f1: 0.5225 - precision_measure: 0.5997 - recall_measure: 0.4911 - val_loss: 0.6426 - val_acc: 0.6875 - val_f1: 0.6829 - val_precision_measure: 0.6901 - val_recall_measure: 0.6766\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 196s 651us/step - loss: 0.4395 - acc: 0.7176 - f1: 0.7138 - precision_measure: 0.7242 - recall_measure: 0.7038 - val_loss: 0.8535 - val_acc: 0.5804 - val_f1: 0.5677 - val_precision_measure: 0.5816 - val_recall_measure: 0.5560\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 197s 653us/step - loss: 0.3785 - acc: 0.7761 - f1: 0.7743 - precision_measure: 0.7815 - recall_measure: 0.7674 - val_loss: 0.8438 - val_acc: 0.5723 - val_f1: 0.5688 - val_precision_measure: 0.5726 - val_recall_measure: 0.5653\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 201s 666us/step - loss: 0.3338 - acc: 0.8074 - f1: 0.8067 - precision_measure: 0.8112 - recall_measure: 0.8023 - val_loss: 0.4895 - val_acc: 0.8215 - val_f1: 0.8203 - val_precision_measure: 0.8240 - val_recall_measure: 0.8168\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 197s 654us/step - loss: 0.3003 - acc: 0.8346 - f1: 0.8342 - precision_measure: 0.8376 - recall_measure: 0.8308 - val_loss: 0.4553 - val_acc: 0.8432 - val_f1: 0.8415 - val_precision_measure: 0.8446 - val_recall_measure: 0.8385\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 196s 650us/step - loss: 0.2740 - acc: 0.8496 - f1: 0.8494 - precision_measure: 0.8519 - recall_measure: 0.8470 - val_loss: 0.7482 - val_acc: 0.6999 - val_f1: 0.6991 - val_precision_measure: 0.7012 - val_recall_measure: 0.6971\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 234s 777us/step - loss: 0.2572 - acc: 0.8623 - f1: 0.8621 - precision_measure: 0.8641 - recall_measure: 0.8602 - val_loss: 0.4972 - val_acc: 0.8133 - val_f1: 0.8125 - val_precision_measure: 0.8143 - val_recall_measure: 0.8108\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 283s 937us/step - loss: 0.2342 - acc: 0.8759 - f1: 0.8760 - precision_measure: 0.8773 - recall_measure: 0.8747 - val_loss: 0.4609 - val_acc: 0.8369 - val_f1: 0.8364 - val_precision_measure: 0.8382 - val_recall_measure: 0.8348\n",
      "33762/33762 [==============================] - 7s 214us/step\n",
      "Fitting  3 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 231s 766us/step - loss: 0.7348 - acc: 0.5559 - f1: 0.4904 - precision_measure: 0.5817 - recall_measure: 0.4544 - val_loss: 0.8335 - val_acc: 0.5097 - val_f1: 0.5034 - val_precision_measure: 0.5103 - val_recall_measure: 0.4974\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 223s 739us/step - loss: 0.4639 - acc: 0.6493 - f1: 0.6431 - precision_measure: 0.6548 - recall_measure: 0.6320 - val_loss: 0.8544 - val_acc: 0.5386 - val_f1: 0.5305 - val_precision_measure: 0.5404 - val_recall_measure: 0.5219\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 208s 691us/step - loss: 0.4186 - acc: 0.7096 - f1: 0.7058 - precision_measure: 0.7148 - recall_measure: 0.6972 - val_loss: 0.6681 - val_acc: 0.6905 - val_f1: 0.6887 - val_precision_measure: 0.6927 - val_recall_measure: 0.6850\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 207s 686us/step - loss: 0.3662 - acc: 0.7768 - f1: 0.7751 - precision_measure: 0.7810 - recall_measure: 0.7694 - val_loss: 0.5470 - val_acc: 0.7772 - val_f1: 0.7742 - val_precision_measure: 0.7792 - val_recall_measure: 0.7696\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 198s 656us/step - loss: 0.3232 - acc: 0.8165 - f1: 0.8156 - precision_measure: 0.8199 - recall_measure: 0.8115 - val_loss: 0.4814 - val_acc: 0.8286 - val_f1: 0.8276 - val_precision_measure: 0.8312 - val_recall_measure: 0.8242\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 243s 807us/step - loss: 0.2958 - acc: 0.8367 - f1: 0.8361 - precision_measure: 0.8394 - recall_measure: 0.8328 - val_loss: 0.5085 - val_acc: 0.8013 - val_f1: 0.7996 - val_precision_measure: 0.8041 - val_recall_measure: 0.7955\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 204s 675us/step - loss: 0.2756 - acc: 0.8500 - f1: 0.8496 - precision_measure: 0.8519 - recall_measure: 0.8474 - val_loss: 0.4733 - val_acc: 0.8363 - val_f1: 0.8346 - val_precision_measure: 0.8379 - val_recall_measure: 0.8314\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 205s 680us/step - loss: 0.2592 - acc: 0.8596 - f1: 0.8594 - precision_measure: 0.8611 - recall_measure: 0.8578 - val_loss: 0.5783 - val_acc: 0.7806 - val_f1: 0.7799 - val_precision_measure: 0.7815 - val_recall_measure: 0.7782\n",
      "33762/33762 [==============================] - 7s 216us/step\n",
      "Fitting  4 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 203s 674us/step - loss: 0.7483 - acc: 0.5383 - f1: 0.4717 - precision_measure: 0.5620 - recall_measure: 0.4357 - val_loss: 0.9708 - val_acc: 0.3608 - val_f1: 0.3498 - val_precision_measure: 0.3632 - val_recall_measure: 0.3390\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 196s 650us/step - loss: 0.4705 - acc: 0.6510 - f1: 0.6448 - precision_measure: 0.6595 - recall_measure: 0.6311 - val_loss: 0.9347 - val_acc: 0.4164 - val_f1: 0.4151 - val_precision_measure: 0.4181 - val_recall_measure: 0.4124\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 208s 689us/step - loss: 0.3862 - acc: 0.7650 - f1: 0.7629 - precision_measure: 0.7711 - recall_measure: 0.7550 - val_loss: 0.5144 - val_acc: 0.8040 - val_f1: 0.8025 - val_precision_measure: 0.8072 - val_recall_measure: 0.7983\n",
      "Epoch 4/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 185s 614us/step - loss: 0.3354 - acc: 0.8140 - f1: 0.8129 - precision_measure: 0.8188 - recall_measure: 0.8072 - val_loss: 0.5623 - val_acc: 0.7681 - val_f1: 0.7674 - val_precision_measure: 0.7696 - val_recall_measure: 0.7654\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 186s 618us/step - loss: 0.3014 - acc: 0.8364 - f1: 0.8359 - precision_measure: 0.8398 - recall_measure: 0.8320 - val_loss: 0.3944 - val_acc: 0.8846 - val_f1: 0.8833 - val_precision_measure: 0.8864 - val_recall_measure: 0.8804\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 188s 623us/step - loss: 0.2718 - acc: 0.8556 - f1: 0.8552 - precision_measure: 0.8578 - recall_measure: 0.8528 - val_loss: 0.5374 - val_acc: 0.7941 - val_f1: 0.7936 - val_precision_measure: 0.7951 - val_recall_measure: 0.7923\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 191s 633us/step - loss: 0.2488 - acc: 0.8698 - f1: 0.8697 - precision_measure: 0.8715 - recall_measure: 0.8680 - val_loss: 0.4683 - val_acc: 0.8460 - val_f1: 0.8459 - val_precision_measure: 0.8465 - val_recall_measure: 0.8453\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 195s 647us/step - loss: 0.2292 - acc: 0.8833 - f1: 0.8832 - precision_measure: 0.8845 - recall_measure: 0.8820 - val_loss: 0.3601 - val_acc: 0.8934 - val_f1: 0.8930 - val_precision_measure: 0.8947 - val_recall_measure: 0.8914\n",
      "33762/33762 [==============================] - 6s 190us/step\n",
      "Fitting  5 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 199s 659us/step - loss: 0.6567 - acc: 0.5739 - f1: 0.5259 - precision_measure: 0.5943 - recall_measure: 0.4953 - val_loss: 0.7781 - val_acc: 0.6219 - val_f1: 0.6120 - val_precision_measure: 0.6253 - val_recall_measure: 0.6006\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.4089 - acc: 0.7464 - f1: 0.7423 - precision_measure: 0.7531 - recall_measure: 0.7321 - val_loss: 0.6919 - val_acc: 0.7011 - val_f1: 0.6979 - val_precision_measure: 0.7045 - val_recall_measure: 0.6920\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 202s 671us/step - loss: 0.3552 - acc: 0.7945 - f1: 0.7927 - precision_measure: 0.7999 - recall_measure: 0.7857 - val_loss: 0.7686 - val_acc: 0.6386 - val_f1: 0.6337 - val_precision_measure: 0.6412 - val_recall_measure: 0.6271\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 189s 628us/step - loss: 0.3207 - acc: 0.8201 - f1: 0.8191 - precision_measure: 0.8241 - recall_measure: 0.8142 - val_loss: 0.5990 - val_acc: 0.7945 - val_f1: 0.7929 - val_precision_measure: 0.7979 - val_recall_measure: 0.7883\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 190s 630us/step - loss: 0.2891 - acc: 0.8389 - f1: 0.8383 - precision_measure: 0.8420 - recall_measure: 0.8347 - val_loss: 0.4827 - val_acc: 0.8043 - val_f1: 0.8034 - val_precision_measure: 0.8064 - val_recall_measure: 0.8006\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 192s 637us/step - loss: 0.2624 - acc: 0.8556 - f1: 0.8553 - precision_measure: 0.8578 - recall_measure: 0.8529 - val_loss: 0.4191 - val_acc: 0.8654 - val_f1: 0.8634 - val_precision_measure: 0.8666 - val_recall_measure: 0.8605\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 190s 629us/step - loss: 0.2473 - acc: 0.8638 - f1: 0.8637 - precision_measure: 0.8657 - recall_measure: 0.8617 - val_loss: 0.4594 - val_acc: 0.8383 - val_f1: 0.8374 - val_precision_measure: 0.8400 - val_recall_measure: 0.8350\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.2266 - acc: 0.8764 - f1: 0.8763 - precision_measure: 0.8776 - recall_measure: 0.8750 - val_loss: 0.7031 - val_acc: 0.7361 - val_f1: 0.7359 - val_precision_measure: 0.7374 - val_recall_measure: 0.7344\n",
      "33762/33762 [==============================] - 7s 202us/step\n",
      "Fitting  6 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 198s 656us/step - loss: 0.6640 - acc: 0.5976 - f1: 0.5410 - precision_measure: 0.6151 - recall_measure: 0.5098 - val_loss: 0.9544 - val_acc: 0.5076 - val_f1: 0.5011 - val_precision_measure: 0.5080 - val_recall_measure: 0.4951\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 196s 651us/step - loss: 0.4105 - acc: 0.7369 - f1: 0.7332 - precision_measure: 0.7429 - recall_measure: 0.7240 - val_loss: 1.0905 - val_acc: 0.5202 - val_f1: 0.5087 - val_precision_measure: 0.5213 - val_recall_measure: 0.4983\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 197s 652us/step - loss: 0.3491 - acc: 0.7900 - f1: 0.7888 - precision_measure: 0.7947 - recall_measure: 0.7830 - val_loss: 0.6643 - val_acc: 0.7095 - val_f1: 0.7079 - val_precision_measure: 0.7113 - val_recall_measure: 0.7047\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 199s 661us/step - loss: 0.3097 - acc: 0.8224 - f1: 0.8216 - precision_measure: 0.8255 - recall_measure: 0.8179 - val_loss: 0.5005 - val_acc: 0.8136 - val_f1: 0.8114 - val_precision_measure: 0.8175 - val_recall_measure: 0.8058\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 203s 672us/step - loss: 0.2817 - acc: 0.8407 - f1: 0.8403 - precision_measure: 0.8432 - recall_measure: 0.8376 - val_loss: 0.5901 - val_acc: 0.7433 - val_f1: 0.7414 - val_precision_measure: 0.7442 - val_recall_measure: 0.7388\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 199s 659us/step - loss: 0.2596 - acc: 0.8577 - f1: 0.8575 - precision_measure: 0.8597 - recall_measure: 0.8553 - val_loss: 0.6703 - val_acc: 0.7288 - val_f1: 0.7260 - val_precision_measure: 0.7307 - val_recall_measure: 0.7217\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 204s 678us/step - loss: 0.2407 - acc: 0.8687 - f1: 0.8685 - precision_measure: 0.8702 - recall_measure: 0.8669 - val_loss: 0.5445 - val_acc: 0.7821 - val_f1: 0.7817 - val_precision_measure: 0.7828 - val_recall_measure: 0.7806\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 200s 661us/step - loss: 0.2252 - acc: 0.8784 - f1: 0.8783 - precision_measure: 0.8795 - recall_measure: 0.8770 - val_loss: 0.5144 - val_acc: 0.8031 - val_f1: 0.8014 - val_precision_measure: 0.8047 - val_recall_measure: 0.7982\n",
      "33762/33762 [==============================] - 7s 194us/step\n",
      "Fitting  7 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 201s 666us/step - loss: 0.6124 - acc: 0.6075 - f1: 0.5649 - precision_measure: 0.6201 - recall_measure: 0.5388 - val_loss: 0.8679 - val_acc: 0.4882 - val_f1: 0.4757 - val_precision_measure: 0.4886 - val_recall_measure: 0.4650\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 199s 659us/step - loss: 0.3883 - acc: 0.7635 - f1: 0.7607 - precision_measure: 0.7696 - recall_measure: 0.7522 - val_loss: 0.4268 - val_acc: 0.8784 - val_f1: 0.8759 - val_precision_measure: 0.8811 - val_recall_measure: 0.8711\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 210s 696us/step - loss: 0.3299 - acc: 0.8119 - f1: 0.8107 - precision_measure: 0.8160 - recall_measure: 0.8055 - val_loss: 0.6338 - val_acc: 0.7236 - val_f1: 0.7206 - val_precision_measure: 0.7261 - val_recall_measure: 0.7157\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 201s 668us/step - loss: 0.2926 - acc: 0.8364 - f1: 0.8359 - precision_measure: 0.8394 - recall_measure: 0.8325 - val_loss: 0.6078 - val_acc: 0.7676 - val_f1: 0.7669 - val_precision_measure: 0.7689 - val_recall_measure: 0.7651\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 202s 668us/step - loss: 0.2662 - acc: 0.8533 - f1: 0.8530 - precision_measure: 0.8555 - recall_measure: 0.8505 - val_loss: 0.5708 - val_acc: 0.7771 - val_f1: 0.7752 - val_precision_measure: 0.7789 - val_recall_measure: 0.7717\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 203s 674us/step - loss: 0.2411 - acc: 0.8680 - f1: 0.8677 - precision_measure: 0.8695 - recall_measure: 0.8660 - val_loss: 0.2982 - val_acc: 0.9194 - val_f1: 0.9190 - val_precision_measure: 0.9201 - val_recall_measure: 0.9179\n",
      "Epoch 7/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 204s 677us/step - loss: 0.2204 - acc: 0.8794 - f1: 0.8793 - precision_measure: 0.8805 - recall_measure: 0.8780 - val_loss: 0.6791 - val_acc: 0.7359 - val_f1: 0.7352 - val_precision_measure: 0.7368 - val_recall_measure: 0.7337\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.2088 - acc: 0.8876 - f1: 0.8875 - precision_measure: 0.8888 - recall_measure: 0.8864 - val_loss: 0.4178 - val_acc: 0.8638 - val_f1: 0.8636 - val_precision_measure: 0.8642 - val_recall_measure: 0.8630\n",
      "33762/33762 [==============================] - 8s 243us/step\n",
      "Fitting  8 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 193s 641us/step - loss: 0.6156 - acc: 0.6066 - f1: 0.5579 - precision_measure: 0.6166 - recall_measure: 0.5311 - val_loss: 0.6634 - val_acc: 0.6733 - val_f1: 0.6656 - val_precision_measure: 0.6779 - val_recall_measure: 0.6552\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 194s 643us/step - loss: 0.3720 - acc: 0.7790 - f1: 0.7768 - precision_measure: 0.7852 - recall_measure: 0.7687 - val_loss: 0.4802 - val_acc: 0.8307 - val_f1: 0.8282 - val_precision_measure: 0.8333 - val_recall_measure: 0.8234\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 201s 668us/step - loss: 0.3195 - acc: 0.8212 - f1: 0.8204 - precision_measure: 0.8258 - recall_measure: 0.8153 - val_loss: 0.4169 - val_acc: 0.8621 - val_f1: 0.8612 - val_precision_measure: 0.8651 - val_recall_measure: 0.8577\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 211s 701us/step - loss: 0.2858 - acc: 0.8429 - f1: 0.8426 - precision_measure: 0.8462 - recall_measure: 0.8391 - val_loss: 0.4996 - val_acc: 0.8132 - val_f1: 0.8122 - val_precision_measure: 0.8143 - val_recall_measure: 0.8102\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 197s 652us/step - loss: 0.2613 - acc: 0.8583 - f1: 0.8582 - precision_measure: 0.8604 - recall_measure: 0.8561 - val_loss: 0.3570 - val_acc: 0.8887 - val_f1: 0.8883 - val_precision_measure: 0.8894 - val_recall_measure: 0.8873\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 202s 669us/step - loss: 0.2375 - acc: 0.8710 - f1: 0.8709 - precision_measure: 0.8724 - recall_measure: 0.8693 - val_loss: 0.3688 - val_acc: 0.8711 - val_f1: 0.8711 - val_precision_measure: 0.8720 - val_recall_measure: 0.8703\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 199s 659us/step - loss: 0.2216 - acc: 0.8820 - f1: 0.8820 - precision_measure: 0.8832 - recall_measure: 0.8808 - val_loss: 0.3639 - val_acc: 0.8880 - val_f1: 0.8878 - val_precision_measure: 0.8890 - val_recall_measure: 0.8866\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 194s 645us/step - loss: 0.2050 - acc: 0.8919 - f1: 0.8918 - precision_measure: 0.8927 - recall_measure: 0.8910 - val_loss: 0.4478 - val_acc: 0.8375 - val_f1: 0.8372 - val_precision_measure: 0.8384 - val_recall_measure: 0.8361\n",
      "33762/33762 [==============================] - 8s 225us/step\n",
      "Fitting  9 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 209s 693us/step - loss: 0.5876 - acc: 0.5971 - f1: 0.5583 - precision_measure: 0.6092 - recall_measure: 0.5318 - val_loss: 0.8561 - val_acc: 0.5654 - val_f1: 0.5595 - val_precision_measure: 0.5673 - val_recall_measure: 0.5526\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 200s 664us/step - loss: 0.3808 - acc: 0.7603 - f1: 0.7572 - precision_measure: 0.7665 - recall_measure: 0.7482 - val_loss: 0.6005 - val_acc: 0.7420 - val_f1: 0.7369 - val_precision_measure: 0.7446 - val_recall_measure: 0.7300\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 263s 873us/step - loss: 0.3180 - acc: 0.8152 - f1: 0.8140 - precision_measure: 0.8201 - recall_measure: 0.8081 - val_loss: 0.3482 - val_acc: 0.8918 - val_f1: 0.8913 - val_precision_measure: 0.8942 - val_recall_measure: 0.8886\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 242s 804us/step - loss: 0.2816 - acc: 0.8394 - f1: 0.8388 - precision_measure: 0.8430 - recall_measure: 0.8348 - val_loss: 0.3774 - val_acc: 0.8708 - val_f1: 0.8696 - val_precision_measure: 0.8729 - val_recall_measure: 0.8666\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 261s 866us/step - loss: 0.2529 - acc: 0.8582 - f1: 0.8579 - precision_measure: 0.8606 - recall_measure: 0.8552 - val_loss: 0.3456 - val_acc: 0.8859 - val_f1: 0.8853 - val_precision_measure: 0.8882 - val_recall_measure: 0.8826\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 206s 682us/step - loss: 0.2315 - acc: 0.8714 - f1: 0.8712 - precision_measure: 0.8731 - recall_measure: 0.8693 - val_loss: 0.4907 - val_acc: 0.8061 - val_f1: 0.8049 - val_precision_measure: 0.8070 - val_recall_measure: 0.8031\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 202s 669us/step - loss: 0.2084 - acc: 0.8830 - f1: 0.8828 - precision_measure: 0.8841 - recall_measure: 0.8816 - val_loss: 0.4044 - val_acc: 0.8473 - val_f1: 0.8468 - val_precision_measure: 0.8477 - val_recall_measure: 0.8460\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 260s 863us/step - loss: 0.1935 - acc: 0.8935 - f1: 0.8934 - precision_measure: 0.8942 - recall_measure: 0.8926 - val_loss: 0.5411 - val_acc: 0.7989 - val_f1: 0.7988 - val_precision_measure: 0.7996 - val_recall_measure: 0.7981\n",
      "33762/33762 [==============================] - 8s 237us/step\n",
      "Fitting  10 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 210s 696us/step - loss: 0.5775 - acc: 0.5974 - f1: 0.5649 - precision_measure: 0.6093 - recall_measure: 0.5401 - val_loss: 0.7697 - val_acc: 0.5897 - val_f1: 0.5819 - val_precision_measure: 0.5912 - val_recall_measure: 0.5735\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 198s 658us/step - loss: 0.3572 - acc: 0.7914 - f1: 0.7891 - precision_measure: 0.7969 - recall_measure: 0.7816 - val_loss: 0.8890 - val_acc: 0.5718 - val_f1: 0.5663 - val_precision_measure: 0.5741 - val_recall_measure: 0.5597\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 218s 722us/step - loss: 0.3051 - acc: 0.8272 - f1: 0.8265 - precision_measure: 0.8314 - recall_measure: 0.8218 - val_loss: 0.5575 - val_acc: 0.7766 - val_f1: 0.7750 - val_precision_measure: 0.7786 - val_recall_measure: 0.7716\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 203s 674us/step - loss: 0.2758 - acc: 0.8475 - f1: 0.8471 - precision_measure: 0.8504 - recall_measure: 0.8438 - val_loss: 0.4938 - val_acc: 0.8078 - val_f1: 0.8043 - val_precision_measure: 0.8093 - val_recall_measure: 0.7997\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 204s 676us/step - loss: 0.2507 - acc: 0.8609 - f1: 0.8607 - precision_measure: 0.8632 - recall_measure: 0.8582 - val_loss: 0.4179 - val_acc: 0.8308 - val_f1: 0.8301 - val_precision_measure: 0.8327 - val_recall_measure: 0.8276\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 308s 1ms/step - loss: 0.2268 - acc: 0.8734 - f1: 0.8733 - precision_measure: 0.8749 - recall_measure: 0.8717 - val_loss: 0.4346 - val_acc: 0.8364 - val_f1: 0.8362 - val_precision_measure: 0.8369 - val_recall_measure: 0.8355\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 228s 757us/step - loss: 0.2109 - acc: 0.8835 - f1: 0.8834 - precision_measure: 0.8846 - recall_measure: 0.8821 - val_loss: 0.5181 - val_acc: 0.8087 - val_f1: 0.8083 - val_precision_measure: 0.8096 - val_recall_measure: 0.8071\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 206s 684us/step - loss: 0.1956 - acc: 0.8921 - f1: 0.8921 - precision_measure: 0.8930 - recall_measure: 0.8912 - val_loss: 0.4487 - val_acc: 0.8298 - val_f1: 0.8295 - val_precision_measure: 0.8299 - val_recall_measure: 0.8290\n",
      "33762/33762 [==============================] - 8s 243us/step\n",
      "Fitting  11 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 205s 681us/step - loss: 0.5675 - acc: 0.6496 - f1: 0.6233 - precision_measure: 0.6669 - recall_measure: 0.5983 - val_loss: 0.8392 - val_acc: 0.5906 - val_f1: 0.5802 - val_precision_measure: 0.5929 - val_recall_measure: 0.5693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 194s 644us/step - loss: 0.3569 - acc: 0.8004 - f1: 0.7987 - precision_measure: 0.8072 - recall_measure: 0.7905 - val_loss: 0.7583 - val_acc: 0.6407 - val_f1: 0.6378 - val_precision_measure: 0.6426 - val_recall_measure: 0.6334\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 188s 622us/step - loss: 0.3059 - acc: 0.8308 - f1: 0.8302 - precision_measure: 0.8357 - recall_measure: 0.8249 - val_loss: 0.5916 - val_acc: 0.7559 - val_f1: 0.7519 - val_precision_measure: 0.7592 - val_recall_measure: 0.7454\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 189s 627us/step - loss: 0.2744 - acc: 0.8487 - f1: 0.8483 - precision_measure: 0.8521 - recall_measure: 0.8446 - val_loss: 0.5372 - val_acc: 0.7806 - val_f1: 0.7791 - val_precision_measure: 0.7840 - val_recall_measure: 0.7746\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 186s 617us/step - loss: 0.2481 - acc: 0.8639 - f1: 0.8637 - precision_measure: 0.8662 - recall_measure: 0.8612 - val_loss: 0.5915 - val_acc: 0.7558 - val_f1: 0.7549 - val_precision_measure: 0.7579 - val_recall_measure: 0.7522\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 226s 749us/step - loss: 0.2288 - acc: 0.8743 - f1: 0.8742 - precision_measure: 0.8759 - recall_measure: 0.8726 - val_loss: 0.5354 - val_acc: 0.7885 - val_f1: 0.7881 - val_precision_measure: 0.7903 - val_recall_measure: 0.7860\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 245s 811us/step - loss: 0.2125 - acc: 0.8853 - f1: 0.8852 - precision_measure: 0.8865 - recall_measure: 0.8840 - val_loss: 0.5223 - val_acc: 0.7889 - val_f1: 0.7884 - val_precision_measure: 0.7901 - val_recall_measure: 0.7867\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 223s 741us/step - loss: 0.1931 - acc: 0.8957 - f1: 0.8957 - precision_measure: 0.8966 - recall_measure: 0.8949 - val_loss: 0.4704 - val_acc: 0.8200 - val_f1: 0.8196 - val_precision_measure: 0.8206 - val_recall_measure: 0.8186\n",
      "33762/33762 [==============================] - 8s 248us/step\n",
      "Fitting  12 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 211s 701us/step - loss: 0.5597 - acc: 0.6233 - f1: 0.5959 - precision_measure: 0.6405 - recall_measure: 0.5723 - val_loss: 0.8829 - val_acc: 0.5631 - val_f1: 0.5525 - val_precision_measure: 0.5649 - val_recall_measure: 0.5421\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 206s 683us/step - loss: 0.3440 - acc: 0.7967 - f1: 0.7952 - precision_measure: 0.8021 - recall_measure: 0.7885 - val_loss: 0.8648 - val_acc: 0.6014 - val_f1: 0.5996 - val_precision_measure: 0.6045 - val_recall_measure: 0.5951\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 203s 675us/step - loss: 0.2930 - acc: 0.8372 - f1: 0.8367 - precision_measure: 0.8405 - recall_measure: 0.8330 - val_loss: 0.4614 - val_acc: 0.8218 - val_f1: 0.8213 - val_precision_measure: 0.8232 - val_recall_measure: 0.8195\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 228s 755us/step - loss: 0.2582 - acc: 0.8570 - f1: 0.8567 - precision_measure: 0.8591 - recall_measure: 0.8543 - val_loss: 0.5768 - val_acc: 0.7778 - val_f1: 0.7776 - val_precision_measure: 0.7792 - val_recall_measure: 0.7762\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 245s 813us/step - loss: 0.2333 - acc: 0.8722 - f1: 0.8720 - precision_measure: 0.8735 - recall_measure: 0.8705 - val_loss: 0.5171 - val_acc: 0.8085 - val_f1: 0.8076 - val_precision_measure: 0.8094 - val_recall_measure: 0.8059\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 290s 963us/step - loss: 0.2135 - acc: 0.8845 - f1: 0.8844 - precision_measure: 0.8856 - recall_measure: 0.8833 - val_loss: 0.4898 - val_acc: 0.7971 - val_f1: 0.7967 - val_precision_measure: 0.7983 - val_recall_measure: 0.7952\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 283s 939us/step - loss: 0.1912 - acc: 0.8980 - f1: 0.8979 - precision_measure: 0.8986 - recall_measure: 0.8971 - val_loss: 0.7845 - val_acc: 0.7172 - val_f1: 0.7166 - val_precision_measure: 0.7180 - val_recall_measure: 0.7153\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 260s 861us/step - loss: 0.1776 - acc: 0.9087 - f1: 0.9087 - precision_measure: 0.9093 - recall_measure: 0.9081 - val_loss: 0.4200 - val_acc: 0.8510 - val_f1: 0.8504 - val_precision_measure: 0.8521 - val_recall_measure: 0.8489\n",
      "33762/33762 [==============================] - 9s 253us/step\n",
      "Fitting  13 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 235s 780us/step - loss: 0.5459 - acc: 0.6204 - f1: 0.5965 - precision_measure: 0.6355 - recall_measure: 0.5727 - val_loss: 0.5466 - val_acc: 0.7915 - val_f1: 0.7881 - val_precision_measure: 0.7966 - val_recall_measure: 0.7805\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 195s 645us/step - loss: 0.3516 - acc: 0.7872 - f1: 0.7853 - precision_measure: 0.7934 - recall_measure: 0.7776 - val_loss: 0.9239 - val_acc: 0.6096 - val_f1: 0.6064 - val_precision_measure: 0.6115 - val_recall_measure: 0.6018\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 197s 653us/step - loss: 0.2931 - acc: 0.8309 - f1: 0.8302 - precision_measure: 0.8352 - recall_measure: 0.8253 - val_loss: 0.5350 - val_acc: 0.7808 - val_f1: 0.7796 - val_precision_measure: 0.7830 - val_recall_measure: 0.7765\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 203s 673us/step - loss: 0.2666 - acc: 0.8526 - f1: 0.8521 - precision_measure: 0.8558 - recall_measure: 0.8486 - val_loss: 0.2646 - val_acc: 0.9209 - val_f1: 0.9209 - val_precision_measure: 0.9222 - val_recall_measure: 0.9198\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 200s 662us/step - loss: 0.2355 - acc: 0.8672 - f1: 0.8670 - precision_measure: 0.8691 - recall_measure: 0.8649 - val_loss: 0.4202 - val_acc: 0.8445 - val_f1: 0.8438 - val_precision_measure: 0.8453 - val_recall_measure: 0.8425\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 195s 645us/step - loss: 0.2180 - acc: 0.8769 - f1: 0.8768 - precision_measure: 0.8785 - recall_measure: 0.8752 - val_loss: 0.5042 - val_acc: 0.8080 - val_f1: 0.8076 - val_precision_measure: 0.8089 - val_recall_measure: 0.8064\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 198s 655us/step - loss: 0.2027 - acc: 0.8865 - f1: 0.8864 - precision_measure: 0.8877 - recall_measure: 0.8852 - val_loss: 0.4735 - val_acc: 0.8266 - val_f1: 0.8265 - val_precision_measure: 0.8278 - val_recall_measure: 0.8252\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 196s 651us/step - loss: 0.1852 - acc: 0.8977 - f1: 0.8977 - precision_measure: 0.8986 - recall_measure: 0.8968 - val_loss: 0.4668 - val_acc: 0.8314 - val_f1: 0.8310 - val_precision_measure: 0.8324 - val_recall_measure: 0.8297\n",
      "33762/33762 [==============================] - 7s 222us/step\n",
      "Fitting  14 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 209s 693us/step - loss: 0.5358 - acc: 0.6591 - f1: 0.6346 - precision_measure: 0.6741 - recall_measure: 0.6111 - val_loss: 0.7107 - val_acc: 0.6656 - val_f1: 0.6548 - val_precision_measure: 0.6706 - val_recall_measure: 0.6418\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 194s 645us/step - loss: 0.3372 - acc: 0.8087 - f1: 0.8073 - precision_measure: 0.8150 - recall_measure: 0.7999 - val_loss: 0.5695 - val_acc: 0.7745 - val_f1: 0.7708 - val_precision_measure: 0.7788 - val_recall_measure: 0.7637\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 202s 671us/step - loss: 0.2819 - acc: 0.8415 - f1: 0.8411 - precision_measure: 0.8452 - recall_measure: 0.8370 - val_loss: 0.6197 - val_acc: 0.7261 - val_f1: 0.7244 - val_precision_measure: 0.7272 - val_recall_measure: 0.7219\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 200s 664us/step - loss: 0.2509 - acc: 0.8587 - f1: 0.8586 - precision_measure: 0.8613 - recall_measure: 0.8559 - val_loss: 0.5930 - val_acc: 0.7636 - val_f1: 0.7620 - val_precision_measure: 0.7660 - val_recall_measure: 0.7582\n",
      "Epoch 5/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 180s 597us/step - loss: 0.2268 - acc: 0.8715 - f1: 0.8713 - precision_measure: 0.8734 - recall_measure: 0.8692 - val_loss: 0.5144 - val_acc: 0.7965 - val_f1: 0.7962 - val_precision_measure: 0.7974 - val_recall_measure: 0.7951\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 180s 595us/step - loss: 0.2074 - acc: 0.8822 - f1: 0.8821 - precision_measure: 0.8837 - recall_measure: 0.8807 - val_loss: 0.2834 - val_acc: 0.9091 - val_f1: 0.9091 - val_precision_measure: 0.9104 - val_recall_measure: 0.9080\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 176s 583us/step - loss: 0.1898 - acc: 0.8935 - f1: 0.8935 - precision_measure: 0.8946 - recall_measure: 0.8924 - val_loss: 0.4796 - val_acc: 0.8296 - val_f1: 0.8296 - val_precision_measure: 0.8308 - val_recall_measure: 0.8284\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 176s 585us/step - loss: 0.1756 - acc: 0.9037 - f1: 0.9036 - precision_measure: 0.9046 - recall_measure: 0.9027 - val_loss: 0.4251 - val_acc: 0.8306 - val_f1: 0.8304 - val_precision_measure: 0.8311 - val_recall_measure: 0.8297\n",
      "33762/33762 [==============================] - 6s 179us/step\n",
      "Fitting  15 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 179s 593us/step - loss: 0.5136 - acc: 0.6699 - f1: 0.6498 - precision_measure: 0.6827 - recall_measure: 0.6291 - val_loss: 0.6726 - val_acc: 0.6708 - val_f1: 0.6679 - val_precision_measure: 0.6733 - val_recall_measure: 0.6629\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 178s 590us/step - loss: 0.3187 - acc: 0.8200 - f1: 0.8188 - precision_measure: 0.8249 - recall_measure: 0.8129 - val_loss: 0.5814 - val_acc: 0.7780 - val_f1: 0.7743 - val_precision_measure: 0.7821 - val_recall_measure: 0.7674\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.2697 - acc: 0.8502 - f1: 0.8499 - precision_measure: 0.8536 - recall_measure: 0.8462 - val_loss: 0.4770 - val_acc: 0.8122 - val_f1: 0.8116 - val_precision_measure: 0.8144 - val_recall_measure: 0.8089\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 180s 595us/step - loss: 0.2383 - acc: 0.8678 - f1: 0.8677 - precision_measure: 0.8701 - recall_measure: 0.8653 - val_loss: 0.4011 - val_acc: 0.8490 - val_f1: 0.8488 - val_precision_measure: 0.8507 - val_recall_measure: 0.8471\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 180s 595us/step - loss: 0.2189 - acc: 0.8787 - f1: 0.8785 - precision_measure: 0.8803 - recall_measure: 0.8768 - val_loss: 0.4553 - val_acc: 0.8321 - val_f1: 0.8312 - val_precision_measure: 0.8343 - val_recall_measure: 0.8283\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 181s 599us/step - loss: 0.1963 - acc: 0.8916 - f1: 0.8915 - precision_measure: 0.8927 - recall_measure: 0.8904 - val_loss: 0.6102 - val_acc: 0.7473 - val_f1: 0.7466 - val_precision_measure: 0.7483 - val_recall_measure: 0.7450\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 180s 597us/step - loss: 0.1840 - acc: 0.9011 - f1: 0.9011 - precision_measure: 0.9021 - recall_measure: 0.9001 - val_loss: 0.4496 - val_acc: 0.8373 - val_f1: 0.8373 - val_precision_measure: 0.8379 - val_recall_measure: 0.8368\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.1644 - acc: 0.9122 - f1: 0.9122 - precision_measure: 0.9128 - recall_measure: 0.9116 - val_loss: 0.5442 - val_acc: 0.7955 - val_f1: 0.7952 - val_precision_measure: 0.7958 - val_recall_measure: 0.7947\n",
      "33762/33762 [==============================] - 6s 183us/step\n",
      "Fitting  16 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 180s 595us/step - loss: 0.4939 - acc: 0.7017 - f1: 0.6815 - precision_measure: 0.7122 - recall_measure: 0.6635 - val_loss: 0.6638 - val_acc: 0.7065 - val_f1: 0.7034 - val_precision_measure: 0.7097 - val_recall_measure: 0.6978\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 176s 582us/step - loss: 0.3085 - acc: 0.8257 - f1: 0.8247 - precision_measure: 0.8305 - recall_measure: 0.8191 - val_loss: 0.4450 - val_acc: 0.8321 - val_f1: 0.8308 - val_precision_measure: 0.8361 - val_recall_measure: 0.8261\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 177s 586us/step - loss: 0.2618 - acc: 0.8553 - f1: 0.8549 - precision_measure: 0.8585 - recall_measure: 0.8514 - val_loss: 0.3317 - val_acc: 0.8879 - val_f1: 0.8872 - val_precision_measure: 0.8893 - val_recall_measure: 0.8851\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 179s 595us/step - loss: 0.2327 - acc: 0.8716 - f1: 0.8715 - precision_measure: 0.8737 - recall_measure: 0.8693 - val_loss: 0.5395 - val_acc: 0.7742 - val_f1: 0.7730 - val_precision_measure: 0.7764 - val_recall_measure: 0.7699\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.2101 - acc: 0.8839 - f1: 0.8838 - precision_measure: 0.8852 - recall_measure: 0.8824 - val_loss: 0.6449 - val_acc: 0.7515 - val_f1: 0.7508 - val_precision_measure: 0.7541 - val_recall_measure: 0.7478\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 592us/step - loss: 0.1965 - acc: 0.8937 - f1: 0.8936 - precision_measure: 0.8947 - recall_measure: 0.8926 - val_loss: 0.5408 - val_acc: 0.7835 - val_f1: 0.7830 - val_precision_measure: 0.7840 - val_recall_measure: 0.7820\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 178s 591us/step - loss: 0.1771 - acc: 0.9056 - f1: 0.9055 - precision_measure: 0.9063 - recall_measure: 0.9047 - val_loss: 0.3975 - val_acc: 0.8629 - val_f1: 0.8623 - val_precision_measure: 0.8643 - val_recall_measure: 0.8605\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 177s 585us/step - loss: 0.1619 - acc: 0.9167 - f1: 0.9166 - precision_measure: 0.9173 - recall_measure: 0.9160 - val_loss: 0.4442 - val_acc: 0.8465 - val_f1: 0.8462 - val_precision_measure: 0.8471 - val_recall_measure: 0.8454\n",
      "33762/33762 [==============================] - 7s 197us/step\n",
      "Fitting  17 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.7837 - acc: 0.5449 - f1: 0.4638 - precision_measure: 0.5724 - recall_measure: 0.4227 - val_loss: 1.0414 - val_acc: 0.4199 - val_f1: 0.4076 - val_precision_measure: 0.4211 - val_recall_measure: 0.3969\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 180s 598us/step - loss: 0.4968 - acc: 0.6169 - f1: 0.6068 - precision_measure: 0.6231 - recall_measure: 0.5917 - val_loss: 0.8440 - val_acc: 0.4979 - val_f1: 0.4869 - val_precision_measure: 0.4988 - val_recall_measure: 0.4768\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.4500 - acc: 0.6775 - f1: 0.6713 - precision_measure: 0.6837 - recall_measure: 0.6595 - val_loss: 0.9658 - val_acc: 0.4972 - val_f1: 0.4922 - val_precision_measure: 0.4966 - val_recall_measure: 0.4883\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 180s 596us/step - loss: 0.4069 - acc: 0.7370 - f1: 0.7338 - precision_measure: 0.7425 - recall_measure: 0.7255 - val_loss: 0.7307 - val_acc: 0.6281 - val_f1: 0.6265 - val_precision_measure: 0.6301 - val_recall_measure: 0.6232\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.3689 - acc: 0.7804 - f1: 0.7786 - precision_measure: 0.7852 - recall_measure: 0.7723 - val_loss: 0.5568 - val_acc: 0.7643 - val_f1: 0.7623 - val_precision_measure: 0.7657 - val_recall_measure: 0.7591\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 593us/step - loss: 0.3333 - acc: 0.8120 - f1: 0.8109 - precision_measure: 0.8159 - recall_measure: 0.8061 - val_loss: 0.5538 - val_acc: 0.7893 - val_f1: 0.7861 - val_precision_measure: 0.7917 - val_recall_measure: 0.7811\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.3081 - acc: 0.8300 - f1: 0.8294 - precision_measure: 0.8332 - recall_measure: 0.8257 - val_loss: 0.4843 - val_acc: 0.8194 - val_f1: 0.8181 - val_precision_measure: 0.8202 - val_recall_measure: 0.8161\n",
      "Epoch 8/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 174s 578us/step - loss: 0.2854 - acc: 0.8443 - f1: 0.8440 - precision_measure: 0.8469 - recall_measure: 0.8413 - val_loss: 0.4702 - val_acc: 0.8320 - val_f1: 0.8313 - val_precision_measure: 0.8336 - val_recall_measure: 0.8291\n",
      "33762/33762 [==============================] - 7s 193us/step\n",
      "Fitting  18 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 187s 621us/step - loss: 0.7903 - acc: 0.5577 - f1: 0.4745 - precision_measure: 0.5876 - recall_measure: 0.4338 - val_loss: 1.0269 - val_acc: 0.4622 - val_f1: 0.4279 - val_precision_measure: 0.4649 - val_recall_measure: 0.4027\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 181s 601us/step - loss: 0.4708 - acc: 0.6968 - f1: 0.6898 - precision_measure: 0.7038 - recall_measure: 0.6766 - val_loss: 0.9185 - val_acc: 0.5635 - val_f1: 0.5574 - val_precision_measure: 0.5637 - val_recall_measure: 0.5517\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 184s 609us/step - loss: 0.4047 - acc: 0.7644 - f1: 0.7620 - precision_measure: 0.7704 - recall_measure: 0.7540 - val_loss: 0.8262 - val_acc: 0.5416 - val_f1: 0.5353 - val_precision_measure: 0.5428 - val_recall_measure: 0.5288\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 185s 613us/step - loss: 0.3640 - acc: 0.7947 - f1: 0.7930 - precision_measure: 0.7994 - recall_measure: 0.7867 - val_loss: 0.5444 - val_acc: 0.7996 - val_f1: 0.7968 - val_precision_measure: 0.8020 - val_recall_measure: 0.7920\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 182s 605us/step - loss: 0.3389 - acc: 0.8093 - f1: 0.8081 - precision_measure: 0.8130 - recall_measure: 0.8034 - val_loss: 0.4961 - val_acc: 0.8255 - val_f1: 0.8244 - val_precision_measure: 0.8276 - val_recall_measure: 0.8214\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 184s 609us/step - loss: 0.3142 - acc: 0.8254 - f1: 0.8249 - precision_measure: 0.8288 - recall_measure: 0.8211 - val_loss: 0.5991 - val_acc: 0.7753 - val_f1: 0.7727 - val_precision_measure: 0.7775 - val_recall_measure: 0.7684\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 182s 602us/step - loss: 0.2911 - acc: 0.8390 - f1: 0.8386 - precision_measure: 0.8416 - recall_measure: 0.8356 - val_loss: 0.4867 - val_acc: 0.8230 - val_f1: 0.8226 - val_precision_measure: 0.8238 - val_recall_measure: 0.8215\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 186s 617us/step - loss: 0.2781 - acc: 0.8474 - f1: 0.8470 - precision_measure: 0.8496 - recall_measure: 0.8445 - val_loss: 0.5059 - val_acc: 0.8219 - val_f1: 0.8217 - val_precision_measure: 0.8230 - val_recall_measure: 0.8205\n",
      "33762/33762 [==============================] - 7s 198us/step\n",
      "Fitting  19 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 191s 634us/step - loss: 0.8023 - acc: 0.5478 - f1: 0.4647 - precision_measure: 0.5767 - recall_measure: 0.4232 - val_loss: 0.9870 - val_acc: 0.4657 - val_f1: 0.4447 - val_precision_measure: 0.4675 - val_recall_measure: 0.4282\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 185s 615us/step - loss: 0.4881 - acc: 0.6665 - f1: 0.6584 - precision_measure: 0.6750 - recall_measure: 0.6430 - val_loss: 0.7444 - val_acc: 0.6118 - val_f1: 0.6079 - val_precision_measure: 0.6134 - val_recall_measure: 0.6030\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 190s 630us/step - loss: 0.4393 - acc: 0.7144 - f1: 0.7098 - precision_measure: 0.7214 - recall_measure: 0.6988 - val_loss: 0.8256 - val_acc: 0.5355 - val_f1: 0.5330 - val_precision_measure: 0.5366 - val_recall_measure: 0.5297\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 186s 616us/step - loss: 0.4042 - acc: 0.7445 - f1: 0.7419 - precision_measure: 0.7513 - recall_measure: 0.7330 - val_loss: 0.7147 - val_acc: 0.6439 - val_f1: 0.6402 - val_precision_measure: 0.6459 - val_recall_measure: 0.6349\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 188s 622us/step - loss: 0.3862 - acc: 0.7613 - f1: 0.7595 - precision_measure: 0.7672 - recall_measure: 0.7521 - val_loss: 0.4863 - val_acc: 0.8195 - val_f1: 0.8172 - val_precision_measure: 0.8214 - val_recall_measure: 0.8132\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 190s 628us/step - loss: 0.3569 - acc: 0.7794 - f1: 0.7779 - precision_measure: 0.7840 - recall_measure: 0.7720 - val_loss: 0.7626 - val_acc: 0.6556 - val_f1: 0.6515 - val_precision_measure: 0.6572 - val_recall_measure: 0.6462\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 186s 616us/step - loss: 0.3381 - acc: 0.7986 - f1: 0.7975 - precision_measure: 0.8022 - recall_measure: 0.7930 - val_loss: 0.5507 - val_acc: 0.7781 - val_f1: 0.7761 - val_precision_measure: 0.7804 - val_recall_measure: 0.7721\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 188s 625us/step - loss: 0.3132 - acc: 0.8218 - f1: 0.8212 - precision_measure: 0.8248 - recall_measure: 0.8176 - val_loss: 0.4646 - val_acc: 0.8249 - val_f1: 0.8241 - val_precision_measure: 0.8260 - val_recall_measure: 0.8224\n",
      "33762/33762 [==============================] - 7s 204us/step\n",
      "Fitting  20 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.7759 - acc: 0.5468 - f1: 0.4717 - precision_measure: 0.5724 - recall_measure: 0.4315 - val_loss: 0.9906 - val_acc: 0.4225 - val_f1: 0.4090 - val_precision_measure: 0.4220 - val_recall_measure: 0.3983\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 184s 609us/step - loss: 0.4860 - acc: 0.6564 - f1: 0.6484 - precision_measure: 0.6640 - recall_measure: 0.6338 - val_loss: 0.7642 - val_acc: 0.6062 - val_f1: 0.6018 - val_precision_measure: 0.6090 - val_recall_measure: 0.5956\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 191s 632us/step - loss: 0.4355 - acc: 0.7136 - f1: 0.7089 - precision_measure: 0.7206 - recall_measure: 0.6978 - val_loss: 0.7630 - val_acc: 0.6380 - val_f1: 0.6344 - val_precision_measure: 0.6401 - val_recall_measure: 0.6293\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 185s 613us/step - loss: 0.4059 - acc: 0.7417 - f1: 0.7388 - precision_measure: 0.7480 - recall_measure: 0.7299 - val_loss: 0.6699 - val_acc: 0.6960 - val_f1: 0.6877 - val_precision_measure: 0.6989 - val_recall_measure: 0.6782\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 187s 621us/step - loss: 0.3803 - acc: 0.7630 - f1: 0.7608 - precision_measure: 0.7683 - recall_measure: 0.7536 - val_loss: 1.2118 - val_acc: 0.4847 - val_f1: 0.4817 - val_precision_measure: 0.4861 - val_recall_measure: 0.4776\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 187s 619us/step - loss: 0.3606 - acc: 0.7793 - f1: 0.7776 - precision_measure: 0.7837 - recall_measure: 0.7717 - val_loss: 0.7039 - val_acc: 0.7006 - val_f1: 0.6964 - val_precision_measure: 0.7029 - val_recall_measure: 0.6906\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 186s 618us/step - loss: 0.3428 - acc: 0.7924 - f1: 0.7913 - precision_measure: 0.7963 - recall_measure: 0.7864 - val_loss: 0.5333 - val_acc: 0.8001 - val_f1: 0.7989 - val_precision_measure: 0.8021 - val_recall_measure: 0.7959\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 188s 623us/step - loss: 0.3304 - acc: 0.8047 - f1: 0.8037 - precision_measure: 0.8077 - recall_measure: 0.7998 - val_loss: 0.4762 - val_acc: 0.8239 - val_f1: 0.8217 - val_precision_measure: 0.8252 - val_recall_measure: 0.8184\n",
      "33762/33762 [==============================] - 8s 224us/step\n",
      "Fitting  21 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 200s 663us/step - loss: 0.6804 - acc: 0.5395 - f1: 0.4826 - precision_measure: 0.5567 - recall_measure: 0.4491 - val_loss: 0.9091 - val_acc: 0.5368 - val_f1: 0.5272 - val_precision_measure: 0.5406 - val_recall_measure: 0.5159\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 188s 624us/step - loss: 0.4270 - acc: 0.7190 - f1: 0.7137 - precision_measure: 0.7273 - recall_measure: 0.7010 - val_loss: 0.7066 - val_acc: 0.6727 - val_f1: 0.6699 - val_precision_measure: 0.6747 - val_recall_measure: 0.6654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 177s 587us/step - loss: 0.3653 - acc: 0.7888 - f1: 0.7870 - precision_measure: 0.7952 - recall_measure: 0.7792 - val_loss: 0.5355 - val_acc: 0.7941 - val_f1: 0.7924 - val_precision_measure: 0.7961 - val_recall_measure: 0.7891\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 179s 595us/step - loss: 0.3287 - acc: 0.8149 - f1: 0.8139 - precision_measure: 0.8200 - recall_measure: 0.8079 - val_loss: 0.4719 - val_acc: 0.7974 - val_f1: 0.7960 - val_precision_measure: 0.7989 - val_recall_measure: 0.7934\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.3038 - acc: 0.8307 - f1: 0.8300 - precision_measure: 0.8349 - recall_measure: 0.8252 - val_loss: 0.5042 - val_acc: 0.8066 - val_f1: 0.8058 - val_precision_measure: 0.8085 - val_recall_measure: 0.8032\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 594us/step - loss: 0.2834 - acc: 0.8428 - f1: 0.8424 - precision_measure: 0.8463 - recall_measure: 0.8386 - val_loss: 0.4006 - val_acc: 0.8726 - val_f1: 0.8715 - val_precision_measure: 0.8740 - val_recall_measure: 0.8693\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 180s 595us/step - loss: 0.2691 - acc: 0.8523 - f1: 0.8521 - precision_measure: 0.8553 - recall_measure: 0.8489 - val_loss: 0.4008 - val_acc: 0.8665 - val_f1: 0.8656 - val_precision_measure: 0.8681 - val_recall_measure: 0.8632\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.2517 - acc: 0.8627 - f1: 0.8624 - precision_measure: 0.8648 - recall_measure: 0.8600 - val_loss: 0.6173 - val_acc: 0.7269 - val_f1: 0.7264 - val_precision_measure: 0.7281 - val_recall_measure: 0.7249\n",
      "33762/33762 [==============================] - 7s 195us/step\n",
      "Fitting  22 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 183s 606us/step - loss: 0.6705 - acc: 0.5790 - f1: 0.5210 - precision_measure: 0.5972 - recall_measure: 0.4898 - val_loss: 0.9155 - val_acc: 0.5448 - val_f1: 0.5346 - val_precision_measure: 0.5482 - val_recall_measure: 0.5236\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 178s 588us/step - loss: 0.4272 - acc: 0.7181 - f1: 0.7133 - precision_measure: 0.7248 - recall_measure: 0.7023 - val_loss: 0.8372 - val_acc: 0.5915 - val_f1: 0.5618 - val_precision_measure: 0.5968 - val_recall_measure: 0.5360\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 180s 598us/step - loss: 0.3752 - acc: 0.7709 - f1: 0.7687 - precision_measure: 0.7765 - recall_measure: 0.7612 - val_loss: 0.7135 - val_acc: 0.6637 - val_f1: 0.6579 - val_precision_measure: 0.6654 - val_recall_measure: 0.6514\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 178s 591us/step - loss: 0.3364 - acc: 0.8052 - f1: 0.8038 - precision_measure: 0.8092 - recall_measure: 0.7986 - val_loss: 0.6320 - val_acc: 0.7395 - val_f1: 0.7373 - val_precision_measure: 0.7410 - val_recall_measure: 0.7339\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 180s 597us/step - loss: 0.3081 - acc: 0.8272 - f1: 0.8267 - precision_measure: 0.8305 - recall_measure: 0.8229 - val_loss: 0.8680 - val_acc: 0.6272 - val_f1: 0.6249 - val_precision_measure: 0.6284 - val_recall_measure: 0.6216\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 178s 591us/step - loss: 0.2826 - acc: 0.8441 - f1: 0.8438 - precision_measure: 0.8468 - recall_measure: 0.8408 - val_loss: 0.4305 - val_acc: 0.8442 - val_f1: 0.8437 - val_precision_measure: 0.8456 - val_recall_measure: 0.8419\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 176s 585us/step - loss: 0.2689 - acc: 0.8554 - f1: 0.8551 - precision_measure: 0.8577 - recall_measure: 0.8525 - val_loss: 0.5948 - val_acc: 0.7632 - val_f1: 0.7623 - val_precision_measure: 0.7649 - val_recall_measure: 0.7599\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.2516 - acc: 0.8642 - f1: 0.8640 - precision_measure: 0.8661 - recall_measure: 0.8620 - val_loss: 0.5289 - val_acc: 0.7867 - val_f1: 0.7862 - val_precision_measure: 0.7873 - val_recall_measure: 0.7852\n",
      "33762/33762 [==============================] - 7s 203us/step\n",
      "Fitting  23 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 182s 602us/step - loss: 0.6625 - acc: 0.5361 - f1: 0.4859 - precision_measure: 0.5499 - recall_measure: 0.4543 - val_loss: 0.8049 - val_acc: 0.5615 - val_f1: 0.5502 - val_precision_measure: 0.5654 - val_recall_measure: 0.5377\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 181s 599us/step - loss: 0.4346 - acc: 0.7126 - f1: 0.7064 - precision_measure: 0.7200 - recall_measure: 0.6936 - val_loss: 0.9335 - val_acc: 0.5120 - val_f1: 0.5016 - val_precision_measure: 0.5125 - val_recall_measure: 0.4922\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 180s 597us/step - loss: 0.3623 - acc: 0.7916 - f1: 0.7897 - precision_measure: 0.7968 - recall_measure: 0.7829 - val_loss: 1.0249 - val_acc: 0.5014 - val_f1: 0.4998 - val_precision_measure: 0.5019 - val_recall_measure: 0.4978\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 178s 590us/step - loss: 0.3267 - acc: 0.8188 - f1: 0.8179 - precision_measure: 0.8230 - recall_measure: 0.8129 - val_loss: 0.6229 - val_acc: 0.7267 - val_f1: 0.7250 - val_precision_measure: 0.7278 - val_recall_measure: 0.7224\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 178s 590us/step - loss: 0.3030 - acc: 0.8363 - f1: 0.8356 - precision_measure: 0.8395 - recall_measure: 0.8318 - val_loss: 0.3935 - val_acc: 0.8645 - val_f1: 0.8635 - val_precision_measure: 0.8664 - val_recall_measure: 0.8608\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 594us/step - loss: 0.2844 - acc: 0.8469 - f1: 0.8464 - precision_measure: 0.8496 - recall_measure: 0.8433 - val_loss: 0.4723 - val_acc: 0.8210 - val_f1: 0.8200 - val_precision_measure: 0.8221 - val_recall_measure: 0.8180\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 180s 596us/step - loss: 0.2676 - acc: 0.8563 - f1: 0.8560 - precision_measure: 0.8586 - recall_measure: 0.8534 - val_loss: 0.5911 - val_acc: 0.7549 - val_f1: 0.7545 - val_precision_measure: 0.7559 - val_recall_measure: 0.7531\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 185s 614us/step - loss: 0.2572 - acc: 0.8630 - f1: 0.8627 - precision_measure: 0.8649 - recall_measure: 0.8606 - val_loss: 0.3764 - val_acc: 0.8736 - val_f1: 0.8733 - val_precision_measure: 0.8750 - val_recall_measure: 0.8717\n",
      "33762/33762 [==============================] - 8s 226us/step\n",
      "Fitting  24 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 182s 603us/step - loss: 0.6711 - acc: 0.5274 - f1: 0.4705 - precision_measure: 0.5438 - recall_measure: 0.4360 - val_loss: 0.9554 - val_acc: 0.4598 - val_f1: 0.4411 - val_precision_measure: 0.4589 - val_recall_measure: 0.4272\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 182s 602us/step - loss: 0.4230 - acc: 0.7142 - f1: 0.7081 - precision_measure: 0.7218 - recall_measure: 0.6953 - val_loss: 0.7582 - val_acc: 0.6226 - val_f1: 0.6123 - val_precision_measure: 0.6231 - val_recall_measure: 0.6032\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 180s 596us/step - loss: 0.3533 - acc: 0.7959 - f1: 0.7941 - precision_measure: 0.8017 - recall_measure: 0.7867 - val_loss: 0.9119 - val_acc: 0.5592 - val_f1: 0.5546 - val_precision_measure: 0.5597 - val_recall_measure: 0.5500\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 180s 596us/step - loss: 0.3174 - acc: 0.8208 - f1: 0.8199 - precision_measure: 0.8248 - recall_measure: 0.8150 - val_loss: 0.4341 - val_acc: 0.8485 - val_f1: 0.8466 - val_precision_measure: 0.8510 - val_recall_measure: 0.8427\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 180s 597us/step - loss: 0.2999 - acc: 0.8342 - f1: 0.8334 - precision_measure: 0.8375 - recall_measure: 0.8294 - val_loss: 0.5851 - val_acc: 0.7540 - val_f1: 0.7504 - val_precision_measure: 0.7559 - val_recall_measure: 0.7453\n",
      "Epoch 6/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 175s 581us/step - loss: 0.2743 - acc: 0.8472 - f1: 0.8467 - precision_measure: 0.8499 - recall_measure: 0.8437 - val_loss: 0.5825 - val_acc: 0.7407 - val_f1: 0.7397 - val_precision_measure: 0.7419 - val_recall_measure: 0.7376\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 175s 581us/step - loss: 0.2557 - acc: 0.8580 - f1: 0.8578 - precision_measure: 0.8602 - recall_measure: 0.8555 - val_loss: 0.5077 - val_acc: 0.7938 - val_f1: 0.7930 - val_precision_measure: 0.7952 - val_recall_measure: 0.7909\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 174s 578us/step - loss: 0.2413 - acc: 0.8687 - f1: 0.8684 - precision_measure: 0.8704 - recall_measure: 0.8665 - val_loss: 0.6346 - val_acc: 0.7440 - val_f1: 0.7426 - val_precision_measure: 0.7456 - val_recall_measure: 0.7398\n",
      "33762/33762 [==============================] - 7s 205us/step\n",
      "Fitting  25 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 184s 609us/step - loss: 0.6121 - acc: 0.5817 - f1: 0.5408 - precision_measure: 0.5979 - recall_measure: 0.5109 - val_loss: 0.7903 - val_acc: 0.6215 - val_f1: 0.6170 - val_precision_measure: 0.6254 - val_recall_measure: 0.6097\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 176s 582us/step - loss: 0.3902 - acc: 0.7616 - f1: 0.7584 - precision_measure: 0.7684 - recall_measure: 0.7489 - val_loss: 0.5906 - val_acc: 0.7623 - val_f1: 0.7593 - val_precision_measure: 0.7655 - val_recall_measure: 0.7536\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.3348 - acc: 0.8116 - f1: 0.8103 - precision_measure: 0.8169 - recall_measure: 0.8039 - val_loss: 0.6886 - val_acc: 0.7042 - val_f1: 0.6974 - val_precision_measure: 0.7071 - val_recall_measure: 0.6889\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 176s 583us/step - loss: 0.3018 - acc: 0.8294 - f1: 0.8288 - precision_measure: 0.8340 - recall_measure: 0.8237 - val_loss: 0.3581 - val_acc: 0.8877 - val_f1: 0.8870 - val_precision_measure: 0.8906 - val_recall_measure: 0.8837\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 175s 581us/step - loss: 0.2802 - acc: 0.8429 - f1: 0.8423 - precision_measure: 0.8460 - recall_measure: 0.8386 - val_loss: 0.3761 - val_acc: 0.8775 - val_f1: 0.8764 - val_precision_measure: 0.8795 - val_recall_measure: 0.8735\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 176s 584us/step - loss: 0.2636 - acc: 0.8527 - f1: 0.8524 - precision_measure: 0.8553 - recall_measure: 0.8495 - val_loss: 0.4296 - val_acc: 0.8362 - val_f1: 0.8353 - val_precision_measure: 0.8369 - val_recall_measure: 0.8338\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.2519 - acc: 0.8600 - f1: 0.8597 - precision_measure: 0.8624 - recall_measure: 0.8571 - val_loss: 0.3649 - val_acc: 0.8644 - val_f1: 0.8642 - val_precision_measure: 0.8650 - val_recall_measure: 0.8635\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 177s 585us/step - loss: 0.2381 - acc: 0.8692 - f1: 0.8690 - precision_measure: 0.8711 - recall_measure: 0.8670 - val_loss: 0.3839 - val_acc: 0.8748 - val_f1: 0.8745 - val_precision_measure: 0.8764 - val_recall_measure: 0.8728\n",
      "33762/33762 [==============================] - 7s 213us/step\n",
      "Fitting  26 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 184s 610us/step - loss: 0.6092 - acc: 0.5963 - f1: 0.5588 - precision_measure: 0.6161 - recall_measure: 0.5285 - val_loss: 0.8745 - val_acc: 0.5699 - val_f1: 0.5566 - val_precision_measure: 0.5717 - val_recall_measure: 0.5443\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.3996 - acc: 0.7500 - f1: 0.7460 - precision_measure: 0.7567 - recall_measure: 0.7358 - val_loss: 0.6999 - val_acc: 0.6070 - val_f1: 0.6041 - val_precision_measure: 0.6097 - val_recall_measure: 0.5990\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 179s 593us/step - loss: 0.3479 - acc: 0.7933 - f1: 0.7916 - precision_measure: 0.7989 - recall_measure: 0.7846 - val_loss: 0.6356 - val_acc: 0.7232 - val_f1: 0.7222 - val_precision_measure: 0.7248 - val_recall_measure: 0.7197\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 179s 592us/step - loss: 0.3088 - acc: 0.8258 - f1: 0.8249 - precision_measure: 0.8300 - recall_measure: 0.8200 - val_loss: 0.5691 - val_acc: 0.7630 - val_f1: 0.7627 - val_precision_measure: 0.7652 - val_recall_measure: 0.7603\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 178s 590us/step - loss: 0.2837 - acc: 0.8411 - f1: 0.8404 - precision_measure: 0.8446 - recall_measure: 0.8364 - val_loss: 0.5740 - val_acc: 0.7628 - val_f1: 0.7619 - val_precision_measure: 0.7645 - val_recall_measure: 0.7594\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 187s 621us/step - loss: 0.2644 - acc: 0.8519 - f1: 0.8515 - precision_measure: 0.8545 - recall_measure: 0.8487 - val_loss: 0.4908 - val_acc: 0.8255 - val_f1: 0.8228 - val_precision_measure: 0.8285 - val_recall_measure: 0.8177\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 178s 591us/step - loss: 0.2469 - acc: 0.8618 - f1: 0.8614 - precision_measure: 0.8638 - recall_measure: 0.8591 - val_loss: 0.4928 - val_acc: 0.8136 - val_f1: 0.8131 - val_precision_measure: 0.8148 - val_recall_measure: 0.8114\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 179s 595us/step - loss: 0.2305 - acc: 0.8706 - f1: 0.8705 - precision_measure: 0.8721 - recall_measure: 0.8688 - val_loss: 0.5964 - val_acc: 0.7742 - val_f1: 0.7736 - val_precision_measure: 0.7750 - val_recall_measure: 0.7723\n",
      "33762/33762 [==============================] - 7s 206us/step\n",
      "Fitting  27 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 182s 603us/step - loss: 0.5886 - acc: 0.6073 - f1: 0.5752 - precision_measure: 0.6245 - recall_measure: 0.5483 - val_loss: 0.8812 - val_acc: 0.6098 - val_f1: 0.6007 - val_precision_measure: 0.6167 - val_recall_measure: 0.5874\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 177s 586us/step - loss: 0.3746 - acc: 0.7851 - f1: 0.7828 - precision_measure: 0.7917 - recall_measure: 0.7742 - val_loss: 0.5240 - val_acc: 0.8080 - val_f1: 0.8050 - val_precision_measure: 0.8113 - val_recall_measure: 0.7992\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.3252 - acc: 0.8187 - f1: 0.8176 - precision_measure: 0.8239 - recall_measure: 0.8114 - val_loss: 0.6868 - val_acc: 0.6911 - val_f1: 0.6896 - val_precision_measure: 0.6935 - val_recall_measure: 0.6861\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 177s 585us/step - loss: 0.2938 - acc: 0.8383 - f1: 0.8374 - precision_measure: 0.8423 - recall_measure: 0.8326 - val_loss: 0.4754 - val_acc: 0.8213 - val_f1: 0.8202 - val_precision_measure: 0.8227 - val_recall_measure: 0.8178\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 180s 596us/step - loss: 0.2699 - acc: 0.8521 - f1: 0.8516 - precision_measure: 0.8552 - recall_measure: 0.8480 - val_loss: 0.6873 - val_acc: 0.7506 - val_f1: 0.7502 - val_precision_measure: 0.7519 - val_recall_measure: 0.7487\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 594us/step - loss: 0.2505 - acc: 0.8625 - f1: 0.8623 - precision_measure: 0.8649 - recall_measure: 0.8596 - val_loss: 0.4776 - val_acc: 0.8122 - val_f1: 0.8118 - val_precision_measure: 0.8146 - val_recall_measure: 0.8092\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 178s 589us/step - loss: 0.2326 - acc: 0.8716 - f1: 0.8713 - precision_measure: 0.8733 - recall_measure: 0.8694 - val_loss: 0.4425 - val_acc: 0.8346 - val_f1: 0.8344 - val_precision_measure: 0.8363 - val_recall_measure: 0.8327\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 188s 622us/step - loss: 0.2200 - acc: 0.8806 - f1: 0.8804 - precision_measure: 0.8820 - recall_measure: 0.8788 - val_loss: 0.6309 - val_acc: 0.7580 - val_f1: 0.7575 - val_precision_measure: 0.7584 - val_recall_measure: 0.7566\n",
      "33762/33762 [==============================] - 7s 208us/step\n",
      "Fitting  28 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 181s 601us/step - loss: 0.5797 - acc: 0.6095 - f1: 0.5784 - precision_measure: 0.6261 - recall_measure: 0.5517 - val_loss: 0.8433 - val_acc: 0.5708 - val_f1: 0.5503 - val_precision_measure: 0.5727 - val_recall_measure: 0.5326\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 182s 603us/step - loss: 0.3772 - acc: 0.7672 - f1: 0.7641 - precision_measure: 0.7733 - recall_measure: 0.7552 - val_loss: 0.8040 - val_acc: 0.6046 - val_f1: 0.6029 - val_precision_measure: 0.6064 - val_recall_measure: 0.5997\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 179s 592us/step - loss: 0.3234 - acc: 0.8167 - f1: 0.8157 - precision_measure: 0.8210 - recall_measure: 0.8104 - val_loss: 0.4420 - val_acc: 0.8572 - val_f1: 0.8560 - val_precision_measure: 0.8602 - val_recall_measure: 0.8523\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 179s 593us/step - loss: 0.2867 - acc: 0.8402 - f1: 0.8395 - precision_measure: 0.8434 - recall_measure: 0.8358 - val_loss: 0.2966 - val_acc: 0.9071 - val_f1: 0.9068 - val_precision_measure: 0.9082 - val_recall_measure: 0.9054\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 181s 602us/step - loss: 0.2658 - acc: 0.8522 - f1: 0.8518 - precision_measure: 0.8549 - recall_measure: 0.8488 - val_loss: 0.4301 - val_acc: 0.8459 - val_f1: 0.8455 - val_precision_measure: 0.8467 - val_recall_measure: 0.8444\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 594us/step - loss: 0.2499 - acc: 0.8633 - f1: 0.8631 - precision_measure: 0.8654 - recall_measure: 0.8608 - val_loss: 0.4817 - val_acc: 0.8267 - val_f1: 0.8253 - val_precision_measure: 0.8327 - val_recall_measure: 0.8186\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 180s 596us/step - loss: 0.2278 - acc: 0.8749 - f1: 0.8748 - precision_measure: 0.8765 - recall_measure: 0.8731 - val_loss: 0.3865 - val_acc: 0.8678 - val_f1: 0.8675 - val_precision_measure: 0.8688 - val_recall_measure: 0.8663\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 183s 606us/step - loss: 0.2181 - acc: 0.8827 - f1: 0.8827 - precision_measure: 0.8841 - recall_measure: 0.8813 - val_loss: 0.4185 - val_acc: 0.8510 - val_f1: 0.8508 - val_precision_measure: 0.8517 - val_recall_measure: 0.8500\n",
      "33762/33762 [==============================] - 7s 221us/step\n",
      "Fitting  29 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 179s 594us/step - loss: 0.5772 - acc: 0.6085 - f1: 0.5768 - precision_measure: 0.6249 - recall_measure: 0.5487 - val_loss: 0.8395 - val_acc: 0.6016 - val_f1: 0.5947 - val_precision_measure: 0.6028 - val_recall_measure: 0.5876\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 178s 590us/step - loss: 0.3867 - acc: 0.7468 - f1: 0.7437 - precision_measure: 0.7535 - recall_measure: 0.7343 - val_loss: 0.7293 - val_acc: 0.6166 - val_f1: 0.6114 - val_precision_measure: 0.6185 - val_recall_measure: 0.6051\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 177s 586us/step - loss: 0.3346 - acc: 0.8009 - f1: 0.7997 - precision_measure: 0.8066 - recall_measure: 0.7931 - val_loss: 0.5619 - val_acc: 0.7627 - val_f1: 0.7574 - val_precision_measure: 0.7673 - val_recall_measure: 0.7487\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 177s 587us/step - loss: 0.2985 - acc: 0.8260 - f1: 0.8251 - precision_measure: 0.8301 - recall_measure: 0.8202 - val_loss: 0.4674 - val_acc: 0.8166 - val_f1: 0.8157 - val_precision_measure: 0.8181 - val_recall_measure: 0.8135\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 178s 591us/step - loss: 0.2703 - acc: 0.8426 - f1: 0.8421 - precision_measure: 0.8454 - recall_measure: 0.8390 - val_loss: 0.7005 - val_acc: 0.7038 - val_f1: 0.7023 - val_precision_measure: 0.7060 - val_recall_measure: 0.6988\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 177s 587us/step - loss: 0.2517 - acc: 0.8554 - f1: 0.8550 - precision_measure: 0.8577 - recall_measure: 0.8523 - val_loss: 0.5449 - val_acc: 0.7725 - val_f1: 0.7718 - val_precision_measure: 0.7745 - val_recall_measure: 0.7692\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 182s 604us/step - loss: 0.2388 - acc: 0.8623 - f1: 0.8621 - precision_measure: 0.8642 - recall_measure: 0.8601 - val_loss: 0.4038 - val_acc: 0.8394 - val_f1: 0.8390 - val_precision_measure: 0.8409 - val_recall_measure: 0.8372\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.2200 - acc: 0.8719 - f1: 0.8718 - precision_measure: 0.8734 - recall_measure: 0.8701 - val_loss: 0.3738 - val_acc: 0.8605 - val_f1: 0.8604 - val_precision_measure: 0.8615 - val_recall_measure: 0.8593\n",
      "33762/33762 [==============================] - 7s 218us/step\n",
      "Fitting  30 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 187s 621us/step - loss: 0.5512 - acc: 0.6553 - f1: 0.6315 - precision_measure: 0.6732 - recall_measure: 0.6058 - val_loss: 1.1003 - val_acc: 0.4542 - val_f1: 0.4509 - val_precision_measure: 0.4550 - val_recall_measure: 0.4472\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.3681 - acc: 0.7842 - f1: 0.7817 - precision_measure: 0.7900 - recall_measure: 0.7737 - val_loss: 0.7119 - val_acc: 0.6624 - val_f1: 0.6591 - val_precision_measure: 0.6635 - val_recall_measure: 0.6551\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 190s 631us/step - loss: 0.3216 - acc: 0.8137 - f1: 0.8123 - precision_measure: 0.8181 - recall_measure: 0.8066 - val_loss: 0.7276 - val_acc: 0.6614 - val_f1: 0.6593 - val_precision_measure: 0.6634 - val_recall_measure: 0.6556\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 194s 644us/step - loss: 0.2924 - acc: 0.8324 - f1: 0.8318 - precision_measure: 0.8364 - recall_measure: 0.8273 - val_loss: 0.4356 - val_acc: 0.8348 - val_f1: 0.8340 - val_precision_measure: 0.8364 - val_recall_measure: 0.8317\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 197s 653us/step - loss: 0.2720 - acc: 0.8439 - f1: 0.8435 - precision_measure: 0.8470 - recall_measure: 0.8400 - val_loss: 0.3413 - val_acc: 0.8977 - val_f1: 0.8966 - val_precision_measure: 0.8987 - val_recall_measure: 0.8946\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 194s 642us/step - loss: 0.2533 - acc: 0.8544 - f1: 0.8541 - precision_measure: 0.8568 - recall_measure: 0.8516 - val_loss: 0.6720 - val_acc: 0.7168 - val_f1: 0.7160 - val_precision_measure: 0.7174 - val_recall_measure: 0.7147\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 196s 651us/step - loss: 0.2357 - acc: 0.8657 - f1: 0.8654 - precision_measure: 0.8676 - recall_measure: 0.8633 - val_loss: 0.3749 - val_acc: 0.8609 - val_f1: 0.8605 - val_precision_measure: 0.8620 - val_recall_measure: 0.8591\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 198s 656us/step - loss: 0.2246 - acc: 0.8744 - f1: 0.8742 - precision_measure: 0.8761 - recall_measure: 0.8723 - val_loss: 0.4791 - val_acc: 0.8179 - val_f1: 0.8168 - val_precision_measure: 0.8193 - val_recall_measure: 0.8143\n",
      "33762/33762 [==============================] - 9s 272us/step\n",
      "Fitting  31 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 202s 670us/step - loss: 0.5285 - acc: 0.6741 - f1: 0.6480 - precision_measure: 0.6889 - recall_measure: 0.6246 - val_loss: 0.6498 - val_acc: 0.6960 - val_f1: 0.6915 - val_precision_measure: 0.6981 - val_recall_measure: 0.6857\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 201s 666us/step - loss: 0.3449 - acc: 0.7990 - f1: 0.7970 - precision_measure: 0.8044 - recall_measure: 0.7898 - val_loss: 0.4029 - val_acc: 0.8497 - val_f1: 0.8482 - val_precision_measure: 0.8510 - val_recall_measure: 0.8456\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 200s 664us/step - loss: 0.2894 - acc: 0.8375 - f1: 0.8369 - precision_measure: 0.8412 - recall_measure: 0.8328 - val_loss: 0.4079 - val_acc: 0.8549 - val_f1: 0.8545 - val_precision_measure: 0.8571 - val_recall_measure: 0.8521\n",
      "Epoch 4/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 180s 595us/step - loss: 0.2679 - acc: 0.8514 - f1: 0.8509 - precision_measure: 0.8543 - recall_measure: 0.8477 - val_loss: 0.5444 - val_acc: 0.7842 - val_f1: 0.7840 - val_precision_measure: 0.7858 - val_recall_measure: 0.7822\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 183s 605us/step - loss: 0.2489 - acc: 0.8633 - f1: 0.8631 - precision_measure: 0.8656 - recall_measure: 0.8606 - val_loss: 0.4242 - val_acc: 0.8474 - val_f1: 0.8474 - val_precision_measure: 0.8482 - val_recall_measure: 0.8467\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 179s 594us/step - loss: 0.2347 - acc: 0.8705 - f1: 0.8704 - precision_measure: 0.8725 - recall_measure: 0.8683 - val_loss: 0.3644 - val_acc: 0.8691 - val_f1: 0.8684 - val_precision_measure: 0.8704 - val_recall_measure: 0.8666\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 182s 603us/step - loss: 0.2181 - acc: 0.8798 - f1: 0.8796 - precision_measure: 0.8811 - recall_measure: 0.8782 - val_loss: 0.4183 - val_acc: 0.8468 - val_f1: 0.8465 - val_precision_measure: 0.8476 - val_recall_measure: 0.8455\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 200s 663us/step - loss: 0.2071 - acc: 0.8862 - f1: 0.8861 - precision_measure: 0.8873 - recall_measure: 0.8850 - val_loss: 0.4743 - val_acc: 0.8182 - val_f1: 0.8178 - val_precision_measure: 0.8190 - val_recall_measure: 0.8166\n",
      "33762/33762 [==============================] - 8s 235us/step\n",
      "Fitting  32 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 199s 659us/step - loss: 0.5174 - acc: 0.6854 - f1: 0.6639 - precision_measure: 0.7004 - recall_measure: 0.6421 - val_loss: 0.6151 - val_acc: 0.7089 - val_f1: 0.7020 - val_precision_measure: 0.7131 - val_recall_measure: 0.6923\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 194s 642us/step - loss: 0.3387 - acc: 0.8035 - f1: 0.8021 - precision_measure: 0.8095 - recall_measure: 0.7949 - val_loss: 0.4648 - val_acc: 0.8399 - val_f1: 0.8377 - val_precision_measure: 0.8464 - val_recall_measure: 0.8300\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 192s 637us/step - loss: 0.2957 - acc: 0.8309 - f1: 0.8303 - precision_measure: 0.8353 - recall_measure: 0.8254 - val_loss: 0.6795 - val_acc: 0.6997 - val_f1: 0.6973 - val_precision_measure: 0.7012 - val_recall_measure: 0.6936\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 192s 636us/step - loss: 0.2668 - acc: 0.8483 - f1: 0.8480 - precision_measure: 0.8512 - recall_measure: 0.8447 - val_loss: 0.4502 - val_acc: 0.8179 - val_f1: 0.8170 - val_precision_measure: 0.8203 - val_recall_measure: 0.8140\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 202s 669us/step - loss: 0.2420 - acc: 0.8614 - f1: 0.8610 - precision_measure: 0.8635 - recall_measure: 0.8585 - val_loss: 0.8288 - val_acc: 0.6585 - val_f1: 0.6561 - val_precision_measure: 0.6612 - val_recall_measure: 0.6515\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 206s 683us/step - loss: 0.2267 - acc: 0.8704 - f1: 0.8703 - precision_measure: 0.8723 - recall_measure: 0.8684 - val_loss: 0.5035 - val_acc: 0.7962 - val_f1: 0.7958 - val_precision_measure: 0.7971 - val_recall_measure: 0.7946\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 194s 643us/step - loss: 0.2069 - acc: 0.8840 - f1: 0.8839 - precision_measure: 0.8854 - recall_measure: 0.8825 - val_loss: 0.4885 - val_acc: 0.8315 - val_f1: 0.8298 - val_precision_measure: 0.8350 - val_recall_measure: 0.8250\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 200s 661us/step - loss: 0.1950 - acc: 0.8916 - f1: 0.8915 - precision_measure: 0.8927 - recall_measure: 0.8903 - val_loss: 0.4311 - val_acc: 0.8303 - val_f1: 0.8293 - val_precision_measure: 0.8321 - val_recall_measure: 0.8266\n",
      "33762/33762 [==============================] - 8s 232us/step\n",
      "Fitting  33 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 203s 673us/step - loss: 1.0381 - acc: 0.4908 - f1: 0.3265 - precision_measure: 0.5547 - recall_measure: 0.2579 - val_loss: 0.8786 - val_acc: 0.3037 - val_f1: 0.2721 - val_precision_measure: 0.3007 - val_recall_measure: 0.2567\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 194s 642us/step - loss: 0.6043 - acc: 0.5334 - f1: 0.4986 - precision_measure: 0.5360 - recall_measure: 0.4673 - val_loss: 0.8909 - val_acc: 0.4783 - val_f1: 0.4518 - val_precision_measure: 0.4789 - val_recall_measure: 0.4327\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 200s 663us/step - loss: 0.5485 - acc: 0.6154 - f1: 0.5961 - precision_measure: 0.6205 - recall_measure: 0.5742 - val_loss: 0.9470 - val_acc: 0.4166 - val_f1: 0.3972 - val_precision_measure: 0.4149 - val_recall_measure: 0.3835\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 206s 684us/step - loss: 0.5154 - acc: 0.6488 - f1: 0.6354 - precision_measure: 0.6550 - recall_measure: 0.6174 - val_loss: 0.8960 - val_acc: 0.4232 - val_f1: 0.4161 - val_precision_measure: 0.4225 - val_recall_measure: 0.4106\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 191s 632us/step - loss: 0.4866 - acc: 0.6827 - f1: 0.6732 - precision_measure: 0.6897 - recall_measure: 0.6577 - val_loss: 0.9758 - val_acc: 0.4480 - val_f1: 0.4384 - val_precision_measure: 0.4483 - val_recall_measure: 0.4300\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 196s 650us/step - loss: 0.4711 - acc: 0.6982 - f1: 0.6903 - precision_measure: 0.7060 - recall_measure: 0.6757 - val_loss: 0.9371 - val_acc: 0.4664 - val_f1: 0.4518 - val_precision_measure: 0.4680 - val_recall_measure: 0.4392\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 195s 646us/step - loss: 0.4499 - acc: 0.7174 - f1: 0.7114 - precision_measure: 0.7252 - recall_measure: 0.6985 - val_loss: 0.7840 - val_acc: 0.5283 - val_f1: 0.5191 - val_precision_measure: 0.5284 - val_recall_measure: 0.5111\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 194s 642us/step - loss: 0.4252 - acc: 0.7382 - f1: 0.7336 - precision_measure: 0.7456 - recall_measure: 0.7222 - val_loss: 0.6995 - val_acc: 0.5836 - val_f1: 0.5776 - val_precision_measure: 0.5843 - val_recall_measure: 0.5716\n",
      "33762/33762 [==============================] - 9s 257us/step\n",
      "Fitting  34 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 207s 688us/step - loss: 0.9607 - acc: 0.4707 - f1: 0.3210 - precision_measure: 0.5196 - recall_measure: 0.2604 - val_loss: 0.9451 - val_acc: 0.2857 - val_f1: 0.2261 - val_precision_measure: 0.2797 - val_recall_measure: 0.2052\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 195s 647us/step - loss: 0.6091 - acc: 0.4658 - f1: 0.4230 - precision_measure: 0.4632 - recall_measure: 0.3910 - val_loss: 0.8222 - val_acc: 0.3690 - val_f1: 0.3450 - val_precision_measure: 0.3667 - val_recall_measure: 0.3304\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 198s 655us/step - loss: 0.5633 - acc: 0.5563 - f1: 0.5303 - precision_measure: 0.5581 - recall_measure: 0.5060 - val_loss: 0.7376 - val_acc: 0.4858 - val_f1: 0.4774 - val_precision_measure: 0.4867 - val_recall_measure: 0.4694\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 206s 682us/step - loss: 0.5260 - acc: 0.5990 - f1: 0.5831 - precision_measure: 0.6037 - recall_measure: 0.5643 - val_loss: 0.7990 - val_acc: 0.4891 - val_f1: 0.4709 - val_precision_measure: 0.4864 - val_recall_measure: 0.4579\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 214s 709us/step - loss: 0.5035 - acc: 0.6398 - f1: 0.6293 - precision_measure: 0.6463 - recall_measure: 0.6136 - val_loss: 0.7632 - val_acc: 0.5088 - val_f1: 0.4998 - val_precision_measure: 0.5087 - val_recall_measure: 0.4921\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 196s 651us/step - loss: 0.4989 - acc: 0.6197 - f1: 0.6078 - precision_measure: 0.6261 - recall_measure: 0.5911 - val_loss: 0.9073 - val_acc: 0.4395 - val_f1: 0.4325 - val_precision_measure: 0.4407 - val_recall_measure: 0.4257\n",
      "Epoch 7/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 195s 647us/step - loss: 0.4646 - acc: 0.6795 - f1: 0.6726 - precision_measure: 0.6863 - recall_measure: 0.6598 - val_loss: 0.8543 - val_acc: 0.4523 - val_f1: 0.4455 - val_precision_measure: 0.4531 - val_recall_measure: 0.4390\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 206s 684us/step - loss: 0.4502 - acc: 0.6905 - f1: 0.6839 - precision_measure: 0.6966 - recall_measure: 0.6720 - val_loss: 0.8500 - val_acc: 0.4607 - val_f1: 0.4561 - val_precision_measure: 0.4602 - val_recall_measure: 0.4524\n",
      "33762/33762 [==============================] - 10s 303us/step\n",
      "Fitting  35 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 236s 784us/step - loss: 0.9664 - acc: 0.4667 - f1: 0.3206 - precision_measure: 0.5116 - recall_measure: 0.2666 - val_loss: 0.8225 - val_acc: 0.3130 - val_f1: 0.2689 - val_precision_measure: 0.3215 - val_recall_measure: 0.2482\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 198s 656us/step - loss: 0.5963 - acc: 0.4664 - f1: 0.4308 - precision_measure: 0.4648 - recall_measure: 0.4027 - val_loss: 0.7680 - val_acc: 0.4685 - val_f1: 0.4581 - val_precision_measure: 0.4695 - val_recall_measure: 0.4484\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 193s 640us/step - loss: 0.5499 - acc: 0.5825 - f1: 0.5596 - precision_measure: 0.5847 - recall_measure: 0.5373 - val_loss: 0.8198 - val_acc: 0.4938 - val_f1: 0.4630 - val_precision_measure: 0.4905 - val_recall_measure: 0.4420\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 195s 645us/step - loss: 0.5281 - acc: 0.6190 - f1: 0.6016 - precision_measure: 0.6232 - recall_measure: 0.5821 - val_loss: 0.8320 - val_acc: 0.5092 - val_f1: 0.4864 - val_precision_measure: 0.5070 - val_recall_measure: 0.4709\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 193s 641us/step - loss: 0.4964 - acc: 0.6603 - f1: 0.6486 - precision_measure: 0.6669 - recall_measure: 0.6317 - val_loss: 0.8145 - val_acc: 0.5690 - val_f1: 0.5575 - val_precision_measure: 0.5711 - val_recall_measure: 0.5460\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 193s 640us/step - loss: 0.4730 - acc: 0.6925 - f1: 0.6841 - precision_measure: 0.7006 - recall_measure: 0.6689 - val_loss: 0.8687 - val_acc: 0.5082 - val_f1: 0.4861 - val_precision_measure: 0.5096 - val_recall_measure: 0.4678\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 194s 645us/step - loss: 0.4511 - acc: 0.7078 - f1: 0.7019 - precision_measure: 0.7157 - recall_measure: 0.6888 - val_loss: 0.7977 - val_acc: 0.5799 - val_f1: 0.5749 - val_precision_measure: 0.5802 - val_recall_measure: 0.5702\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 201s 665us/step - loss: 0.4384 - acc: 0.7179 - f1: 0.7123 - precision_measure: 0.7248 - recall_measure: 0.7004 - val_loss: 0.8568 - val_acc: 0.5081 - val_f1: 0.4959 - val_precision_measure: 0.5059 - val_recall_measure: 0.4873\n",
      "33762/33762 [==============================] - 10s 300us/step\n",
      "Fitting  36 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 196s 650us/step - loss: 1.0028 - acc: 0.4969 - f1: 0.3566 - precision_measure: 0.5657 - recall_measure: 0.2936 - val_loss: 1.0169 - val_acc: 0.2809 - val_f1: 0.2697 - val_precision_measure: 0.2818 - val_recall_measure: 0.2612\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 195s 645us/step - loss: 0.6122 - acc: 0.4626 - f1: 0.4382 - precision_measure: 0.4756 - recall_measure: 0.4075 - val_loss: 0.8219 - val_acc: 0.3022 - val_f1: 0.2914 - val_precision_measure: 0.2990 - val_recall_measure: 0.2851\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 195s 647us/step - loss: 0.5529 - acc: 0.5076 - f1: 0.4738 - precision_measure: 0.5033 - recall_measure: 0.4484 - val_loss: 0.7825 - val_acc: 0.4571 - val_f1: 0.4237 - val_precision_measure: 0.4499 - val_recall_measure: 0.4049\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 193s 639us/step - loss: 0.5199 - acc: 0.5996 - f1: 0.5828 - precision_measure: 0.6020 - recall_measure: 0.5654 - val_loss: 0.7960 - val_acc: 0.7929 - val_f1: 0.7590 - val_precision_measure: 0.8019 - val_recall_measure: 0.7257\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 194s 642us/step - loss: 0.4873 - acc: 0.6715 - f1: 0.6612 - precision_measure: 0.6771 - recall_measure: 0.6463 - val_loss: 0.7686 - val_acc: 0.5733 - val_f1: 0.5671 - val_precision_measure: 0.5754 - val_recall_measure: 0.5597\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 192s 637us/step - loss: 0.4563 - acc: 0.7173 - f1: 0.7112 - precision_measure: 0.7241 - recall_measure: 0.6991 - val_loss: 0.7678 - val_acc: 0.5563 - val_f1: 0.5542 - val_precision_measure: 0.5590 - val_recall_measure: 0.5498\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 195s 645us/step - loss: 0.4468 - acc: 0.7253 - f1: 0.7194 - precision_measure: 0.7330 - recall_measure: 0.7067 - val_loss: 0.6618 - val_acc: 0.5863 - val_f1: 0.5835 - val_precision_measure: 0.5871 - val_recall_measure: 0.5803\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 191s 635us/step - loss: 0.4249 - acc: 0.7552 - f1: 0.7508 - precision_measure: 0.7615 - recall_measure: 0.7406 - val_loss: 0.8127 - val_acc: 0.5165 - val_f1: 0.5132 - val_precision_measure: 0.5167 - val_recall_measure: 0.5098\n",
      "33762/33762 [==============================] - 9s 264us/step\n",
      "Fitting  37 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 256s 847us/step - loss: 0.8585 - acc: 0.4734 - f1: 0.3646 - precision_measure: 0.5061 - recall_measure: 0.3143 - val_loss: 0.8464 - val_acc: 0.3324 - val_f1: 0.2937 - val_precision_measure: 0.3383 - val_recall_measure: 0.2738\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 197s 655us/step - loss: 0.5631 - acc: 0.5172 - f1: 0.4847 - precision_measure: 0.5206 - recall_measure: 0.4549 - val_loss: 0.7856 - val_acc: 0.5611 - val_f1: 0.5416 - val_precision_measure: 0.5629 - val_recall_measure: 0.5249\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 241s 799us/step - loss: 0.5121 - acc: 0.6272 - f1: 0.6108 - precision_measure: 0.6348 - recall_measure: 0.5891 - val_loss: 0.9142 - val_acc: 0.5419 - val_f1: 0.5120 - val_precision_measure: 0.5425 - val_recall_measure: 0.4896\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 382s 1ms/step - loss: 0.4810 - acc: 0.6608 - f1: 0.6495 - precision_measure: 0.6678 - recall_measure: 0.6325 - val_loss: 0.8342 - val_acc: 0.5417 - val_f1: 0.5299 - val_precision_measure: 0.5411 - val_recall_measure: 0.5204\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 380s 1ms/step - loss: 0.4541 - acc: 0.6884 - f1: 0.6802 - precision_measure: 0.6956 - recall_measure: 0.6658 - val_loss: 0.7301 - val_acc: 0.5242 - val_f1: 0.5132 - val_precision_measure: 0.5228 - val_recall_measure: 0.5055\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 299s 990us/step - loss: 0.4468 - acc: 0.6822 - f1: 0.6740 - precision_measure: 0.6874 - recall_measure: 0.6615 - val_loss: 0.7209 - val_acc: 0.6374 - val_f1: 0.6284 - val_precision_measure: 0.6416 - val_recall_measure: 0.6170\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 272s 902us/step - loss: 0.4206 - acc: 0.7263 - f1: 0.7210 - precision_measure: 0.7324 - recall_measure: 0.7101 - val_loss: 0.5980 - val_acc: 0.6988 - val_f1: 0.6954 - val_precision_measure: 0.7008 - val_recall_measure: 0.6903\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 256s 847us/step - loss: 0.3985 - acc: 0.7545 - f1: 0.7502 - precision_measure: 0.7603 - recall_measure: 0.7404 - val_loss: 0.6897 - val_acc: 0.6683 - val_f1: 0.6590 - val_precision_measure: 0.6698 - val_recall_measure: 0.6494\n",
      "33762/33762 [==============================] - 29s 868us/step\n",
      "Fitting  38 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 317s 1ms/step - loss: 0.8568 - acc: 0.4755 - f1: 0.3420 - precision_measure: 0.4979 - recall_measure: 0.2927 - val_loss: 0.8089 - val_acc: 0.4082 - val_f1: 0.2909 - val_precision_measure: 0.3752 - val_recall_measure: 0.2600\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 190s 630us/step - loss: 0.5365 - acc: 0.5880 - f1: 0.5643 - precision_measure: 0.5937 - recall_measure: 0.5388 - val_loss: 0.9324 - val_acc: 0.5062 - val_f1: 0.4801 - val_precision_measure: 0.4998 - val_recall_measure: 0.4646\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 177s 588us/step - loss: 0.4832 - acc: 0.6912 - f1: 0.6819 - precision_measure: 0.6993 - recall_measure: 0.6657 - val_loss: 0.7317 - val_acc: 0.6092 - val_f1: 0.6010 - val_precision_measure: 0.6084 - val_recall_measure: 0.5945\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 182s 604us/step - loss: 0.4399 - acc: 0.7358 - f1: 0.7306 - precision_measure: 0.7445 - recall_measure: 0.7175 - val_loss: 0.7159 - val_acc: 0.5933 - val_f1: 0.5871 - val_precision_measure: 0.5934 - val_recall_measure: 0.5816\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 205s 681us/step - loss: 0.4169 - acc: 0.7623 - f1: 0.7583 - precision_measure: 0.7707 - recall_measure: 0.7465 - val_loss: 0.6946 - val_acc: 0.6384 - val_f1: 0.6347 - val_precision_measure: 0.6396 - val_recall_measure: 0.6303\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 384s 1ms/step - loss: 0.3930 - acc: 0.7829 - f1: 0.7793 - precision_measure: 0.7895 - recall_measure: 0.7696 - val_loss: 0.6212 - val_acc: 0.7097 - val_f1: 0.7049 - val_precision_measure: 0.7107 - val_recall_measure: 0.6996\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 253s 839us/step - loss: 0.3881 - acc: 0.7936 - f1: 0.7910 - precision_measure: 0.7996 - recall_measure: 0.7829 - val_loss: 0.6087 - val_acc: 0.7618 - val_f1: 0.7482 - val_precision_measure: 0.7665 - val_recall_measure: 0.7322\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 192s 637us/step - loss: 0.3582 - acc: 0.8064 - f1: 0.8041 - precision_measure: 0.8119 - recall_measure: 0.7967 - val_loss: 0.5338 - val_acc: 0.7690 - val_f1: 0.7664 - val_precision_measure: 0.7700 - val_recall_measure: 0.7629\n",
      "33762/33762 [==============================] - 12s 367us/step\n",
      "Fitting  39 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 211s 701us/step - loss: 0.7900 - acc: 0.4866 - f1: 0.3839 - precision_measure: 0.5156 - recall_measure: 0.3361 - val_loss: 0.6578 - val_acc: 0.8443 - val_f1: 0.8280 - val_precision_measure: 0.8545 - val_recall_measure: 0.8072\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 191s 633us/step - loss: 0.5350 - acc: 0.5409 - f1: 0.5126 - precision_measure: 0.5438 - recall_measure: 0.4859 - val_loss: 0.6992 - val_acc: 0.5189 - val_f1: 0.5095 - val_precision_measure: 0.5212 - val_recall_measure: 0.4996\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 193s 639us/step - loss: 0.4922 - acc: 0.6284 - f1: 0.6142 - precision_measure: 0.6352 - recall_measure: 0.5950 - val_loss: 0.7931 - val_acc: 0.5241 - val_f1: 0.5200 - val_precision_measure: 0.5244 - val_recall_measure: 0.5161\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 189s 627us/step - loss: 0.4575 - acc: 0.6917 - f1: 0.6842 - precision_measure: 0.6995 - recall_measure: 0.6698 - val_loss: 0.7219 - val_acc: 0.5798 - val_f1: 0.5762 - val_precision_measure: 0.5800 - val_recall_measure: 0.5727\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 193s 641us/step - loss: 0.4305 - acc: 0.7302 - f1: 0.7253 - precision_measure: 0.7383 - recall_measure: 0.7130 - val_loss: 0.7658 - val_acc: 0.5535 - val_f1: 0.5486 - val_precision_measure: 0.5537 - val_recall_measure: 0.5440\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 301s 999us/step - loss: 0.4017 - acc: 0.7574 - f1: 0.7536 - precision_measure: 0.7650 - recall_measure: 0.7426 - val_loss: 0.8943 - val_acc: 0.5130 - val_f1: 0.5082 - val_precision_measure: 0.5150 - val_recall_measure: 0.5022\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 416s 1ms/step - loss: 0.3833 - acc: 0.7783 - f1: 0.7754 - precision_measure: 0.7854 - recall_measure: 0.7658 - val_loss: 0.6824 - val_acc: 0.6373 - val_f1: 0.6349 - val_precision_measure: 0.6384 - val_recall_measure: 0.6317\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 291s 964us/step - loss: 0.3687 - acc: 0.7935 - f1: 0.7911 - precision_measure: 0.7994 - recall_measure: 0.7831 - val_loss: 0.6722 - val_acc: 0.6742 - val_f1: 0.6700 - val_precision_measure: 0.6750 - val_recall_measure: 0.6655\n",
      "33762/33762 [==============================] - 13s 376us/step\n",
      "Fitting  40 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 288s 956us/step - loss: 0.8784 - acc: 0.4756 - f1: 0.3612 - precision_measure: 0.5244 - recall_measure: 0.3061 - val_loss: 0.8145 - val_acc: 0.3049 - val_f1: 0.2906 - val_precision_measure: 0.3038 - val_recall_measure: 0.2805\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 181s 600us/step - loss: 0.5416 - acc: 0.5482 - f1: 0.5219 - precision_measure: 0.5510 - recall_measure: 0.4966 - val_loss: 0.7919 - val_acc: 0.5186 - val_f1: 0.5096 - val_precision_measure: 0.5189 - val_recall_measure: 0.5018\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 246s 814us/step - loss: 0.4812 - acc: 0.6657 - f1: 0.6558 - precision_measure: 0.6726 - recall_measure: 0.6403 - val_loss: 0.7203 - val_acc: 0.5695 - val_f1: 0.5646 - val_precision_measure: 0.5709 - val_recall_measure: 0.5591\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 182s 604us/step - loss: 0.4410 - acc: 0.7147 - f1: 0.7091 - precision_measure: 0.7222 - recall_measure: 0.6968 - val_loss: 0.6557 - val_acc: 0.6716 - val_f1: 0.6578 - val_precision_measure: 0.6713 - val_recall_measure: 0.6465\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 186s 617us/step - loss: 0.4152 - acc: 0.7487 - f1: 0.7445 - precision_measure: 0.7563 - recall_measure: 0.7334 - val_loss: 0.6789 - val_acc: 0.6389 - val_f1: 0.6320 - val_precision_measure: 0.6403 - val_recall_measure: 0.6248\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 226s 750us/step - loss: 0.3879 - acc: 0.7781 - f1: 0.7749 - precision_measure: 0.7846 - recall_measure: 0.7656 - val_loss: 0.7846 - val_acc: 0.6134 - val_f1: 0.6069 - val_precision_measure: 0.6152 - val_recall_measure: 0.5995\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 227s 752us/step - loss: 0.3662 - acc: 0.7927 - f1: 0.7906 - precision_measure: 0.7987 - recall_measure: 0.7829 - val_loss: 0.8076 - val_acc: 0.5796 - val_f1: 0.5745 - val_precision_measure: 0.5824 - val_recall_measure: 0.5679\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 224s 742us/step - loss: 0.3624 - acc: 0.8003 - f1: 0.7980 - precision_measure: 0.8054 - recall_measure: 0.7909 - val_loss: 0.4417 - val_acc: 0.8361 - val_f1: 0.8352 - val_precision_measure: 0.8380 - val_recall_measure: 0.8325\n",
      "33762/33762 [==============================] - 13s 398us/step\n",
      "Fitting  41 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 242s 802us/step - loss: 0.7515 - acc: 0.4734 - f1: 0.4080 - precision_measure: 0.5112 - recall_measure: 0.3636 - val_loss: 0.8810 - val_acc: 0.2823 - val_f1: 0.2740 - val_precision_measure: 0.2827 - val_recall_measure: 0.2675\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 209s 692us/step - loss: 0.5452 - acc: 0.4580 - f1: 0.4346 - precision_measure: 0.4653 - recall_measure: 0.4087 - val_loss: 0.8436 - val_acc: 0.2976 - val_f1: 0.2865 - val_precision_measure: 0.2942 - val_recall_measure: 0.2806\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 207s 688us/step - loss: 0.5177 - acc: 0.5048 - f1: 0.4746 - precision_measure: 0.5037 - recall_measure: 0.4496 - val_loss: 0.9269 - val_acc: 0.3111 - val_f1: 0.2949 - val_precision_measure: 0.3065 - val_recall_measure: 0.2865\n",
      "Epoch 4/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 273s 906us/step - loss: 0.4753 - acc: 0.6369 - f1: 0.6214 - precision_measure: 0.6409 - recall_measure: 0.6036 - val_loss: 0.7970 - val_acc: 0.5633 - val_f1: 0.5493 - val_precision_measure: 0.5611 - val_recall_measure: 0.5397\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 223s 741us/step - loss: 0.4388 - acc: 0.6903 - f1: 0.6828 - precision_measure: 0.6966 - recall_measure: 0.6698 - val_loss: 0.7217 - val_acc: 0.5997 - val_f1: 0.5930 - val_precision_measure: 0.5992 - val_recall_measure: 0.5877\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 238s 789us/step - loss: 0.4161 - acc: 0.7208 - f1: 0.7160 - precision_measure: 0.7275 - recall_measure: 0.7050 - val_loss: 0.7697 - val_acc: 0.5393 - val_f1: 0.5305 - val_precision_measure: 0.5384 - val_recall_measure: 0.5237\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 193s 641us/step - loss: 0.4013 - acc: 0.7342 - f1: 0.7285 - precision_measure: 0.7398 - recall_measure: 0.7178 - val_loss: 0.6100 - val_acc: 0.6772 - val_f1: 0.6741 - val_precision_measure: 0.6777 - val_recall_measure: 0.6708\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 222s 735us/step - loss: 0.3652 - acc: 0.7890 - f1: 0.7864 - precision_measure: 0.7949 - recall_measure: 0.7782 - val_loss: 0.8681 - val_acc: 0.7903 - val_f1: 0.7888 - val_precision_measure: 0.7949 - val_recall_measure: 0.7832\n",
      "33762/33762 [==============================] - 15s 437us/step\n",
      "Fitting  42 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 249s 826us/step - loss: 0.7475 - acc: 0.4709 - f1: 0.3903 - precision_measure: 0.5001 - recall_measure: 0.3472 - val_loss: 0.8065 - val_acc: 0.2955 - val_f1: 0.2769 - val_precision_measure: 0.2926 - val_recall_measure: 0.2656\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 266s 881us/step - loss: 0.5139 - acc: 0.5595 - f1: 0.5345 - precision_measure: 0.5613 - recall_measure: 0.5112 - val_loss: 0.7832 - val_acc: 0.5719 - val_f1: 0.5652 - val_precision_measure: 0.5730 - val_recall_measure: 0.5589\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 306s 1ms/step - loss: 0.4543 - acc: 0.7048 - f1: 0.6970 - precision_measure: 0.7127 - recall_measure: 0.6823 - val_loss: 0.7425 - val_acc: 0.6384 - val_f1: 0.6318 - val_precision_measure: 0.6386 - val_recall_measure: 0.6260\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 396s 1ms/step - loss: 0.4103 - acc: 0.7604 - f1: 0.7565 - precision_measure: 0.7675 - recall_measure: 0.7460 - val_loss: 0.7767 - val_acc: 0.6342 - val_f1: 0.6292 - val_precision_measure: 0.6357 - val_recall_measure: 0.6233\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 349s 1ms/step - loss: 0.3969 - acc: 0.7724 - f1: 0.7694 - precision_measure: 0.7803 - recall_measure: 0.7591 - val_loss: 0.5308 - val_acc: 0.8406 - val_f1: 0.8345 - val_precision_measure: 0.8460 - val_recall_measure: 0.8242\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 356s 1ms/step - loss: 0.3686 - acc: 0.7988 - f1: 0.7961 - precision_measure: 0.8055 - recall_measure: 0.7871 - val_loss: 0.8140 - val_acc: 0.5985 - val_f1: 0.5952 - val_precision_measure: 0.5997 - val_recall_measure: 0.5911\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 326s 1ms/step - loss: 0.3489 - acc: 0.8097 - f1: 0.8076 - precision_measure: 0.8155 - recall_measure: 0.8001 - val_loss: 0.6636 - val_acc: 0.6834 - val_f1: 0.6825 - val_precision_measure: 0.6850 - val_recall_measure: 0.6802\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 341s 1ms/step - loss: 0.3387 - acc: 0.8179 - f1: 0.8162 - precision_measure: 0.8230 - recall_measure: 0.8098 - val_loss: 0.5648 - val_acc: 0.7152 - val_f1: 0.7141 - val_precision_measure: 0.7166 - val_recall_measure: 0.7117\n",
      "33762/33762 [==============================] - 17s 509us/step\n",
      "Fitting  43 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 304s 1ms/step - loss: 0.7161 - acc: 0.4838 - f1: 0.4162 - precision_measure: 0.5084 - recall_measure: 0.3744 - val_loss: 0.7590 - val_acc: 0.3348 - val_f1: 0.3208 - val_precision_measure: 0.3344 - val_recall_measure: 0.3107\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 327s 1ms/step - loss: 0.5110 - acc: 0.5582 - f1: 0.5384 - precision_measure: 0.5645 - recall_measure: 0.5158 - val_loss: 0.8085 - val_acc: 0.4429 - val_f1: 0.4337 - val_precision_measure: 0.4414 - val_recall_measure: 0.4273\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 207s 685us/step - loss: 0.4427 - acc: 0.6983 - f1: 0.6905 - precision_measure: 0.7051 - recall_measure: 0.6768 - val_loss: 0.8769 - val_acc: 0.5199 - val_f1: 0.5139 - val_precision_measure: 0.5200 - val_recall_measure: 0.5085\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 201s 667us/step - loss: 0.4020 - acc: 0.7539 - f1: 0.7495 - precision_measure: 0.7599 - recall_measure: 0.7396 - val_loss: 0.5854 - val_acc: 0.7625 - val_f1: 0.7584 - val_precision_measure: 0.7666 - val_recall_measure: 0.7511\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 199s 659us/step - loss: 0.3741 - acc: 0.7861 - f1: 0.7835 - precision_measure: 0.7920 - recall_measure: 0.7754 - val_loss: 0.5960 - val_acc: 0.7232 - val_f1: 0.7185 - val_precision_measure: 0.7257 - val_recall_measure: 0.7119\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 200s 663us/step - loss: 0.3572 - acc: 0.8014 - f1: 0.7996 - precision_measure: 0.8073 - recall_measure: 0.7921 - val_loss: 0.6634 - val_acc: 0.6524 - val_f1: 0.6502 - val_precision_measure: 0.6532 - val_recall_measure: 0.6474\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 202s 670us/step - loss: 0.3408 - acc: 0.8136 - f1: 0.8118 - precision_measure: 0.8185 - recall_measure: 0.8054 - val_loss: 0.4554 - val_acc: 0.8277 - val_f1: 0.8264 - val_precision_measure: 0.8289 - val_recall_measure: 0.8241\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 197s 652us/step - loss: 0.3254 - acc: 0.8242 - f1: 0.8229 - precision_measure: 0.8289 - recall_measure: 0.8170 - val_loss: 0.6155 - val_acc: 0.7537 - val_f1: 0.7446 - val_precision_measure: 0.7589 - val_recall_measure: 0.7321\n",
      "33762/33762 [==============================] - 14s 422us/step\n",
      "Fitting  44 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 221s 732us/step - loss: 0.7498 - acc: 0.4812 - f1: 0.4058 - precision_measure: 0.5153 - recall_measure: 0.3595 - val_loss: 0.8322 - val_acc: 0.2828 - val_f1: 0.2663 - val_precision_measure: 0.2759 - val_recall_measure: 0.2590\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 204s 676us/step - loss: 0.5198 - acc: 0.5213 - f1: 0.4992 - precision_measure: 0.5258 - recall_measure: 0.4761 - val_loss: 0.7532 - val_acc: 0.5077 - val_f1: 0.4965 - val_precision_measure: 0.5083 - val_recall_measure: 0.4865\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 207s 685us/step - loss: 0.4575 - acc: 0.6789 - f1: 0.6689 - precision_measure: 0.6866 - recall_measure: 0.6527 - val_loss: 0.7045 - val_acc: 0.6246 - val_f1: 0.6133 - val_precision_measure: 0.6236 - val_recall_measure: 0.6047\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 209s 694us/step - loss: 0.4032 - acc: 0.7588 - f1: 0.7539 - precision_measure: 0.7663 - recall_measure: 0.7422 - val_loss: 0.6887 - val_acc: 0.6563 - val_f1: 0.6533 - val_precision_measure: 0.6568 - val_recall_measure: 0.6503\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 208s 689us/step - loss: 0.3712 - acc: 0.7957 - f1: 0.7928 - precision_measure: 0.8019 - recall_measure: 0.7840 - val_loss: 0.5944 - val_acc: 0.7138 - val_f1: 0.7097 - val_precision_measure: 0.7157 - val_recall_measure: 0.7043\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 209s 694us/step - loss: 0.3545 - acc: 0.8081 - f1: 0.8060 - precision_measure: 0.8142 - recall_measure: 0.7981 - val_loss: 0.4519 - val_acc: 0.8361 - val_f1: 0.8336 - val_precision_measure: 0.8383 - val_recall_measure: 0.8294\n",
      "Epoch 7/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 187s 618us/step - loss: 0.3357 - acc: 0.8178 - f1: 0.8161 - precision_measure: 0.8236 - recall_measure: 0.8089 - val_loss: 0.6734 - val_acc: 0.6873 - val_f1: 0.6848 - val_precision_measure: 0.6880 - val_recall_measure: 0.6817\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 183s 607us/step - loss: 0.3240 - acc: 0.8279 - f1: 0.8263 - precision_measure: 0.8330 - recall_measure: 0.8199 - val_loss: 0.4845 - val_acc: 0.8076 - val_f1: 0.8070 - val_precision_measure: 0.8085 - val_recall_measure: 0.8055\n",
      "33762/33762 [==============================] - 10s 293us/step\n",
      "Fitting  45 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 329s 1ms/step - loss: 0.7061 - acc: 0.4596 - f1: 0.3899 - precision_measure: 0.4773 - recall_measure: 0.3477 - val_loss: 0.8388 - val_acc: 0.2599 - val_f1: 0.2444 - val_precision_measure: 0.2595 - val_recall_measure: 0.2351\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 226s 748us/step - loss: 0.5195 - acc: 0.4695 - f1: 0.4333 - precision_measure: 0.4648 - recall_measure: 0.4073 - val_loss: 0.7992 - val_acc: 0.4536 - val_f1: 0.4319 - val_precision_measure: 0.4500 - val_recall_measure: 0.4174\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 195s 647us/step - loss: 0.4598 - acc: 0.6578 - f1: 0.6460 - precision_measure: 0.6630 - recall_measure: 0.6303 - val_loss: 0.7079 - val_acc: 0.5889 - val_f1: 0.5787 - val_precision_measure: 0.5879 - val_recall_measure: 0.5708\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 199s 661us/step - loss: 0.4170 - acc: 0.7416 - f1: 0.7360 - precision_measure: 0.7493 - recall_measure: 0.7235 - val_loss: 0.6811 - val_acc: 0.6342 - val_f1: 0.6299 - val_precision_measure: 0.6344 - val_recall_measure: 0.6258\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 196s 649us/step - loss: 0.3926 - acc: 0.7658 - f1: 0.7613 - precision_measure: 0.7727 - recall_measure: 0.7506 - val_loss: 0.5097 - val_acc: 0.7833 - val_f1: 0.7785 - val_precision_measure: 0.7891 - val_recall_measure: 0.7693\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 194s 642us/step - loss: 0.3675 - acc: 0.7929 - f1: 0.7899 - precision_measure: 0.7995 - recall_measure: 0.7806 - val_loss: 0.6179 - val_acc: 0.7197 - val_f1: 0.7176 - val_precision_measure: 0.7234 - val_recall_measure: 0.7125\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 196s 651us/step - loss: 0.3378 - acc: 0.8120 - f1: 0.8102 - precision_measure: 0.8181 - recall_measure: 0.8026 - val_loss: 0.3806 - val_acc: 0.8782 - val_f1: 0.8757 - val_precision_measure: 0.8804 - val_recall_measure: 0.8713\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 195s 646us/step - loss: 0.3342 - acc: 0.8162 - f1: 0.8144 - precision_measure: 0.8222 - recall_measure: 0.8069 - val_loss: 0.3367 - val_acc: 0.8727 - val_f1: 0.8717 - val_precision_measure: 0.8737 - val_recall_measure: 0.8698\n",
      "33762/33762 [==============================] - 12s 362us/step\n",
      "Fitting  46 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 211s 700us/step - loss: 0.6885 - acc: 0.4697 - f1: 0.4062 - precision_measure: 0.4826 - recall_measure: 0.3636 - val_loss: 0.8556 - val_acc: 0.3492 - val_f1: 0.2629 - val_precision_measure: 0.3182 - val_recall_measure: 0.2429\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 207s 688us/step - loss: 0.5039 - acc: 0.5965 - f1: 0.5708 - precision_measure: 0.5981 - recall_measure: 0.5470 - val_loss: 0.8066 - val_acc: 0.6125 - val_f1: 0.5885 - val_precision_measure: 0.6174 - val_recall_measure: 0.5666\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 213s 707us/step - loss: 0.4318 - acc: 0.7216 - f1: 0.7154 - precision_measure: 0.7280 - recall_measure: 0.7036 - val_loss: 0.6567 - val_acc: 0.6385 - val_f1: 0.6326 - val_precision_measure: 0.6392 - val_recall_measure: 0.6267\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 421s 1ms/step - loss: 0.3818 - acc: 0.7784 - f1: 0.7754 - precision_measure: 0.7844 - recall_measure: 0.7667 - val_loss: 0.5035 - val_acc: 0.7548 - val_f1: 0.7535 - val_precision_measure: 0.7573 - val_recall_measure: 0.7500\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 520s 2ms/step - loss: 0.3595 - acc: 0.8004 - f1: 0.7985 - precision_measure: 0.8059 - recall_measure: 0.7915 - val_loss: 0.4254 - val_acc: 0.8452 - val_f1: 0.8444 - val_precision_measure: 0.8474 - val_recall_measure: 0.8416\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 371s 1ms/step - loss: 0.3372 - acc: 0.8151 - f1: 0.8138 - precision_measure: 0.8206 - recall_measure: 0.8072 - val_loss: 0.6077 - val_acc: 0.6614 - val_f1: 0.6584 - val_precision_measure: 0.6626 - val_recall_measure: 0.6546\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 408s 1ms/step - loss: 0.3276 - acc: 0.8191 - f1: 0.8176 - precision_measure: 0.8239 - recall_measure: 0.8115 - val_loss: 0.4494 - val_acc: 0.8074 - val_f1: 0.8055 - val_precision_measure: 0.8090 - val_recall_measure: 0.8022\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 293s 971us/step - loss: 0.3291 - acc: 0.8166 - f1: 0.8149 - precision_measure: 0.8214 - recall_measure: 0.8088 - val_loss: 0.4124 - val_acc: 0.8494 - val_f1: 0.8482 - val_precision_measure: 0.8520 - val_recall_measure: 0.8447\n",
      "33762/33762 [==============================] - 30s 895us/step\n",
      "Fitting  47 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n",
      "301655/301655 [==============================] - 285s 944us/step - loss: 0.6535 - acc: 0.4993 - f1: 0.4480 - precision_measure: 0.5162 - recall_measure: 0.4089 - val_loss: 0.7920 - val_acc: 0.6711 - val_f1: 0.6410 - val_precision_measure: 0.6889 - val_recall_measure: 0.6090\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 241s 799us/step - loss: 0.4785 - acc: 0.6390 - f1: 0.6241 - precision_measure: 0.6487 - recall_measure: 0.6023 - val_loss: 0.9096 - val_acc: 0.5392 - val_f1: 0.5261 - val_precision_measure: 0.5374 - val_recall_measure: 0.5169\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 242s 802us/step - loss: 0.4038 - acc: 0.7634 - f1: 0.7584 - precision_measure: 0.7720 - recall_measure: 0.7455 - val_loss: 0.7842 - val_acc: 0.5655 - val_f1: 0.5575 - val_precision_measure: 0.5638 - val_recall_measure: 0.5520\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 395s 1ms/step - loss: 0.3654 - acc: 0.7953 - f1: 0.7925 - precision_measure: 0.8022 - recall_measure: 0.7832 - val_loss: 0.5164 - val_acc: 0.7838 - val_f1: 0.7820 - val_precision_measure: 0.7854 - val_recall_measure: 0.7787\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 219s 728us/step - loss: 0.3376 - acc: 0.8156 - f1: 0.8139 - precision_measure: 0.8212 - recall_measure: 0.8069 - val_loss: 0.4749 - val_acc: 0.7840 - val_f1: 0.7831 - val_precision_measure: 0.7855 - val_recall_measure: 0.7808\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 214s 711us/step - loss: 0.3281 - acc: 0.8239 - f1: 0.8224 - precision_measure: 0.8296 - recall_measure: 0.8155 - val_loss: 0.4784 - val_acc: 0.7995 - val_f1: 0.7984 - val_precision_measure: 0.8021 - val_recall_measure: 0.7950\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 207s 686us/step - loss: 0.3159 - acc: 0.8284 - f1: 0.8272 - precision_measure: 0.8336 - recall_measure: 0.8210 - val_loss: 0.4950 - val_acc: 0.8021 - val_f1: 0.8008 - val_precision_measure: 0.8056 - val_recall_measure: 0.7964\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 222s 735us/step - loss: 0.2973 - acc: 0.8380 - f1: 0.8371 - precision_measure: 0.8418 - recall_measure: 0.8325 - val_loss: 0.3739 - val_acc: 0.8564 - val_f1: 0.8558 - val_precision_measure: 0.8578 - val_recall_measure: 0.8540\n",
      "33762/33762 [==============================] - 16s 466us/step\n",
      "Fitting  48 / 48  model\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301655/301655 [==============================] - 302s 1ms/step - loss: 0.6530 - acc: 0.5406 - f1: 0.4850 - precision_measure: 0.5525 - recall_measure: 0.4463 - val_loss: 0.7665 - val_acc: 0.6180 - val_f1: 0.5966 - val_precision_measure: 0.6188 - val_recall_measure: 0.5787\n",
      "Epoch 2/8\n",
      "301655/301655 [==============================] - 275s 911us/step - loss: 0.4464 - acc: 0.7241 - f1: 0.7151 - precision_measure: 0.7324 - recall_measure: 0.6991 - val_loss: 0.5692 - val_acc: 0.7431 - val_f1: 0.7377 - val_precision_measure: 0.7444 - val_recall_measure: 0.7315\n",
      "Epoch 3/8\n",
      "301655/301655 [==============================] - 280s 929us/step - loss: 0.3809 - acc: 0.7920 - f1: 0.7889 - precision_measure: 0.7993 - recall_measure: 0.7789 - val_loss: 0.5787 - val_acc: 0.7232 - val_f1: 0.7181 - val_precision_measure: 0.7235 - val_recall_measure: 0.7132\n",
      "Epoch 4/8\n",
      "301655/301655 [==============================] - 307s 1ms/step - loss: 0.3489 - acc: 0.8112 - f1: 0.8095 - precision_measure: 0.8178 - recall_measure: 0.8015 - val_loss: 0.4751 - val_acc: 0.8083 - val_f1: 0.8064 - val_precision_measure: 0.8107 - val_recall_measure: 0.8023\n",
      "Epoch 5/8\n",
      "301655/301655 [==============================] - 225s 745us/step - loss: 0.3271 - acc: 0.8265 - f1: 0.8254 - precision_measure: 0.8322 - recall_measure: 0.8189 - val_loss: 0.4894 - val_acc: 0.8030 - val_f1: 0.8013 - val_precision_measure: 0.8069 - val_recall_measure: 0.7962\n",
      "Epoch 6/8\n",
      "301655/301655 [==============================] - 211s 701us/step - loss: 0.3154 - acc: 0.8336 - f1: 0.8327 - precision_measure: 0.8385 - recall_measure: 0.8271 - val_loss: 0.6348 - val_acc: 0.6877 - val_f1: 0.6867 - val_precision_measure: 0.6881 - val_recall_measure: 0.6852\n",
      "Epoch 7/8\n",
      "301655/301655 [==============================] - 208s 691us/step - loss: 0.2989 - acc: 0.8424 - f1: 0.8417 - precision_measure: 0.8465 - recall_measure: 0.8370 - val_loss: 0.4491 - val_acc: 0.8125 - val_f1: 0.8107 - val_precision_measure: 0.8152 - val_recall_measure: 0.8065\n",
      "Epoch 8/8\n",
      "301655/301655 [==============================] - 204s 675us/step - loss: 0.2930 - acc: 0.8421 - f1: 0.8411 - precision_measure: 0.8462 - recall_measure: 0.8361 - val_loss: 0.5924 - val_acc: 0.7920 - val_f1: 0.7873 - val_precision_measure: 0.7972 - val_recall_measure: 0.7783\n",
      "33762/33762 [==============================] - 15s 445us/step\n",
      "7\n",
      "0.8655490393539087\n",
      "<keras.callbacks.History object at 0x1307a0d90>\n"
     ]
    }
   ],
   "source": [
    "# Define the dropout grid\n",
    "dropout_grid = [0.1, 0.5, 0.9]\n",
    "l1_grid = [2**-5, 2**-6, 2**-7, 2**-8]\n",
    "l2_grid = [2**-5, 2**-6, 2**-7, 2**-8]\n",
    "tot = len(dropout_grid) * len(l1_grid) * len(l2_grid)\n",
    "\n",
    "# Variables for the best result\n",
    "scores = []\n",
    "best_history = [] # place holder\n",
    "best_ind = 0\n",
    "best_acc = 0\n",
    "\n",
    "# Loop through each combination\n",
    "pos = 0\n",
    "for ii in dropout_grid:\n",
    "    for jj in l1_grid:\n",
    "        for kk in l2_grid:\n",
    "            pos = pos + 1\n",
    "            print(\"Fitting \", pos, \"/\", tot , \" model\")\n",
    "            # define the model\n",
    "            curr_model = define_LSTM_model(ii, jj, kk)\n",
    "            #curr_model.summary()\n",
    "            \n",
    "            # train the model\n",
    "            curr_history = curr_model.fit(training_X, training_y_encoded, epochs = 8, batch_size = 64, \n",
    "                                     validation_data = (val_X, val_y_encoded), class_weight = label_weights, \n",
    "                                     verbose = 1)\n",
    "            curr_acc = st.mean(curr_history.history['val_acc'][5:10])\n",
    "                        \n",
    "            # get prediction report\n",
    "            y_pred = curr_model.predict(val_X, batch_size=64, verbose=1)\n",
    "            y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "            scores.append(classification_report(val_y, y_pred_bool))\n",
    "            \n",
    "            # save the best result\n",
    "            if best_acc < curr_acc:\n",
    "                best_acc = curr_acc\n",
    "                best_ind = pos - 1\n",
    "                best_history = curr_history\n",
    "\n",
    "# Display best best_ind, best_acc, and best_history\n",
    "print(best_ind)\n",
    "print(best_acc)\n",
    "print(best_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-dutch",
   "metadata": {},
   "source": [
    "The above hyperparamter search for this LSTM returns that index 7 is the best index combination of hyperparameters, returning an accuracy of 0.8655490393539087. The hyperparamters that correspond to this index are found in 'Fitting Model 8 / 48' (results are in log file). They are `dropout_rate` = 0.1, `l1` = 2e-6, `l2` = 2e-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dressed-polls",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_60 (LSTM)               (None, 125)               66000     \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 125)               15750     \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 4)                 504       \n",
      "=================================================================\n",
      "Total params: 82,254\n",
      "Trainable params: 82,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/15\n",
      "301655/301655 [==============================] - 314s 1ms/step - loss: 0.6236 - acc: 0.5876 - f1: 0.5467 - precision_measure: 0.6039 - recall_measure: 0.5168 - val_loss: 0.8067 - val_acc: 0.5714 - val_f1: 0.5557 - val_precision_measure: 0.5743 - val_recall_measure: 0.5406\n",
      "Epoch 2/15\n",
      "301655/301655 [==============================] - 214s 710us/step - loss: 0.3948 - acc: 0.7571 - f1: 0.7537 - precision_measure: 0.7635 - recall_measure: 0.7443 - val_loss: 0.5173 - val_acc: 0.8468 - val_f1: 0.8403 - val_precision_measure: 0.8533 - val_recall_measure: 0.8293\n",
      "Epoch 3/15\n",
      "301655/301655 [==============================] - 209s 693us/step - loss: 0.3339 - acc: 0.8098 - f1: 0.8086 - precision_measure: 0.8144 - recall_measure: 0.8030 - val_loss: 0.4779 - val_acc: 0.8300 - val_f1: 0.8288 - val_precision_measure: 0.8324 - val_recall_measure: 0.8255\n",
      "Epoch 4/15\n",
      "301655/301655 [==============================] - 212s 702us/step - loss: 0.2920 - acc: 0.8388 - f1: 0.8383 - precision_measure: 0.8417 - recall_measure: 0.8350 - val_loss: 0.5367 - val_acc: 0.7941 - val_f1: 0.7925 - val_precision_measure: 0.7964 - val_recall_measure: 0.7889\n",
      "Epoch 5/15\n",
      "301655/301655 [==============================] - 209s 693us/step - loss: 0.2636 - acc: 0.8583 - f1: 0.8581 - precision_measure: 0.8602 - recall_measure: 0.8560 - val_loss: 0.4313 - val_acc: 0.8495 - val_f1: 0.8484 - val_precision_measure: 0.8516 - val_recall_measure: 0.8454\n",
      "Epoch 6/15\n",
      "301655/301655 [==============================] - 207s 685us/step - loss: 0.2365 - acc: 0.8726 - f1: 0.8724 - precision_measure: 0.8737 - recall_measure: 0.8711 - val_loss: 0.4749 - val_acc: 0.8215 - val_f1: 0.8212 - val_precision_measure: 0.8222 - val_recall_measure: 0.8203\n",
      "Epoch 7/15\n",
      "301655/301655 [==============================] - 208s 688us/step - loss: 0.2187 - acc: 0.8858 - f1: 0.8856 - precision_measure: 0.8867 - recall_measure: 0.8846 - val_loss: 0.3951 - val_acc: 0.8693 - val_f1: 0.8688 - val_precision_measure: 0.8704 - val_recall_measure: 0.8672\n",
      "Epoch 8/15\n",
      "301655/301655 [==============================] - 218s 722us/step - loss: 0.2018 - acc: 0.8955 - f1: 0.8954 - precision_measure: 0.8963 - recall_measure: 0.8945 - val_loss: 0.4044 - val_acc: 0.8599 - val_f1: 0.8596 - val_precision_measure: 0.8605 - val_recall_measure: 0.8587\n",
      "Epoch 9/15\n",
      "301655/301655 [==============================] - 206s 682us/step - loss: 0.1831 - acc: 0.9078 - f1: 0.9078 - precision_measure: 0.9084 - recall_measure: 0.9072 - val_loss: 0.3529 - val_acc: 0.8897 - val_f1: 0.8893 - val_precision_measure: 0.8901 - val_recall_measure: 0.8885\n",
      "Epoch 10/15\n",
      "301655/301655 [==============================] - 209s 694us/step - loss: 0.1726 - acc: 0.9154 - f1: 0.9153 - precision_measure: 0.9158 - recall_measure: 0.9149 - val_loss: 0.4385 - val_acc: 0.8523 - val_f1: 0.8521 - val_precision_measure: 0.8526 - val_recall_measure: 0.8516\n",
      "Epoch 11/15\n",
      "301655/301655 [==============================] - 298s 987us/step - loss: 0.1604 - acc: 0.9240 - f1: 0.9240 - precision_measure: 0.9244 - recall_measure: 0.9236 - val_loss: 0.3547 - val_acc: 0.8952 - val_f1: 0.8951 - val_precision_measure: 0.8953 - val_recall_measure: 0.8949\n",
      "Epoch 12/15\n",
      "301655/301655 [==============================] - 260s 861us/step - loss: 0.1504 - acc: 0.9313 - f1: 0.9312 - precision_measure: 0.9316 - recall_measure: 0.9309 - val_loss: 0.5406 - val_acc: 0.8180 - val_f1: 0.8177 - val_precision_measure: 0.8193 - val_recall_measure: 0.8162\n",
      "Epoch 13/15\n",
      "301655/301655 [==============================] - 212s 704us/step - loss: 0.1370 - acc: 0.9397 - f1: 0.9397 - precision_measure: 0.9399 - recall_measure: 0.9394 - val_loss: 0.4485 - val_acc: 0.8662 - val_f1: 0.8661 - val_precision_measure: 0.8665 - val_recall_measure: 0.8657\n",
      "Epoch 14/15\n",
      "301655/301655 [==============================] - 250s 828us/step - loss: 0.1331 - acc: 0.9444 - f1: 0.9444 - precision_measure: 0.9446 - recall_measure: 0.9442 - val_loss: 0.5076 - val_acc: 0.8356 - val_f1: 0.8355 - val_precision_measure: 0.8358 - val_recall_measure: 0.8352\n",
      "Epoch 15/15\n",
      "301655/301655 [==============================] - 341s 1ms/step - loss: 0.1223 - acc: 0.9507 - f1: 0.9507 - precision_measure: 0.9508 - recall_measure: 0.9505 - val_loss: 0.5007 - val_acc: 0.8584 - val_f1: 0.8583 - val_precision_measure: 0.8585 - val_recall_measure: 0.8581\n",
      "33762/33762 [==============================] - 8s 225us/step\n"
     ]
    }
   ],
   "source": [
    "# Optimal parameters: dropout_rate = 0.1, l1 = 2e-6, l2 = 2e-8\n",
    "best_history, best_accuracy, best_f1, best_precision, best_recall = evaluate_model(training_X, \n",
    "                                                                                   training_y_encoded, \n",
    "                                                                                   val_X, val_y_encoded, \n",
    "                                                                                   0.1, 2**-6, 2**-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "parliamentary-obligation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(best_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "pediatric-difficulty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8546650079971566\n"
     ]
    }
   ],
   "source": [
    "curr_acc = st.mean(best_history.history['val_acc'][10:15])\n",
    "print(curr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-backing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 301655 samples, validate on 33762 samples\n",
      "Epoch 1/15\n",
      "301655/301655 [==============================] - 370s 1ms/step - loss: 0.6426 - acc: 0.6258 - f1: 0.5740 - precision_measure: 0.6425 - recall_measure: 0.5438 - val_loss: 0.7667 - val_acc: 0.6298 - val_f1: 0.6259 - val_precision_measure: 0.6341 - val_recall_measure: 0.6186\n",
      "Epoch 2/15\n",
      "247616/301655 [=======================>......] - ETA: 57s - loss: 0.3853 - acc: 0.7874 - f1: 0.7849 - precision_measure: 0.7938 - recall_measure: 0.7763"
     ]
    }
   ],
   "source": [
    "best_model = define_LSTM_model(0.1, 2**-6, 2**-8)\n",
    "best_history = best_model.fit(training_X, training_y_encoded, epochs = 15, batch_size = 64, \n",
    "              validation_data = (val_X, val_y_encoded), class_weight = label_weights, verbose = 1)\n",
    "# Get prediction report\n",
    "y_pred = best_model.predict(val_X, batch_size = 64, verbose = 1)\n",
    "y_pred_bool = np.argmax(y_pred, axis = 1)\n",
    "print(classification_report(val_y, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions using test data\n",
    "subject9_X = create_dataframe_X('TestData/subject_009_01__x.csv', 'TestData/subject_009_01__x_time.csv')\n",
    "subject10_X = create_dataframe_X('TestData/subject_010_01__x.csv', 'TestData/subject_010_01__x_time.csv')\n",
    "subject11_X = create_dataframe_X('TestData/subject_011_01__x.csv', 'TestData/subject_011_01__x_time.csv')\n",
    "subject12_X = create_dataframe_X('TestData/subject_012_01__x.csv', 'TestData/subject_012_01__x_time.csv')\n",
    "\n",
    "def generate_test_X_data(X, time_steps, step):\n",
    "    X_values = []\n",
    "    for i in range(0, len(X) - time_steps, step):\n",
    "        value = X.iloc[i+(i + time_steps)].values\n",
    "        X_values.append(value)\n",
    "    return np.array(X_values)\n",
    "\n",
    "subject9_X_test = generate_test_X_data(subject9_X, 30, 1)\n",
    "subject10_X_test = generate_test_X_data(subject10_X, 30, 1)\n",
    "subject11_X_test = generate_test_X_data(subject11_X, 30, 1)\n",
    "subject12_X_test = generate_test_X_data(subject12_X, 30, 1)\n",
    "\n",
    "# Subject 9 Predictions\n",
    "subject9_predictions = best_model.predict(subject9_X_test, batch_size=64, verbose=0)\n",
    "subject9_pred_bool = np.argmax(subject9_predictions, axis=1)\n",
    "\n",
    "# Subject 10 Predictions\n",
    "subject10_predictions = best_model.predict(subject10_X_test, batch_size=64, verbose=0)\n",
    "subject10_pred_bool = np.argmax(subject10_predictions, axis=1)\n",
    "\n",
    "# Subject 11 Predictions\n",
    "subject11_predictions = best_model.predict(subject11_X_test, batch_size=64, verbose=0)\n",
    "subject11_pred_bool = np.argmax(subject11_predictions, axis=1)\n",
    "\n",
    "# Subject 12 Predictions\n",
    "subject12_predictions = best_model.predict(subject12_X_test, batch_size=64, verbose=0)\n",
    "subject12_pred_bool = np.argmax(subject12_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
